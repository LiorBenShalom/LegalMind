{
  "best_metric": 0.6314252018928528,
  "best_model_checkpoint": "./mBERT-mlm-3k-drugs/checkpoint-32129",
  "epoch": 19.0,
  "eval_steps": 500,
  "global_step": 32129,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05913660555884092,
      "grad_norm": 13.177042007446289,
      "learning_rate": 4.98521584861029e-05,
      "loss": 1.859,
      "step": 100
    },
    {
      "epoch": 0.11827321111768184,
      "grad_norm": 10.067480087280273,
      "learning_rate": 4.97043169722058e-05,
      "loss": 1.6253,
      "step": 200
    },
    {
      "epoch": 0.17740981667652278,
      "grad_norm": 12.314902305603027,
      "learning_rate": 4.9556475458308695e-05,
      "loss": 1.5545,
      "step": 300
    },
    {
      "epoch": 0.23654642223536368,
      "grad_norm": 7.4953155517578125,
      "learning_rate": 4.940863394441159e-05,
      "loss": 1.507,
      "step": 400
    },
    {
      "epoch": 0.29568302779420463,
      "grad_norm": 20.761323928833008,
      "learning_rate": 4.926079243051449e-05,
      "loss": 1.4156,
      "step": 500
    },
    {
      "epoch": 0.35481963335304556,
      "grad_norm": 15.181623458862305,
      "learning_rate": 4.911295091661739e-05,
      "loss": 1.4011,
      "step": 600
    },
    {
      "epoch": 0.41395623891188643,
      "grad_norm": 13.925823211669922,
      "learning_rate": 4.896510940272029e-05,
      "loss": 1.3529,
      "step": 700
    },
    {
      "epoch": 0.47309284447072736,
      "grad_norm": 8.966285705566406,
      "learning_rate": 4.881726788882318e-05,
      "loss": 1.2451,
      "step": 800
    },
    {
      "epoch": 0.5322294500295683,
      "grad_norm": 9.978373527526855,
      "learning_rate": 4.866942637492608e-05,
      "loss": 1.2936,
      "step": 900
    },
    {
      "epoch": 0.5913660555884093,
      "grad_norm": 16.833677291870117,
      "learning_rate": 4.852158486102898e-05,
      "loss": 1.2538,
      "step": 1000
    },
    {
      "epoch": 0.6505026611472502,
      "grad_norm": 12.331768035888672,
      "learning_rate": 4.837374334713188e-05,
      "loss": 1.2558,
      "step": 1100
    },
    {
      "epoch": 0.7096392667060911,
      "grad_norm": 11.094069480895996,
      "learning_rate": 4.822590183323478e-05,
      "loss": 1.179,
      "step": 1200
    },
    {
      "epoch": 0.768775872264932,
      "grad_norm": 10.37720775604248,
      "learning_rate": 4.807806031933767e-05,
      "loss": 1.1753,
      "step": 1300
    },
    {
      "epoch": 0.8279124778237729,
      "grad_norm": 11.50895881652832,
      "learning_rate": 4.7930218805440567e-05,
      "loss": 1.1556,
      "step": 1400
    },
    {
      "epoch": 0.8870490833826138,
      "grad_norm": 11.77651309967041,
      "learning_rate": 4.778237729154347e-05,
      "loss": 1.1454,
      "step": 1500
    },
    {
      "epoch": 0.9461856889414547,
      "grad_norm": 8.603229522705078,
      "learning_rate": 4.763453577764637e-05,
      "loss": 1.1939,
      "step": 1600
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.0314991474151611,
      "eval_runtime": 17.8608,
      "eval_samples_per_second": 99.044,
      "eval_steps_per_second": 12.429,
      "step": 1691
    },
    {
      "epoch": 1.0053222945002958,
      "grad_norm": 9.779802322387695,
      "learning_rate": 4.7486694263749266e-05,
      "loss": 1.0824,
      "step": 1700
    },
    {
      "epoch": 1.0644589000591367,
      "grad_norm": 9.025646209716797,
      "learning_rate": 4.7338852749852156e-05,
      "loss": 1.0912,
      "step": 1800
    },
    {
      "epoch": 1.1235955056179776,
      "grad_norm": 10.255897521972656,
      "learning_rate": 4.719101123595506e-05,
      "loss": 1.0918,
      "step": 1900
    },
    {
      "epoch": 1.1827321111768185,
      "grad_norm": 8.695150375366211,
      "learning_rate": 4.704316972205796e-05,
      "loss": 1.0645,
      "step": 2000
    },
    {
      "epoch": 1.2418687167356595,
      "grad_norm": 12.727866172790527,
      "learning_rate": 4.6895328208160855e-05,
      "loss": 1.106,
      "step": 2100
    },
    {
      "epoch": 1.3010053222945004,
      "grad_norm": 10.59276008605957,
      "learning_rate": 4.674748669426375e-05,
      "loss": 1.0626,
      "step": 2200
    },
    {
      "epoch": 1.3601419278533413,
      "grad_norm": 8.01634407043457,
      "learning_rate": 4.6599645180366643e-05,
      "loss": 1.06,
      "step": 2300
    },
    {
      "epoch": 1.4192785334121822,
      "grad_norm": 12.999359130859375,
      "learning_rate": 4.645180366646955e-05,
      "loss": 0.9792,
      "step": 2400
    },
    {
      "epoch": 1.4784151389710232,
      "grad_norm": 9.561083793640137,
      "learning_rate": 4.6303962152572445e-05,
      "loss": 1.0336,
      "step": 2500
    },
    {
      "epoch": 1.537551744529864,
      "grad_norm": 9.340998649597168,
      "learning_rate": 4.615612063867534e-05,
      "loss": 0.9849,
      "step": 2600
    },
    {
      "epoch": 1.596688350088705,
      "grad_norm": 7.0243401527404785,
      "learning_rate": 4.600827912477824e-05,
      "loss": 1.0479,
      "step": 2700
    },
    {
      "epoch": 1.655824955647546,
      "grad_norm": 7.976413249969482,
      "learning_rate": 4.586043761088114e-05,
      "loss": 1.0053,
      "step": 2800
    },
    {
      "epoch": 1.7149615612063869,
      "grad_norm": 11.426361083984375,
      "learning_rate": 4.5712596096984035e-05,
      "loss": 1.044,
      "step": 2900
    },
    {
      "epoch": 1.7740981667652278,
      "grad_norm": 9.519527435302734,
      "learning_rate": 4.556475458308693e-05,
      "loss": 1.0142,
      "step": 3000
    },
    {
      "epoch": 1.8332347723240687,
      "grad_norm": 9.763423919677734,
      "learning_rate": 4.541691306918983e-05,
      "loss": 0.96,
      "step": 3100
    },
    {
      "epoch": 1.8923713778829097,
      "grad_norm": 8.26174545288086,
      "learning_rate": 4.526907155529273e-05,
      "loss": 0.9519,
      "step": 3200
    },
    {
      "epoch": 1.9515079834417506,
      "grad_norm": 7.922457695007324,
      "learning_rate": 4.5121230041395625e-05,
      "loss": 0.9728,
      "step": 3300
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.967503547668457,
      "eval_runtime": 17.8884,
      "eval_samples_per_second": 98.891,
      "eval_steps_per_second": 12.41,
      "step": 3382
    },
    {
      "epoch": 2.0106445890005915,
      "grad_norm": 9.68016242980957,
      "learning_rate": 4.497338852749852e-05,
      "loss": 0.9607,
      "step": 3400
    },
    {
      "epoch": 2.0697811945594324,
      "grad_norm": 4.168907165527344,
      "learning_rate": 4.482554701360142e-05,
      "loss": 0.971,
      "step": 3500
    },
    {
      "epoch": 2.1289178001182734,
      "grad_norm": 7.606497764587402,
      "learning_rate": 4.467770549970432e-05,
      "loss": 0.9771,
      "step": 3600
    },
    {
      "epoch": 2.1880544056771143,
      "grad_norm": 8.883355140686035,
      "learning_rate": 4.452986398580722e-05,
      "loss": 0.9576,
      "step": 3700
    },
    {
      "epoch": 2.247191011235955,
      "grad_norm": 13.388352394104004,
      "learning_rate": 4.438202247191011e-05,
      "loss": 0.952,
      "step": 3800
    },
    {
      "epoch": 2.306327616794796,
      "grad_norm": 11.758111953735352,
      "learning_rate": 4.423418095801301e-05,
      "loss": 0.9717,
      "step": 3900
    },
    {
      "epoch": 2.365464222353637,
      "grad_norm": 9.669195175170898,
      "learning_rate": 4.408633944411591e-05,
      "loss": 0.9619,
      "step": 4000
    },
    {
      "epoch": 2.424600827912478,
      "grad_norm": 5.341103553771973,
      "learning_rate": 4.393849793021881e-05,
      "loss": 0.94,
      "step": 4100
    },
    {
      "epoch": 2.483737433471319,
      "grad_norm": 10.474068641662598,
      "learning_rate": 4.379065641632171e-05,
      "loss": 0.9397,
      "step": 4200
    },
    {
      "epoch": 2.54287403903016,
      "grad_norm": 6.894324779510498,
      "learning_rate": 4.36428149024246e-05,
      "loss": 0.8964,
      "step": 4300
    },
    {
      "epoch": 2.6020106445890008,
      "grad_norm": 15.648621559143066,
      "learning_rate": 4.3494973388527496e-05,
      "loss": 0.9339,
      "step": 4400
    },
    {
      "epoch": 2.6611472501478417,
      "grad_norm": 9.140493392944336,
      "learning_rate": 4.33471318746304e-05,
      "loss": 0.9102,
      "step": 4500
    },
    {
      "epoch": 2.7202838557066826,
      "grad_norm": 11.44580078125,
      "learning_rate": 4.31992903607333e-05,
      "loss": 0.914,
      "step": 4600
    },
    {
      "epoch": 2.7794204612655236,
      "grad_norm": 8.211270332336426,
      "learning_rate": 4.3051448846836196e-05,
      "loss": 0.9512,
      "step": 4700
    },
    {
      "epoch": 2.8385570668243645,
      "grad_norm": 13.068278312683105,
      "learning_rate": 4.2903607332939086e-05,
      "loss": 0.9044,
      "step": 4800
    },
    {
      "epoch": 2.8976936723832054,
      "grad_norm": 9.388544082641602,
      "learning_rate": 4.275576581904199e-05,
      "loss": 0.8741,
      "step": 4900
    },
    {
      "epoch": 2.9568302779420463,
      "grad_norm": 6.4835028648376465,
      "learning_rate": 4.260792430514489e-05,
      "loss": 0.9585,
      "step": 5000
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.9069306254386902,
      "eval_runtime": 17.6915,
      "eval_samples_per_second": 99.992,
      "eval_steps_per_second": 12.548,
      "step": 5073
    },
    {
      "epoch": 3.0159668835008873,
      "grad_norm": 10.034636497497559,
      "learning_rate": 4.2460082791247785e-05,
      "loss": 0.8733,
      "step": 5100
    },
    {
      "epoch": 3.075103489059728,
      "grad_norm": 8.864191055297852,
      "learning_rate": 4.231224127735068e-05,
      "loss": 0.905,
      "step": 5200
    },
    {
      "epoch": 3.134240094618569,
      "grad_norm": 8.930001258850098,
      "learning_rate": 4.216439976345358e-05,
      "loss": 0.9014,
      "step": 5300
    },
    {
      "epoch": 3.19337670017741,
      "grad_norm": 10.233683586120605,
      "learning_rate": 4.201655824955648e-05,
      "loss": 0.9058,
      "step": 5400
    },
    {
      "epoch": 3.252513305736251,
      "grad_norm": 9.905046463012695,
      "learning_rate": 4.1868716735659375e-05,
      "loss": 0.7867,
      "step": 5500
    },
    {
      "epoch": 3.311649911295092,
      "grad_norm": 5.785463333129883,
      "learning_rate": 4.172087522176227e-05,
      "loss": 0.8664,
      "step": 5600
    },
    {
      "epoch": 3.370786516853933,
      "grad_norm": 7.856558799743652,
      "learning_rate": 4.157303370786517e-05,
      "loss": 0.8936,
      "step": 5700
    },
    {
      "epoch": 3.4299231224127738,
      "grad_norm": 10.652738571166992,
      "learning_rate": 4.1425192193968074e-05,
      "loss": 0.8386,
      "step": 5800
    },
    {
      "epoch": 3.4890597279716147,
      "grad_norm": 23.17469596862793,
      "learning_rate": 4.1277350680070965e-05,
      "loss": 0.9,
      "step": 5900
    },
    {
      "epoch": 3.5481963335304556,
      "grad_norm": 8.880276679992676,
      "learning_rate": 4.112950916617386e-05,
      "loss": 0.8542,
      "step": 6000
    },
    {
      "epoch": 3.6073329390892965,
      "grad_norm": 7.219295501708984,
      "learning_rate": 4.098166765227676e-05,
      "loss": 0.8491,
      "step": 6100
    },
    {
      "epoch": 3.6664695446481375,
      "grad_norm": 7.435641765594482,
      "learning_rate": 4.0833826138379664e-05,
      "loss": 0.8312,
      "step": 6200
    },
    {
      "epoch": 3.7256061502069784,
      "grad_norm": 7.185116767883301,
      "learning_rate": 4.068598462448256e-05,
      "loss": 0.8223,
      "step": 6300
    },
    {
      "epoch": 3.7847427557658193,
      "grad_norm": 7.764629364013672,
      "learning_rate": 4.053814311058545e-05,
      "loss": 0.8436,
      "step": 6400
    },
    {
      "epoch": 3.8438793613246602,
      "grad_norm": 7.556813716888428,
      "learning_rate": 4.039030159668835e-05,
      "loss": 0.8725,
      "step": 6500
    },
    {
      "epoch": 3.903015966883501,
      "grad_norm": 10.156183242797852,
      "learning_rate": 4.024246008279125e-05,
      "loss": 0.885,
      "step": 6600
    },
    {
      "epoch": 3.9621525724423416,
      "grad_norm": 10.827733039855957,
      "learning_rate": 4.009461856889415e-05,
      "loss": 0.8407,
      "step": 6700
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.8279592990875244,
      "eval_runtime": 17.7046,
      "eval_samples_per_second": 99.918,
      "eval_steps_per_second": 12.539,
      "step": 6764
    },
    {
      "epoch": 4.021289178001183,
      "grad_norm": 9.36098575592041,
      "learning_rate": 3.994677705499705e-05,
      "loss": 0.8468,
      "step": 6800
    },
    {
      "epoch": 4.080425783560024,
      "grad_norm": 9.713399887084961,
      "learning_rate": 3.979893554109994e-05,
      "loss": 0.8698,
      "step": 6900
    },
    {
      "epoch": 4.139562389118865,
      "grad_norm": 5.4902567863464355,
      "learning_rate": 3.965109402720284e-05,
      "loss": 0.8181,
      "step": 7000
    },
    {
      "epoch": 4.198698994677706,
      "grad_norm": 6.331301689147949,
      "learning_rate": 3.950325251330574e-05,
      "loss": 0.8339,
      "step": 7100
    },
    {
      "epoch": 4.257835600236547,
      "grad_norm": 10.566156387329102,
      "learning_rate": 3.935541099940864e-05,
      "loss": 0.8272,
      "step": 7200
    },
    {
      "epoch": 4.316972205795388,
      "grad_norm": 15.018485069274902,
      "learning_rate": 3.9207569485511536e-05,
      "loss": 0.7844,
      "step": 7300
    },
    {
      "epoch": 4.376108811354229,
      "grad_norm": 7.661245822906494,
      "learning_rate": 3.9059727971614426e-05,
      "loss": 0.8561,
      "step": 7400
    },
    {
      "epoch": 4.4352454169130695,
      "grad_norm": 7.213048458099365,
      "learning_rate": 3.891188645771733e-05,
      "loss": 0.8018,
      "step": 7500
    },
    {
      "epoch": 4.49438202247191,
      "grad_norm": 21.32367706298828,
      "learning_rate": 3.876404494382023e-05,
      "loss": 0.7817,
      "step": 7600
    },
    {
      "epoch": 4.553518628030751,
      "grad_norm": 7.060287952423096,
      "learning_rate": 3.8616203429923125e-05,
      "loss": 0.8163,
      "step": 7700
    },
    {
      "epoch": 4.612655233589592,
      "grad_norm": 7.293033599853516,
      "learning_rate": 3.846836191602602e-05,
      "loss": 0.8671,
      "step": 7800
    },
    {
      "epoch": 4.671791839148433,
      "grad_norm": 9.823026657104492,
      "learning_rate": 3.832052040212892e-05,
      "loss": 0.8075,
      "step": 7900
    },
    {
      "epoch": 4.730928444707274,
      "grad_norm": 12.02316951751709,
      "learning_rate": 3.817267888823182e-05,
      "loss": 0.7895,
      "step": 8000
    },
    {
      "epoch": 4.790065050266115,
      "grad_norm": 9.42021656036377,
      "learning_rate": 3.8024837374334715e-05,
      "loss": 0.8139,
      "step": 8100
    },
    {
      "epoch": 4.849201655824956,
      "grad_norm": 7.925302028656006,
      "learning_rate": 3.787699586043761e-05,
      "loss": 0.7464,
      "step": 8200
    },
    {
      "epoch": 4.908338261383797,
      "grad_norm": 11.048622131347656,
      "learning_rate": 3.772915434654051e-05,
      "loss": 0.8018,
      "step": 8300
    },
    {
      "epoch": 4.967474866942638,
      "grad_norm": 9.63586139678955,
      "learning_rate": 3.758131283264341e-05,
      "loss": 0.7812,
      "step": 8400
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.808047890663147,
      "eval_runtime": 17.9528,
      "eval_samples_per_second": 98.536,
      "eval_steps_per_second": 12.366,
      "step": 8455
    },
    {
      "epoch": 5.026611472501479,
      "grad_norm": 4.011699676513672,
      "learning_rate": 3.7433471318746305e-05,
      "loss": 0.7947,
      "step": 8500
    },
    {
      "epoch": 5.08574807806032,
      "grad_norm": 5.933839321136475,
      "learning_rate": 3.72856298048492e-05,
      "loss": 0.7768,
      "step": 8600
    },
    {
      "epoch": 5.144884683619161,
      "grad_norm": 8.809679985046387,
      "learning_rate": 3.71377882909521e-05,
      "loss": 0.7755,
      "step": 8700
    },
    {
      "epoch": 5.2040212891780016,
      "grad_norm": 12.83100414276123,
      "learning_rate": 3.6989946777055004e-05,
      "loss": 0.8101,
      "step": 8800
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 8.645919799804688,
      "learning_rate": 3.6842105263157895e-05,
      "loss": 0.7447,
      "step": 8900
    },
    {
      "epoch": 5.322294500295683,
      "grad_norm": 6.300670146942139,
      "learning_rate": 3.669426374926079e-05,
      "loss": 0.7889,
      "step": 9000
    },
    {
      "epoch": 5.381431105854524,
      "grad_norm": 12.95174789428711,
      "learning_rate": 3.654642223536369e-05,
      "loss": 0.7828,
      "step": 9100
    },
    {
      "epoch": 5.440567711413365,
      "grad_norm": 5.054419994354248,
      "learning_rate": 3.6398580721466594e-05,
      "loss": 0.753,
      "step": 9200
    },
    {
      "epoch": 5.499704316972206,
      "grad_norm": 9.403324127197266,
      "learning_rate": 3.625073920756949e-05,
      "loss": 0.7307,
      "step": 9300
    },
    {
      "epoch": 5.558840922531047,
      "grad_norm": 5.3735504150390625,
      "learning_rate": 3.610289769367238e-05,
      "loss": 0.7538,
      "step": 9400
    },
    {
      "epoch": 5.617977528089888,
      "grad_norm": 8.226836204528809,
      "learning_rate": 3.595505617977528e-05,
      "loss": 0.7688,
      "step": 9500
    },
    {
      "epoch": 5.677114133648729,
      "grad_norm": 8.319437026977539,
      "learning_rate": 3.5807214665878184e-05,
      "loss": 0.7654,
      "step": 9600
    },
    {
      "epoch": 5.73625073920757,
      "grad_norm": 6.490575790405273,
      "learning_rate": 3.565937315198108e-05,
      "loss": 0.7551,
      "step": 9700
    },
    {
      "epoch": 5.795387344766411,
      "grad_norm": 9.209782600402832,
      "learning_rate": 3.551153163808398e-05,
      "loss": 0.7344,
      "step": 9800
    },
    {
      "epoch": 5.854523950325252,
      "grad_norm": 10.68110179901123,
      "learning_rate": 3.536369012418687e-05,
      "loss": 0.7523,
      "step": 9900
    },
    {
      "epoch": 5.913660555884093,
      "grad_norm": 7.150017261505127,
      "learning_rate": 3.521584861028977e-05,
      "loss": 0.7935,
      "step": 10000
    },
    {
      "epoch": 5.972797161442934,
      "grad_norm": 11.008280754089355,
      "learning_rate": 3.506800709639267e-05,
      "loss": 0.7555,
      "step": 10100
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7770525217056274,
      "eval_runtime": 17.7731,
      "eval_samples_per_second": 99.532,
      "eval_steps_per_second": 12.491,
      "step": 10146
    },
    {
      "epoch": 6.0319337670017745,
      "grad_norm": 10.20661449432373,
      "learning_rate": 3.492016558249557e-05,
      "loss": 0.7742,
      "step": 10200
    },
    {
      "epoch": 6.0910703725606155,
      "grad_norm": 5.127031326293945,
      "learning_rate": 3.4772324068598466e-05,
      "loss": 0.7541,
      "step": 10300
    },
    {
      "epoch": 6.150206978119456,
      "grad_norm": 6.883304119110107,
      "learning_rate": 3.4624482554701356e-05,
      "loss": 0.7555,
      "step": 10400
    },
    {
      "epoch": 6.209343583678297,
      "grad_norm": 10.230741500854492,
      "learning_rate": 3.447664104080426e-05,
      "loss": 0.7381,
      "step": 10500
    },
    {
      "epoch": 6.268480189237138,
      "grad_norm": 8.491459846496582,
      "learning_rate": 3.432879952690716e-05,
      "loss": 0.7816,
      "step": 10600
    },
    {
      "epoch": 6.327616794795979,
      "grad_norm": 8.607531547546387,
      "learning_rate": 3.4180958013010055e-05,
      "loss": 0.7449,
      "step": 10700
    },
    {
      "epoch": 6.38675340035482,
      "grad_norm": 5.502264022827148,
      "learning_rate": 3.403311649911295e-05,
      "loss": 0.7374,
      "step": 10800
    },
    {
      "epoch": 6.445890005913661,
      "grad_norm": 6.391392707824707,
      "learning_rate": 3.388527498521585e-05,
      "loss": 0.7144,
      "step": 10900
    },
    {
      "epoch": 6.505026611472502,
      "grad_norm": 12.043933868408203,
      "learning_rate": 3.373743347131875e-05,
      "loss": 0.7051,
      "step": 11000
    },
    {
      "epoch": 6.564163217031343,
      "grad_norm": 6.9302144050598145,
      "learning_rate": 3.3589591957421645e-05,
      "loss": 0.7587,
      "step": 11100
    },
    {
      "epoch": 6.623299822590184,
      "grad_norm": 8.275776863098145,
      "learning_rate": 3.344175044352454e-05,
      "loss": 0.762,
      "step": 11200
    },
    {
      "epoch": 6.682436428149025,
      "grad_norm": 7.782110214233398,
      "learning_rate": 3.329390892962744e-05,
      "loss": 0.7204,
      "step": 11300
    },
    {
      "epoch": 6.741573033707866,
      "grad_norm": 5.91786003112793,
      "learning_rate": 3.314606741573034e-05,
      "loss": 0.7336,
      "step": 11400
    },
    {
      "epoch": 6.800709639266707,
      "grad_norm": 9.973692893981934,
      "learning_rate": 3.2998225901833235e-05,
      "loss": 0.6955,
      "step": 11500
    },
    {
      "epoch": 6.8598462448255475,
      "grad_norm": 9.049324035644531,
      "learning_rate": 3.285038438793613e-05,
      "loss": 0.7422,
      "step": 11600
    },
    {
      "epoch": 6.918982850384388,
      "grad_norm": 12.718270301818848,
      "learning_rate": 3.270254287403903e-05,
      "loss": 0.715,
      "step": 11700
    },
    {
      "epoch": 6.978119455943229,
      "grad_norm": 5.647329330444336,
      "learning_rate": 3.2554701360141934e-05,
      "loss": 0.7746,
      "step": 11800
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7843020558357239,
      "eval_runtime": 17.8549,
      "eval_samples_per_second": 99.077,
      "eval_steps_per_second": 12.434,
      "step": 11837
    },
    {
      "epoch": 7.037256061502069,
      "grad_norm": 6.447372913360596,
      "learning_rate": 3.2406859846244825e-05,
      "loss": 0.7253,
      "step": 11900
    },
    {
      "epoch": 7.09639266706091,
      "grad_norm": 13.686395645141602,
      "learning_rate": 3.225901833234772e-05,
      "loss": 0.7314,
      "step": 12000
    },
    {
      "epoch": 7.155529272619751,
      "grad_norm": 6.963919639587402,
      "learning_rate": 3.211117681845062e-05,
      "loss": 0.7244,
      "step": 12100
    },
    {
      "epoch": 7.214665878178592,
      "grad_norm": 5.869696140289307,
      "learning_rate": 3.1963335304553524e-05,
      "loss": 0.7283,
      "step": 12200
    },
    {
      "epoch": 7.273802483737433,
      "grad_norm": 14.533265113830566,
      "learning_rate": 3.181549379065642e-05,
      "loss": 0.7383,
      "step": 12300
    },
    {
      "epoch": 7.332939089296274,
      "grad_norm": 8.792540550231934,
      "learning_rate": 3.166765227675931e-05,
      "loss": 0.7449,
      "step": 12400
    },
    {
      "epoch": 7.392075694855115,
      "grad_norm": 8.3872709274292,
      "learning_rate": 3.151981076286221e-05,
      "loss": 0.7072,
      "step": 12500
    },
    {
      "epoch": 7.451212300413956,
      "grad_norm": 6.119906425476074,
      "learning_rate": 3.1371969248965113e-05,
      "loss": 0.7535,
      "step": 12600
    },
    {
      "epoch": 7.510348905972797,
      "grad_norm": 6.820493698120117,
      "learning_rate": 3.122412773506801e-05,
      "loss": 0.6495,
      "step": 12700
    },
    {
      "epoch": 7.569485511531638,
      "grad_norm": 6.919747829437256,
      "learning_rate": 3.107628622117091e-05,
      "loss": 0.705,
      "step": 12800
    },
    {
      "epoch": 7.628622117090479,
      "grad_norm": 14.030189514160156,
      "learning_rate": 3.09284447072738e-05,
      "loss": 0.7278,
      "step": 12900
    },
    {
      "epoch": 7.68775872264932,
      "grad_norm": 7.624231815338135,
      "learning_rate": 3.07806031933767e-05,
      "loss": 0.7077,
      "step": 13000
    },
    {
      "epoch": 7.7468953282081605,
      "grad_norm": 8.551609992980957,
      "learning_rate": 3.06327616794796e-05,
      "loss": 0.7406,
      "step": 13100
    },
    {
      "epoch": 7.806031933767001,
      "grad_norm": 7.000750541687012,
      "learning_rate": 3.0484920165582498e-05,
      "loss": 0.6553,
      "step": 13200
    },
    {
      "epoch": 7.865168539325842,
      "grad_norm": 11.484003067016602,
      "learning_rate": 3.0337078651685396e-05,
      "loss": 0.743,
      "step": 13300
    },
    {
      "epoch": 7.924305144884683,
      "grad_norm": 7.362006187438965,
      "learning_rate": 3.018923713778829e-05,
      "loss": 0.6837,
      "step": 13400
    },
    {
      "epoch": 7.983441750443524,
      "grad_norm": 6.8892645835876465,
      "learning_rate": 3.0041395623891187e-05,
      "loss": 0.7401,
      "step": 13500
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7330331802368164,
      "eval_runtime": 17.9939,
      "eval_samples_per_second": 98.311,
      "eval_steps_per_second": 12.338,
      "step": 13528
    },
    {
      "epoch": 8.042578356002366,
      "grad_norm": 7.490514278411865,
      "learning_rate": 2.9893554109994088e-05,
      "loss": 0.6782,
      "step": 13600
    },
    {
      "epoch": 8.101714961561207,
      "grad_norm": 5.591578006744385,
      "learning_rate": 2.9745712596096985e-05,
      "loss": 0.678,
      "step": 13700
    },
    {
      "epoch": 8.160851567120048,
      "grad_norm": 6.160539627075195,
      "learning_rate": 2.9597871082199886e-05,
      "loss": 0.6883,
      "step": 13800
    },
    {
      "epoch": 8.219988172678889,
      "grad_norm": 7.469318866729736,
      "learning_rate": 2.9450029568302777e-05,
      "loss": 0.6983,
      "step": 13900
    },
    {
      "epoch": 8.27912477823773,
      "grad_norm": 8.359480857849121,
      "learning_rate": 2.9302188054405678e-05,
      "loss": 0.7183,
      "step": 14000
    },
    {
      "epoch": 8.33826138379657,
      "grad_norm": 7.372505187988281,
      "learning_rate": 2.9154346540508575e-05,
      "loss": 0.6799,
      "step": 14100
    },
    {
      "epoch": 8.397397989355412,
      "grad_norm": 9.863004684448242,
      "learning_rate": 2.9006505026611476e-05,
      "loss": 0.6901,
      "step": 14200
    },
    {
      "epoch": 8.456534594914253,
      "grad_norm": 7.443161487579346,
      "learning_rate": 2.8858663512714373e-05,
      "loss": 0.6523,
      "step": 14300
    },
    {
      "epoch": 8.515671200473093,
      "grad_norm": 5.899701118469238,
      "learning_rate": 2.8710821998817267e-05,
      "loss": 0.651,
      "step": 14400
    },
    {
      "epoch": 8.574807806031934,
      "grad_norm": 11.677949905395508,
      "learning_rate": 2.8562980484920165e-05,
      "loss": 0.6952,
      "step": 14500
    },
    {
      "epoch": 8.633944411590775,
      "grad_norm": 5.847776412963867,
      "learning_rate": 2.8415138971023066e-05,
      "loss": 0.6983,
      "step": 14600
    },
    {
      "epoch": 8.693081017149616,
      "grad_norm": 6.2369184494018555,
      "learning_rate": 2.8267297457125963e-05,
      "loss": 0.6862,
      "step": 14700
    },
    {
      "epoch": 8.752217622708457,
      "grad_norm": 11.448034286499023,
      "learning_rate": 2.811945594322886e-05,
      "loss": 0.6685,
      "step": 14800
    },
    {
      "epoch": 8.811354228267298,
      "grad_norm": 8.668030738830566,
      "learning_rate": 2.7971614429331755e-05,
      "loss": 0.6901,
      "step": 14900
    },
    {
      "epoch": 8.870490833826139,
      "grad_norm": 12.631050109863281,
      "learning_rate": 2.7823772915434655e-05,
      "loss": 0.692,
      "step": 15000
    },
    {
      "epoch": 8.92962743938498,
      "grad_norm": 7.967957019805908,
      "learning_rate": 2.7675931401537553e-05,
      "loss": 0.6689,
      "step": 15100
    },
    {
      "epoch": 8.98876404494382,
      "grad_norm": 10.529780387878418,
      "learning_rate": 2.752808988764045e-05,
      "loss": 0.6742,
      "step": 15200
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.73078453540802,
      "eval_runtime": 17.7398,
      "eval_samples_per_second": 99.719,
      "eval_steps_per_second": 12.514,
      "step": 15219
    },
    {
      "epoch": 9.047900650502662,
      "grad_norm": 12.87996768951416,
      "learning_rate": 2.738024837374335e-05,
      "loss": 0.6973,
      "step": 15300
    },
    {
      "epoch": 9.107037256061503,
      "grad_norm": 6.357003211975098,
      "learning_rate": 2.7232406859846242e-05,
      "loss": 0.6338,
      "step": 15400
    },
    {
      "epoch": 9.166173861620344,
      "grad_norm": 13.795461654663086,
      "learning_rate": 2.7084565345949143e-05,
      "loss": 0.6254,
      "step": 15500
    },
    {
      "epoch": 9.225310467179185,
      "grad_norm": 9.076658248901367,
      "learning_rate": 2.693672383205204e-05,
      "loss": 0.6837,
      "step": 15600
    },
    {
      "epoch": 9.284447072738025,
      "grad_norm": 6.764990329742432,
      "learning_rate": 2.678888231815494e-05,
      "loss": 0.6378,
      "step": 15700
    },
    {
      "epoch": 9.343583678296866,
      "grad_norm": 8.296331405639648,
      "learning_rate": 2.6641040804257838e-05,
      "loss": 0.6169,
      "step": 15800
    },
    {
      "epoch": 9.402720283855707,
      "grad_norm": 3.8242218494415283,
      "learning_rate": 2.6493199290360736e-05,
      "loss": 0.6516,
      "step": 15900
    },
    {
      "epoch": 9.461856889414548,
      "grad_norm": 7.125074863433838,
      "learning_rate": 2.634535777646363e-05,
      "loss": 0.6678,
      "step": 16000
    },
    {
      "epoch": 9.52099349497339,
      "grad_norm": 5.328891754150391,
      "learning_rate": 2.619751626256653e-05,
      "loss": 0.6444,
      "step": 16100
    },
    {
      "epoch": 9.58013010053223,
      "grad_norm": 6.987284183502197,
      "learning_rate": 2.6049674748669428e-05,
      "loss": 0.6621,
      "step": 16200
    },
    {
      "epoch": 9.639266706091071,
      "grad_norm": 8.989425659179688,
      "learning_rate": 2.5901833234772325e-05,
      "loss": 0.5956,
      "step": 16300
    },
    {
      "epoch": 9.698403311649912,
      "grad_norm": 7.276064395904541,
      "learning_rate": 2.5753991720875226e-05,
      "loss": 0.5997,
      "step": 16400
    },
    {
      "epoch": 9.757539917208753,
      "grad_norm": 6.758804798126221,
      "learning_rate": 2.560615020697812e-05,
      "loss": 0.6403,
      "step": 16500
    },
    {
      "epoch": 9.816676522767594,
      "grad_norm": 8.903985977172852,
      "learning_rate": 2.5458308693081018e-05,
      "loss": 0.6701,
      "step": 16600
    },
    {
      "epoch": 9.875813128326435,
      "grad_norm": 7.7017364501953125,
      "learning_rate": 2.5310467179183915e-05,
      "loss": 0.6478,
      "step": 16700
    },
    {
      "epoch": 9.934949733885276,
      "grad_norm": 5.241621494293213,
      "learning_rate": 2.5162625665286816e-05,
      "loss": 0.6664,
      "step": 16800
    },
    {
      "epoch": 9.994086339444117,
      "grad_norm": 7.271327018737793,
      "learning_rate": 2.5014784151389713e-05,
      "loss": 0.6444,
      "step": 16900
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.7230715155601501,
      "eval_runtime": 17.7093,
      "eval_samples_per_second": 99.891,
      "eval_steps_per_second": 12.536,
      "step": 16910
    },
    {
      "epoch": 10.053222945002958,
      "grad_norm": 6.734582424163818,
      "learning_rate": 2.486694263749261e-05,
      "loss": 0.6501,
      "step": 17000
    },
    {
      "epoch": 10.112359550561798,
      "grad_norm": 10.217940330505371,
      "learning_rate": 2.4719101123595505e-05,
      "loss": 0.6073,
      "step": 17100
    },
    {
      "epoch": 10.17149615612064,
      "grad_norm": 20.007076263427734,
      "learning_rate": 2.4571259609698406e-05,
      "loss": 0.6234,
      "step": 17200
    },
    {
      "epoch": 10.23063276167948,
      "grad_norm": 7.539357662200928,
      "learning_rate": 2.44234180958013e-05,
      "loss": 0.6469,
      "step": 17300
    },
    {
      "epoch": 10.289769367238321,
      "grad_norm": 8.757710456848145,
      "learning_rate": 2.42755765819042e-05,
      "loss": 0.6478,
      "step": 17400
    },
    {
      "epoch": 10.348905972797162,
      "grad_norm": 10.299565315246582,
      "learning_rate": 2.4127735068007098e-05,
      "loss": 0.6193,
      "step": 17500
    },
    {
      "epoch": 10.408042578356003,
      "grad_norm": 7.518721580505371,
      "learning_rate": 2.3979893554109996e-05,
      "loss": 0.6096,
      "step": 17600
    },
    {
      "epoch": 10.467179183914844,
      "grad_norm": 7.2195634841918945,
      "learning_rate": 2.3832052040212893e-05,
      "loss": 0.6501,
      "step": 17700
    },
    {
      "epoch": 10.526315789473685,
      "grad_norm": 6.326367378234863,
      "learning_rate": 2.368421052631579e-05,
      "loss": 0.6456,
      "step": 17800
    },
    {
      "epoch": 10.585452395032526,
      "grad_norm": 7.281276226043701,
      "learning_rate": 2.3536369012418688e-05,
      "loss": 0.6203,
      "step": 17900
    },
    {
      "epoch": 10.644589000591367,
      "grad_norm": 5.768675804138184,
      "learning_rate": 2.3388527498521585e-05,
      "loss": 0.6375,
      "step": 18000
    },
    {
      "epoch": 10.703725606150208,
      "grad_norm": 6.012856483459473,
      "learning_rate": 2.3240685984624483e-05,
      "loss": 0.6355,
      "step": 18100
    },
    {
      "epoch": 10.762862211709049,
      "grad_norm": 19.112529754638672,
      "learning_rate": 2.309284447072738e-05,
      "loss": 0.6177,
      "step": 18200
    },
    {
      "epoch": 10.82199881726789,
      "grad_norm": 8.16829776763916,
      "learning_rate": 2.2945002956830278e-05,
      "loss": 0.6495,
      "step": 18300
    },
    {
      "epoch": 10.88113542282673,
      "grad_norm": 9.596715927124023,
      "learning_rate": 2.2797161442933175e-05,
      "loss": 0.5971,
      "step": 18400
    },
    {
      "epoch": 10.940272028385571,
      "grad_norm": 7.4898295402526855,
      "learning_rate": 2.2649319929036076e-05,
      "loss": 0.629,
      "step": 18500
    },
    {
      "epoch": 10.999408633944412,
      "grad_norm": 7.744873046875,
      "learning_rate": 2.250147841513897e-05,
      "loss": 0.5927,
      "step": 18600
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.7214654684066772,
      "eval_runtime": 17.7015,
      "eval_samples_per_second": 99.935,
      "eval_steps_per_second": 12.541,
      "step": 18601
    },
    {
      "epoch": 11.058545239503253,
      "grad_norm": 6.013815402984619,
      "learning_rate": 2.235363690124187e-05,
      "loss": 0.6295,
      "step": 18700
    },
    {
      "epoch": 11.117681845062094,
      "grad_norm": 8.099308967590332,
      "learning_rate": 2.2205795387344768e-05,
      "loss": 0.5968,
      "step": 18800
    },
    {
      "epoch": 11.176818450620935,
      "grad_norm": 7.005115509033203,
      "learning_rate": 2.2057953873447666e-05,
      "loss": 0.6049,
      "step": 18900
    },
    {
      "epoch": 11.235955056179776,
      "grad_norm": 4.708826541900635,
      "learning_rate": 2.1910112359550563e-05,
      "loss": 0.5923,
      "step": 19000
    },
    {
      "epoch": 11.295091661738617,
      "grad_norm": 7.220134258270264,
      "learning_rate": 2.176227084565346e-05,
      "loss": 0.5693,
      "step": 19100
    },
    {
      "epoch": 11.354228267297458,
      "grad_norm": 6.361775875091553,
      "learning_rate": 2.1614429331756358e-05,
      "loss": 0.6503,
      "step": 19200
    },
    {
      "epoch": 11.413364872856299,
      "grad_norm": 5.569043159484863,
      "learning_rate": 2.146658781785926e-05,
      "loss": 0.5804,
      "step": 19300
    },
    {
      "epoch": 11.47250147841514,
      "grad_norm": 7.717668056488037,
      "learning_rate": 2.1318746303962153e-05,
      "loss": 0.6038,
      "step": 19400
    },
    {
      "epoch": 11.53163808397398,
      "grad_norm": 8.814793586730957,
      "learning_rate": 2.1170904790065054e-05,
      "loss": 0.6154,
      "step": 19500
    },
    {
      "epoch": 11.590774689532822,
      "grad_norm": 6.098020553588867,
      "learning_rate": 2.1023063276167948e-05,
      "loss": 0.5735,
      "step": 19600
    },
    {
      "epoch": 11.649911295091663,
      "grad_norm": 7.389381408691406,
      "learning_rate": 2.0875221762270845e-05,
      "loss": 0.5711,
      "step": 19700
    },
    {
      "epoch": 11.709047900650503,
      "grad_norm": 9.270795822143555,
      "learning_rate": 2.0727380248373746e-05,
      "loss": 0.6233,
      "step": 19800
    },
    {
      "epoch": 11.768184506209344,
      "grad_norm": 8.849324226379395,
      "learning_rate": 2.057953873447664e-05,
      "loss": 0.6311,
      "step": 19900
    },
    {
      "epoch": 11.827321111768185,
      "grad_norm": 14.977745056152344,
      "learning_rate": 2.043169722057954e-05,
      "loss": 0.6106,
      "step": 20000
    },
    {
      "epoch": 11.886457717327026,
      "grad_norm": 8.041640281677246,
      "learning_rate": 2.0283855706682435e-05,
      "loss": 0.6352,
      "step": 20100
    },
    {
      "epoch": 11.945594322885867,
      "grad_norm": 6.1017961502075195,
      "learning_rate": 2.0136014192785336e-05,
      "loss": 0.5855,
      "step": 20200
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.678063690662384,
      "eval_runtime": 17.7448,
      "eval_samples_per_second": 99.691,
      "eval_steps_per_second": 12.511,
      "step": 20292
    },
    {
      "epoch": 12.004730928444708,
      "grad_norm": 6.8942036628723145,
      "learning_rate": 1.9988172678888233e-05,
      "loss": 0.619,
      "step": 20300
    },
    {
      "epoch": 12.063867534003549,
      "grad_norm": 24.04005241394043,
      "learning_rate": 1.984033116499113e-05,
      "loss": 0.5787,
      "step": 20400
    },
    {
      "epoch": 12.12300413956239,
      "grad_norm": 7.3453545570373535,
      "learning_rate": 1.9692489651094028e-05,
      "loss": 0.5881,
      "step": 20500
    },
    {
      "epoch": 12.182140745121231,
      "grad_norm": 7.5032196044921875,
      "learning_rate": 1.9544648137196925e-05,
      "loss": 0.5631,
      "step": 20600
    },
    {
      "epoch": 12.241277350680072,
      "grad_norm": 8.521467208862305,
      "learning_rate": 1.9396806623299823e-05,
      "loss": 0.6196,
      "step": 20700
    },
    {
      "epoch": 12.300413956238913,
      "grad_norm": 8.403450965881348,
      "learning_rate": 1.9248965109402724e-05,
      "loss": 0.574,
      "step": 20800
    },
    {
      "epoch": 12.359550561797754,
      "grad_norm": 6.093684673309326,
      "learning_rate": 1.9101123595505618e-05,
      "loss": 0.6131,
      "step": 20900
    },
    {
      "epoch": 12.418687167356595,
      "grad_norm": 8.273444175720215,
      "learning_rate": 1.895328208160852e-05,
      "loss": 0.6167,
      "step": 21000
    },
    {
      "epoch": 12.477823772915436,
      "grad_norm": 4.091744899749756,
      "learning_rate": 1.8805440567711413e-05,
      "loss": 0.617,
      "step": 21100
    },
    {
      "epoch": 12.536960378474276,
      "grad_norm": 6.885185718536377,
      "learning_rate": 1.8657599053814313e-05,
      "loss": 0.6038,
      "step": 21200
    },
    {
      "epoch": 12.596096984033117,
      "grad_norm": 3.714266538619995,
      "learning_rate": 1.850975753991721e-05,
      "loss": 0.5565,
      "step": 21300
    },
    {
      "epoch": 12.655233589591958,
      "grad_norm": 9.594345092773438,
      "learning_rate": 1.836191602602011e-05,
      "loss": 0.6299,
      "step": 21400
    },
    {
      "epoch": 12.7143701951508,
      "grad_norm": 15.814715385437012,
      "learning_rate": 1.8214074512123006e-05,
      "loss": 0.6192,
      "step": 21500
    },
    {
      "epoch": 12.77350680070964,
      "grad_norm": 7.318142414093018,
      "learning_rate": 1.80662329982259e-05,
      "loss": 0.5916,
      "step": 21600
    },
    {
      "epoch": 12.832643406268481,
      "grad_norm": 7.785337448120117,
      "learning_rate": 1.79183914843288e-05,
      "loss": 0.5612,
      "step": 21700
    },
    {
      "epoch": 12.891780011827322,
      "grad_norm": 6.029085636138916,
      "learning_rate": 1.7770549970431698e-05,
      "loss": 0.5541,
      "step": 21800
    },
    {
      "epoch": 12.950916617386163,
      "grad_norm": 5.627827167510986,
      "learning_rate": 1.7622708456534596e-05,
      "loss": 0.5955,
      "step": 21900
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.6845526695251465,
      "eval_runtime": 18.1301,
      "eval_samples_per_second": 97.573,
      "eval_steps_per_second": 12.245,
      "step": 21983
    },
    {
      "epoch": 13.010053222945002,
      "grad_norm": 6.686436176300049,
      "learning_rate": 1.7474866942637493e-05,
      "loss": 0.5828,
      "step": 22000
    },
    {
      "epoch": 13.069189828503843,
      "grad_norm": 6.6798787117004395,
      "learning_rate": 1.732702542874039e-05,
      "loss": 0.603,
      "step": 22100
    },
    {
      "epoch": 13.128326434062684,
      "grad_norm": 4.239433288574219,
      "learning_rate": 1.7179183914843288e-05,
      "loss": 0.5527,
      "step": 22200
    },
    {
      "epoch": 13.187463039621525,
      "grad_norm": 6.902154922485352,
      "learning_rate": 1.703134240094619e-05,
      "loss": 0.5425,
      "step": 22300
    },
    {
      "epoch": 13.246599645180366,
      "grad_norm": 5.638197898864746,
      "learning_rate": 1.6883500887049083e-05,
      "loss": 0.6473,
      "step": 22400
    },
    {
      "epoch": 13.305736250739207,
      "grad_norm": 9.81932544708252,
      "learning_rate": 1.6735659373151984e-05,
      "loss": 0.5621,
      "step": 22500
    },
    {
      "epoch": 13.364872856298048,
      "grad_norm": 8.953335762023926,
      "learning_rate": 1.6587817859254878e-05,
      "loss": 0.5755,
      "step": 22600
    },
    {
      "epoch": 13.424009461856889,
      "grad_norm": 7.864698886871338,
      "learning_rate": 1.643997634535778e-05,
      "loss": 0.6153,
      "step": 22700
    },
    {
      "epoch": 13.48314606741573,
      "grad_norm": 11.832493782043457,
      "learning_rate": 1.6292134831460676e-05,
      "loss": 0.5578,
      "step": 22800
    },
    {
      "epoch": 13.54228267297457,
      "grad_norm": 4.924689292907715,
      "learning_rate": 1.6144293317563573e-05,
      "loss": 0.5654,
      "step": 22900
    },
    {
      "epoch": 13.601419278533411,
      "grad_norm": 9.523970603942871,
      "learning_rate": 1.599645180366647e-05,
      "loss": 0.5403,
      "step": 23000
    },
    {
      "epoch": 13.660555884092252,
      "grad_norm": 7.251994609832764,
      "learning_rate": 1.5848610289769368e-05,
      "loss": 0.5842,
      "step": 23100
    },
    {
      "epoch": 13.719692489651093,
      "grad_norm": 9.004745483398438,
      "learning_rate": 1.5700768775872266e-05,
      "loss": 0.5635,
      "step": 23200
    },
    {
      "epoch": 13.778829095209934,
      "grad_norm": 8.859956741333008,
      "learning_rate": 1.5552927261975163e-05,
      "loss": 0.5408,
      "step": 23300
    },
    {
      "epoch": 13.837965700768775,
      "grad_norm": 8.261137962341309,
      "learning_rate": 1.540508574807806e-05,
      "loss": 0.4967,
      "step": 23400
    },
    {
      "epoch": 13.897102306327616,
      "grad_norm": 3.504929304122925,
      "learning_rate": 1.525724423418096e-05,
      "loss": 0.5938,
      "step": 23500
    },
    {
      "epoch": 13.956238911886457,
      "grad_norm": 7.974198818206787,
      "learning_rate": 1.5109402720283855e-05,
      "loss": 0.5506,
      "step": 23600
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.6783145070075989,
      "eval_runtime": 17.9791,
      "eval_samples_per_second": 98.392,
      "eval_steps_per_second": 12.348,
      "step": 23674
    },
    {
      "epoch": 14.015375517445298,
      "grad_norm": 8.911099433898926,
      "learning_rate": 1.4961561206386755e-05,
      "loss": 0.5224,
      "step": 23700
    },
    {
      "epoch": 14.074512123004139,
      "grad_norm": 6.4382100105285645,
      "learning_rate": 1.4813719692489652e-05,
      "loss": 0.5706,
      "step": 23800
    },
    {
      "epoch": 14.13364872856298,
      "grad_norm": 7.138860702514648,
      "learning_rate": 1.466587817859255e-05,
      "loss": 0.551,
      "step": 23900
    },
    {
      "epoch": 14.19278533412182,
      "grad_norm": 5.071620941162109,
      "learning_rate": 1.4518036664695447e-05,
      "loss": 0.5774,
      "step": 24000
    },
    {
      "epoch": 14.251921939680662,
      "grad_norm": 5.982753276824951,
      "learning_rate": 1.4370195150798346e-05,
      "loss": 0.5142,
      "step": 24100
    },
    {
      "epoch": 14.311058545239502,
      "grad_norm": 7.239334583282471,
      "learning_rate": 1.4222353636901242e-05,
      "loss": 0.5396,
      "step": 24200
    },
    {
      "epoch": 14.370195150798343,
      "grad_norm": 9.057494163513184,
      "learning_rate": 1.4074512123004141e-05,
      "loss": 0.5422,
      "step": 24300
    },
    {
      "epoch": 14.429331756357184,
      "grad_norm": 5.8721022605896,
      "learning_rate": 1.3926670609107037e-05,
      "loss": 0.5569,
      "step": 24400
    },
    {
      "epoch": 14.488468361916025,
      "grad_norm": 6.209652900695801,
      "learning_rate": 1.3778829095209936e-05,
      "loss": 0.548,
      "step": 24500
    },
    {
      "epoch": 14.547604967474866,
      "grad_norm": 6.671267986297607,
      "learning_rate": 1.3630987581312835e-05,
      "loss": 0.5315,
      "step": 24600
    },
    {
      "epoch": 14.606741573033707,
      "grad_norm": 11.37078857421875,
      "learning_rate": 1.348314606741573e-05,
      "loss": 0.5376,
      "step": 24700
    },
    {
      "epoch": 14.665878178592548,
      "grad_norm": 5.545286178588867,
      "learning_rate": 1.333530455351863e-05,
      "loss": 0.4982,
      "step": 24800
    },
    {
      "epoch": 14.725014784151389,
      "grad_norm": 6.499989032745361,
      "learning_rate": 1.3187463039621525e-05,
      "loss": 0.5955,
      "step": 24900
    },
    {
      "epoch": 14.78415138971023,
      "grad_norm": 10.28649616241455,
      "learning_rate": 1.3039621525724425e-05,
      "loss": 0.5533,
      "step": 25000
    },
    {
      "epoch": 14.84328799526907,
      "grad_norm": 3.677407741546631,
      "learning_rate": 1.2891780011827324e-05,
      "loss": 0.5669,
      "step": 25100
    },
    {
      "epoch": 14.902424600827912,
      "grad_norm": 7.84420108795166,
      "learning_rate": 1.274393849793022e-05,
      "loss": 0.5155,
      "step": 25200
    },
    {
      "epoch": 14.961561206386753,
      "grad_norm": 7.662811756134033,
      "learning_rate": 1.2596096984033119e-05,
      "loss": 0.5367,
      "step": 25300
    },
    {
      "epoch": 15.0,
      "eval_loss": 0.6758550405502319,
      "eval_runtime": 17.922,
      "eval_samples_per_second": 98.705,
      "eval_steps_per_second": 12.387,
      "step": 25365
    },
    {
      "epoch": 15.020697811945594,
      "grad_norm": 5.9952216148376465,
      "learning_rate": 1.2448255470136014e-05,
      "loss": 0.5393,
      "step": 25400
    },
    {
      "epoch": 15.079834417504435,
      "grad_norm": 5.312320232391357,
      "learning_rate": 1.2300413956238912e-05,
      "loss": 0.5411,
      "step": 25500
    },
    {
      "epoch": 15.138971023063275,
      "grad_norm": 7.770631790161133,
      "learning_rate": 1.215257244234181e-05,
      "loss": 0.5485,
      "step": 25600
    },
    {
      "epoch": 15.198107628622116,
      "grad_norm": 4.503664016723633,
      "learning_rate": 1.2004730928444707e-05,
      "loss": 0.5549,
      "step": 25700
    },
    {
      "epoch": 15.257244234180957,
      "grad_norm": 9.328091621398926,
      "learning_rate": 1.1856889414547606e-05,
      "loss": 0.504,
      "step": 25800
    },
    {
      "epoch": 15.316380839739798,
      "grad_norm": 7.825904846191406,
      "learning_rate": 1.1709047900650503e-05,
      "loss": 0.5217,
      "step": 25900
    },
    {
      "epoch": 15.37551744529864,
      "grad_norm": 11.93332290649414,
      "learning_rate": 1.15612063867534e-05,
      "loss": 0.5307,
      "step": 26000
    },
    {
      "epoch": 15.43465405085748,
      "grad_norm": 8.542415618896484,
      "learning_rate": 1.1413364872856298e-05,
      "loss": 0.5268,
      "step": 26100
    },
    {
      "epoch": 15.493790656416321,
      "grad_norm": 10.212602615356445,
      "learning_rate": 1.1265523358959196e-05,
      "loss": 0.4925,
      "step": 26200
    },
    {
      "epoch": 15.552927261975162,
      "grad_norm": 6.031828880310059,
      "learning_rate": 1.1117681845062095e-05,
      "loss": 0.5504,
      "step": 26300
    },
    {
      "epoch": 15.612063867534003,
      "grad_norm": 7.48189640045166,
      "learning_rate": 1.0969840331164992e-05,
      "loss": 0.5664,
      "step": 26400
    },
    {
      "epoch": 15.671200473092844,
      "grad_norm": 9.796576499938965,
      "learning_rate": 1.082199881726789e-05,
      "loss": 0.5138,
      "step": 26500
    },
    {
      "epoch": 15.730337078651685,
      "grad_norm": 8.166672706604004,
      "learning_rate": 1.0674157303370787e-05,
      "loss": 0.5479,
      "step": 26600
    },
    {
      "epoch": 15.789473684210526,
      "grad_norm": 9.453617095947266,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.5363,
      "step": 26700
    },
    {
      "epoch": 15.848610289769367,
      "grad_norm": 12.466826438903809,
      "learning_rate": 1.0378474275576584e-05,
      "loss": 0.5252,
      "step": 26800
    },
    {
      "epoch": 15.907746895328208,
      "grad_norm": 12.630552291870117,
      "learning_rate": 1.0230632761679481e-05,
      "loss": 0.5445,
      "step": 26900
    },
    {
      "epoch": 15.966883500887048,
      "grad_norm": 11.212566375732422,
      "learning_rate": 1.0082791247782378e-05,
      "loss": 0.5259,
      "step": 27000
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.677963376045227,
      "eval_runtime": 17.9617,
      "eval_samples_per_second": 98.487,
      "eval_steps_per_second": 12.36,
      "step": 27056
    },
    {
      "epoch": 16.02602010644589,
      "grad_norm": 5.863369941711426,
      "learning_rate": 9.934949733885276e-06,
      "loss": 0.5187,
      "step": 27100
    },
    {
      "epoch": 16.085156712004732,
      "grad_norm": 5.420848369598389,
      "learning_rate": 9.787108219988173e-06,
      "loss": 0.4969,
      "step": 27200
    },
    {
      "epoch": 16.144293317563573,
      "grad_norm": 6.289934158325195,
      "learning_rate": 9.63926670609107e-06,
      "loss": 0.4916,
      "step": 27300
    },
    {
      "epoch": 16.203429923122414,
      "grad_norm": 7.056349277496338,
      "learning_rate": 9.491425192193968e-06,
      "loss": 0.5329,
      "step": 27400
    },
    {
      "epoch": 16.262566528681255,
      "grad_norm": 5.067386627197266,
      "learning_rate": 9.343583678296866e-06,
      "loss": 0.5183,
      "step": 27500
    },
    {
      "epoch": 16.321703134240096,
      "grad_norm": 8.04418659210205,
      "learning_rate": 9.195742164399763e-06,
      "loss": 0.52,
      "step": 27600
    },
    {
      "epoch": 16.380839739798937,
      "grad_norm": 8.034273147583008,
      "learning_rate": 9.04790065050266e-06,
      "loss": 0.5283,
      "step": 27700
    },
    {
      "epoch": 16.439976345357778,
      "grad_norm": 8.842695236206055,
      "learning_rate": 8.90005913660556e-06,
      "loss": 0.5072,
      "step": 27800
    },
    {
      "epoch": 16.49911295091662,
      "grad_norm": 8.11349868774414,
      "learning_rate": 8.752217622708457e-06,
      "loss": 0.5228,
      "step": 27900
    },
    {
      "epoch": 16.55824955647546,
      "grad_norm": 7.997866630554199,
      "learning_rate": 8.604376108811355e-06,
      "loss": 0.5164,
      "step": 28000
    },
    {
      "epoch": 16.6173861620343,
      "grad_norm": 8.789185523986816,
      "learning_rate": 8.456534594914252e-06,
      "loss": 0.524,
      "step": 28100
    },
    {
      "epoch": 16.67652276759314,
      "grad_norm": 9.090141296386719,
      "learning_rate": 8.308693081017151e-06,
      "loss": 0.5207,
      "step": 28200
    },
    {
      "epoch": 16.735659373151982,
      "grad_norm": 6.407036781311035,
      "learning_rate": 8.160851567120049e-06,
      "loss": 0.5448,
      "step": 28300
    },
    {
      "epoch": 16.794795978710823,
      "grad_norm": 8.603484153747559,
      "learning_rate": 8.013010053222946e-06,
      "loss": 0.5015,
      "step": 28400
    },
    {
      "epoch": 16.853932584269664,
      "grad_norm": 4.527263641357422,
      "learning_rate": 7.865168539325843e-06,
      "loss": 0.5472,
      "step": 28500
    },
    {
      "epoch": 16.913069189828505,
      "grad_norm": 7.79557991027832,
      "learning_rate": 7.717327025428741e-06,
      "loss": 0.5131,
      "step": 28600
    },
    {
      "epoch": 16.972205795387346,
      "grad_norm": 8.205253601074219,
      "learning_rate": 7.569485511531639e-06,
      "loss": 0.5022,
      "step": 28700
    },
    {
      "epoch": 17.0,
      "eval_loss": 0.6511939764022827,
      "eval_runtime": 17.9718,
      "eval_samples_per_second": 98.432,
      "eval_steps_per_second": 12.353,
      "step": 28747
    },
    {
      "epoch": 17.031342400946187,
      "grad_norm": 11.28626823425293,
      "learning_rate": 7.421643997634537e-06,
      "loss": 0.5107,
      "step": 28800
    },
    {
      "epoch": 17.090479006505028,
      "grad_norm": 6.08407735824585,
      "learning_rate": 7.273802483737434e-06,
      "loss": 0.4781,
      "step": 28900
    },
    {
      "epoch": 17.14961561206387,
      "grad_norm": 7.792736053466797,
      "learning_rate": 7.1259609698403315e-06,
      "loss": 0.5516,
      "step": 29000
    },
    {
      "epoch": 17.20875221762271,
      "grad_norm": 4.690058708190918,
      "learning_rate": 6.978119455943229e-06,
      "loss": 0.4781,
      "step": 29100
    },
    {
      "epoch": 17.26788882318155,
      "grad_norm": 9.238643646240234,
      "learning_rate": 6.830277942046127e-06,
      "loss": 0.506,
      "step": 29200
    },
    {
      "epoch": 17.32702542874039,
      "grad_norm": 5.536487102508545,
      "learning_rate": 6.682436428149025e-06,
      "loss": 0.5417,
      "step": 29300
    },
    {
      "epoch": 17.386162034299232,
      "grad_norm": 13.42501449584961,
      "learning_rate": 6.534594914251922e-06,
      "loss": 0.5117,
      "step": 29400
    },
    {
      "epoch": 17.445298639858073,
      "grad_norm": 6.250272750854492,
      "learning_rate": 6.3867534003548195e-06,
      "loss": 0.5065,
      "step": 29500
    },
    {
      "epoch": 17.504435245416914,
      "grad_norm": 5.3474531173706055,
      "learning_rate": 6.238911886457718e-06,
      "loss": 0.4706,
      "step": 29600
    },
    {
      "epoch": 17.563571850975755,
      "grad_norm": 4.414156913757324,
      "learning_rate": 6.091070372560615e-06,
      "loss": 0.4846,
      "step": 29700
    },
    {
      "epoch": 17.622708456534596,
      "grad_norm": 4.789571762084961,
      "learning_rate": 5.9432288586635135e-06,
      "loss": 0.5155,
      "step": 29800
    },
    {
      "epoch": 17.681845062093437,
      "grad_norm": 4.149297714233398,
      "learning_rate": 5.795387344766411e-06,
      "loss": 0.519,
      "step": 29900
    },
    {
      "epoch": 17.740981667652278,
      "grad_norm": 13.919974327087402,
      "learning_rate": 5.647545830869308e-06,
      "loss": 0.5339,
      "step": 30000
    },
    {
      "epoch": 17.80011827321112,
      "grad_norm": 9.135302543640137,
      "learning_rate": 5.499704316972206e-06,
      "loss": 0.4846,
      "step": 30100
    },
    {
      "epoch": 17.85925487876996,
      "grad_norm": 5.236570358276367,
      "learning_rate": 5.351862803075103e-06,
      "loss": 0.5308,
      "step": 30200
    },
    {
      "epoch": 17.9183914843288,
      "grad_norm": 7.505738258361816,
      "learning_rate": 5.2040212891780015e-06,
      "loss": 0.4786,
      "step": 30300
    },
    {
      "epoch": 17.97752808988764,
      "grad_norm": 10.623679161071777,
      "learning_rate": 5.056179775280899e-06,
      "loss": 0.5351,
      "step": 30400
    },
    {
      "epoch": 18.0,
      "eval_loss": 0.6399329900741577,
      "eval_runtime": 17.6834,
      "eval_samples_per_second": 100.037,
      "eval_steps_per_second": 12.554,
      "step": 30438
    },
    {
      "epoch": 18.036664695446483,
      "grad_norm": 5.309131145477295,
      "learning_rate": 4.908338261383797e-06,
      "loss": 0.5101,
      "step": 30500
    },
    {
      "epoch": 18.095801301005324,
      "grad_norm": 6.8048930168151855,
      "learning_rate": 4.760496747486695e-06,
      "loss": 0.4992,
      "step": 30600
    },
    {
      "epoch": 18.154937906564165,
      "grad_norm": 7.307120323181152,
      "learning_rate": 4.612655233589592e-06,
      "loss": 0.5116,
      "step": 30700
    },
    {
      "epoch": 18.214074512123005,
      "grad_norm": 7.368720054626465,
      "learning_rate": 4.4648137196924896e-06,
      "loss": 0.508,
      "step": 30800
    },
    {
      "epoch": 18.273211117681846,
      "grad_norm": 9.547259330749512,
      "learning_rate": 4.316972205795387e-06,
      "loss": 0.5174,
      "step": 30900
    },
    {
      "epoch": 18.332347723240687,
      "grad_norm": 14.396318435668945,
      "learning_rate": 4.169130691898285e-06,
      "loss": 0.4853,
      "step": 31000
    },
    {
      "epoch": 18.391484328799528,
      "grad_norm": 5.476776599884033,
      "learning_rate": 4.021289178001183e-06,
      "loss": 0.4946,
      "step": 31100
    },
    {
      "epoch": 18.45062093435837,
      "grad_norm": 7.599123001098633,
      "learning_rate": 3.873447664104081e-06,
      "loss": 0.4955,
      "step": 31200
    },
    {
      "epoch": 18.50975753991721,
      "grad_norm": 3.928985595703125,
      "learning_rate": 3.7256061502069785e-06,
      "loss": 0.5265,
      "step": 31300
    },
    {
      "epoch": 18.56889414547605,
      "grad_norm": 3.861201286315918,
      "learning_rate": 3.577764636309876e-06,
      "loss": 0.4428,
      "step": 31400
    },
    {
      "epoch": 18.628030751034892,
      "grad_norm": 11.058536529541016,
      "learning_rate": 3.4299231224127738e-06,
      "loss": 0.5256,
      "step": 31500
    },
    {
      "epoch": 18.687167356593733,
      "grad_norm": 6.203487396240234,
      "learning_rate": 3.282081608515671e-06,
      "loss": 0.4941,
      "step": 31600
    },
    {
      "epoch": 18.746303962152574,
      "grad_norm": 6.253931999206543,
      "learning_rate": 3.1342400946185695e-06,
      "loss": 0.5261,
      "step": 31700
    },
    {
      "epoch": 18.805440567711415,
      "grad_norm": 7.527932167053223,
      "learning_rate": 2.986398580721467e-06,
      "loss": 0.5159,
      "step": 31800
    },
    {
      "epoch": 18.864577173270256,
      "grad_norm": 5.272171974182129,
      "learning_rate": 2.8385570668243644e-06,
      "loss": 0.5082,
      "step": 31900
    },
    {
      "epoch": 18.923713778829097,
      "grad_norm": 6.847695827484131,
      "learning_rate": 2.6907155529272622e-06,
      "loss": 0.4906,
      "step": 32000
    },
    {
      "epoch": 18.982850384387937,
      "grad_norm": 6.910287380218506,
      "learning_rate": 2.54287403903016e-06,
      "loss": 0.4584,
      "step": 32100
    },
    {
      "epoch": 19.0,
      "eval_loss": 0.6314252018928528,
      "eval_runtime": 17.9693,
      "eval_samples_per_second": 98.446,
      "eval_steps_per_second": 12.354,
      "step": 32129
    }
  ],
  "logging_steps": 100,
  "max_steps": 33820,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.771241977248563e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
