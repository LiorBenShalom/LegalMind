{
  "best_metric": 1.2112691402435303,
  "best_model_checkpoint": "./hebert-mlm-3k-drugs/checkpoint-29880",
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 33200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.060240963855421686,
      "grad_norm": 28.933635711669922,
      "learning_rate": 4.984939759036145e-05,
      "loss": 3.0857,
      "step": 100
    },
    {
      "epoch": 0.12048192771084337,
      "grad_norm": 14.935935020446777,
      "learning_rate": 4.9698795180722894e-05,
      "loss": 2.8122,
      "step": 200
    },
    {
      "epoch": 0.18072289156626506,
      "grad_norm": 11.768684387207031,
      "learning_rate": 4.954819277108434e-05,
      "loss": 2.7373,
      "step": 300
    },
    {
      "epoch": 0.24096385542168675,
      "grad_norm": 10.934419631958008,
      "learning_rate": 4.9397590361445786e-05,
      "loss": 2.6487,
      "step": 400
    },
    {
      "epoch": 0.30120481927710846,
      "grad_norm": 13.818534851074219,
      "learning_rate": 4.924698795180723e-05,
      "loss": 2.7155,
      "step": 500
    },
    {
      "epoch": 0.3614457831325301,
      "grad_norm": 17.007564544677734,
      "learning_rate": 4.909638554216868e-05,
      "loss": 2.4771,
      "step": 600
    },
    {
      "epoch": 0.42168674698795183,
      "grad_norm": 12.18505573272705,
      "learning_rate": 4.8945783132530124e-05,
      "loss": 2.3387,
      "step": 700
    },
    {
      "epoch": 0.4819277108433735,
      "grad_norm": 11.202829360961914,
      "learning_rate": 4.879518072289157e-05,
      "loss": 2.3585,
      "step": 800
    },
    {
      "epoch": 0.5421686746987951,
      "grad_norm": 25.389890670776367,
      "learning_rate": 4.8644578313253016e-05,
      "loss": 2.5505,
      "step": 900
    },
    {
      "epoch": 0.6024096385542169,
      "grad_norm": 15.355973243713379,
      "learning_rate": 4.8493975903614455e-05,
      "loss": 2.5275,
      "step": 1000
    },
    {
      "epoch": 0.6626506024096386,
      "grad_norm": 27.08936309814453,
      "learning_rate": 4.834337349397591e-05,
      "loss": 2.2843,
      "step": 1100
    },
    {
      "epoch": 0.7228915662650602,
      "grad_norm": 15.69882869720459,
      "learning_rate": 4.8192771084337354e-05,
      "loss": 2.3945,
      "step": 1200
    },
    {
      "epoch": 0.7831325301204819,
      "grad_norm": 15.259096145629883,
      "learning_rate": 4.804216867469879e-05,
      "loss": 2.3189,
      "step": 1300
    },
    {
      "epoch": 0.8433734939759037,
      "grad_norm": 12.28947925567627,
      "learning_rate": 4.7891566265060246e-05,
      "loss": 2.4483,
      "step": 1400
    },
    {
      "epoch": 0.9036144578313253,
      "grad_norm": 11.717093467712402,
      "learning_rate": 4.774096385542169e-05,
      "loss": 2.4335,
      "step": 1500
    },
    {
      "epoch": 0.963855421686747,
      "grad_norm": 21.828516006469727,
      "learning_rate": 4.759036144578313e-05,
      "loss": 2.2486,
      "step": 1600
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.051997184753418,
      "eval_runtime": 11.0979,
      "eval_samples_per_second": 157.868,
      "eval_steps_per_second": 19.733,
      "step": 1660
    },
    {
      "epoch": 1.0240963855421688,
      "grad_norm": 12.360569953918457,
      "learning_rate": 4.7439759036144584e-05,
      "loss": 2.3064,
      "step": 1700
    },
    {
      "epoch": 1.0843373493975903,
      "grad_norm": 13.115365982055664,
      "learning_rate": 4.728915662650602e-05,
      "loss": 2.2842,
      "step": 1800
    },
    {
      "epoch": 1.144578313253012,
      "grad_norm": 9.052824020385742,
      "learning_rate": 4.713855421686747e-05,
      "loss": 2.1928,
      "step": 1900
    },
    {
      "epoch": 1.2048192771084336,
      "grad_norm": 9.666767120361328,
      "learning_rate": 4.698795180722892e-05,
      "loss": 2.2131,
      "step": 2000
    },
    {
      "epoch": 1.2650602409638554,
      "grad_norm": 9.596598625183105,
      "learning_rate": 4.683734939759036e-05,
      "loss": 2.3471,
      "step": 2100
    },
    {
      "epoch": 1.3253012048192772,
      "grad_norm": 13.624584197998047,
      "learning_rate": 4.668674698795181e-05,
      "loss": 2.3052,
      "step": 2200
    },
    {
      "epoch": 1.3855421686746987,
      "grad_norm": 10.096691131591797,
      "learning_rate": 4.653614457831326e-05,
      "loss": 2.2908,
      "step": 2300
    },
    {
      "epoch": 1.4457831325301205,
      "grad_norm": 14.103737831115723,
      "learning_rate": 4.63855421686747e-05,
      "loss": 2.3281,
      "step": 2400
    },
    {
      "epoch": 1.5060240963855422,
      "grad_norm": 10.15221118927002,
      "learning_rate": 4.6234939759036145e-05,
      "loss": 2.1989,
      "step": 2500
    },
    {
      "epoch": 1.5662650602409638,
      "grad_norm": 10.242387771606445,
      "learning_rate": 4.608433734939759e-05,
      "loss": 2.0612,
      "step": 2600
    },
    {
      "epoch": 1.6265060240963856,
      "grad_norm": 9.180632591247559,
      "learning_rate": 4.5933734939759037e-05,
      "loss": 2.1026,
      "step": 2700
    },
    {
      "epoch": 1.6867469879518073,
      "grad_norm": 14.776324272155762,
      "learning_rate": 4.578313253012048e-05,
      "loss": 2.0541,
      "step": 2800
    },
    {
      "epoch": 1.7469879518072289,
      "grad_norm": 13.005375862121582,
      "learning_rate": 4.563253012048193e-05,
      "loss": 2.0015,
      "step": 2900
    },
    {
      "epoch": 1.8072289156626506,
      "grad_norm": 18.63397979736328,
      "learning_rate": 4.5481927710843374e-05,
      "loss": 2.0995,
      "step": 3000
    },
    {
      "epoch": 1.8674698795180724,
      "grad_norm": 9.2567777633667,
      "learning_rate": 4.533132530120482e-05,
      "loss": 2.2657,
      "step": 3100
    },
    {
      "epoch": 1.927710843373494,
      "grad_norm": 15.106378555297852,
      "learning_rate": 4.5180722891566266e-05,
      "loss": 2.195,
      "step": 3200
    },
    {
      "epoch": 1.9879518072289155,
      "grad_norm": 9.07999038696289,
      "learning_rate": 4.503012048192771e-05,
      "loss": 2.0619,
      "step": 3300
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.877846598625183,
      "eval_runtime": 11.4228,
      "eval_samples_per_second": 153.378,
      "eval_steps_per_second": 19.172,
      "step": 3320
    },
    {
      "epoch": 2.0481927710843375,
      "grad_norm": 9.173696517944336,
      "learning_rate": 4.487951807228916e-05,
      "loss": 1.881,
      "step": 3400
    },
    {
      "epoch": 2.108433734939759,
      "grad_norm": 16.800621032714844,
      "learning_rate": 4.4728915662650604e-05,
      "loss": 2.1516,
      "step": 3500
    },
    {
      "epoch": 2.1686746987951806,
      "grad_norm": 10.927291870117188,
      "learning_rate": 4.457831325301205e-05,
      "loss": 1.9285,
      "step": 3600
    },
    {
      "epoch": 2.2289156626506026,
      "grad_norm": 8.823811531066895,
      "learning_rate": 4.4427710843373496e-05,
      "loss": 2.1304,
      "step": 3700
    },
    {
      "epoch": 2.289156626506024,
      "grad_norm": 13.52663516998291,
      "learning_rate": 4.427710843373494e-05,
      "loss": 2.2798,
      "step": 3800
    },
    {
      "epoch": 2.3493975903614457,
      "grad_norm": 12.448822021484375,
      "learning_rate": 4.412650602409639e-05,
      "loss": 2.1888,
      "step": 3900
    },
    {
      "epoch": 2.4096385542168672,
      "grad_norm": 11.727936744689941,
      "learning_rate": 4.3975903614457834e-05,
      "loss": 1.9749,
      "step": 4000
    },
    {
      "epoch": 2.4698795180722892,
      "grad_norm": 8.704612731933594,
      "learning_rate": 4.382530120481928e-05,
      "loss": 1.9974,
      "step": 4100
    },
    {
      "epoch": 2.5301204819277108,
      "grad_norm": 10.67055892944336,
      "learning_rate": 4.3674698795180726e-05,
      "loss": 1.9272,
      "step": 4200
    },
    {
      "epoch": 2.5903614457831328,
      "grad_norm": 12.63869857788086,
      "learning_rate": 4.352409638554217e-05,
      "loss": 2.0788,
      "step": 4300
    },
    {
      "epoch": 2.6506024096385543,
      "grad_norm": 8.579427719116211,
      "learning_rate": 4.337349397590362e-05,
      "loss": 2.0286,
      "step": 4400
    },
    {
      "epoch": 2.710843373493976,
      "grad_norm": 8.61453628540039,
      "learning_rate": 4.3222891566265064e-05,
      "loss": 1.7769,
      "step": 4500
    },
    {
      "epoch": 2.7710843373493974,
      "grad_norm": 15.163636207580566,
      "learning_rate": 4.307228915662651e-05,
      "loss": 2.1511,
      "step": 4600
    },
    {
      "epoch": 2.8313253012048194,
      "grad_norm": 11.117581367492676,
      "learning_rate": 4.2921686746987956e-05,
      "loss": 2.1132,
      "step": 4700
    },
    {
      "epoch": 2.891566265060241,
      "grad_norm": 7.0778326988220215,
      "learning_rate": 4.27710843373494e-05,
      "loss": 2.0722,
      "step": 4800
    },
    {
      "epoch": 2.9518072289156625,
      "grad_norm": 9.449246406555176,
      "learning_rate": 4.262048192771085e-05,
      "loss": 2.0213,
      "step": 4900
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.8237007856369019,
      "eval_runtime": 11.3223,
      "eval_samples_per_second": 154.739,
      "eval_steps_per_second": 19.342,
      "step": 4980
    },
    {
      "epoch": 3.0120481927710845,
      "grad_norm": 9.201896667480469,
      "learning_rate": 4.2469879518072294e-05,
      "loss": 2.0284,
      "step": 5000
    },
    {
      "epoch": 3.072289156626506,
      "grad_norm": 9.306723594665527,
      "learning_rate": 4.231927710843373e-05,
      "loss": 2.0109,
      "step": 5100
    },
    {
      "epoch": 3.1325301204819276,
      "grad_norm": 8.863977432250977,
      "learning_rate": 4.2168674698795186e-05,
      "loss": 2.0863,
      "step": 5200
    },
    {
      "epoch": 3.1927710843373496,
      "grad_norm": 9.857525825500488,
      "learning_rate": 4.201807228915663e-05,
      "loss": 1.7842,
      "step": 5300
    },
    {
      "epoch": 3.253012048192771,
      "grad_norm": 12.80846881866455,
      "learning_rate": 4.186746987951807e-05,
      "loss": 1.9295,
      "step": 5400
    },
    {
      "epoch": 3.3132530120481927,
      "grad_norm": 13.553756713867188,
      "learning_rate": 4.1716867469879523e-05,
      "loss": 2.0341,
      "step": 5500
    },
    {
      "epoch": 3.3734939759036147,
      "grad_norm": 7.2691450119018555,
      "learning_rate": 4.156626506024097e-05,
      "loss": 2.0326,
      "step": 5600
    },
    {
      "epoch": 3.433734939759036,
      "grad_norm": 10.084355354309082,
      "learning_rate": 4.141566265060241e-05,
      "loss": 1.8187,
      "step": 5700
    },
    {
      "epoch": 3.4939759036144578,
      "grad_norm": 8.992067337036133,
      "learning_rate": 4.126506024096386e-05,
      "loss": 1.9109,
      "step": 5800
    },
    {
      "epoch": 3.5542168674698793,
      "grad_norm": 16.301673889160156,
      "learning_rate": 4.11144578313253e-05,
      "loss": 2.0996,
      "step": 5900
    },
    {
      "epoch": 3.6144578313253013,
      "grad_norm": 8.195664405822754,
      "learning_rate": 4.0963855421686746e-05,
      "loss": 1.9688,
      "step": 6000
    },
    {
      "epoch": 3.674698795180723,
      "grad_norm": 11.494913101196289,
      "learning_rate": 4.08132530120482e-05,
      "loss": 1.9315,
      "step": 6100
    },
    {
      "epoch": 3.734939759036145,
      "grad_norm": 10.46191692352295,
      "learning_rate": 4.066265060240964e-05,
      "loss": 1.9221,
      "step": 6200
    },
    {
      "epoch": 3.7951807228915664,
      "grad_norm": 9.966053009033203,
      "learning_rate": 4.0512048192771084e-05,
      "loss": 1.9255,
      "step": 6300
    },
    {
      "epoch": 3.855421686746988,
      "grad_norm": 14.372452735900879,
      "learning_rate": 4.036144578313254e-05,
      "loss": 1.9258,
      "step": 6400
    },
    {
      "epoch": 3.9156626506024095,
      "grad_norm": 13.894421577453613,
      "learning_rate": 4.0210843373493976e-05,
      "loss": 1.7829,
      "step": 6500
    },
    {
      "epoch": 3.9759036144578315,
      "grad_norm": 13.60411262512207,
      "learning_rate": 4.006024096385542e-05,
      "loss": 2.0018,
      "step": 6600
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.7358434200286865,
      "eval_runtime": 11.2926,
      "eval_samples_per_second": 155.146,
      "eval_steps_per_second": 19.393,
      "step": 6640
    },
    {
      "epoch": 4.036144578313253,
      "grad_norm": 12.974654197692871,
      "learning_rate": 3.9909638554216875e-05,
      "loss": 1.9098,
      "step": 6700
    },
    {
      "epoch": 4.096385542168675,
      "grad_norm": 12.297069549560547,
      "learning_rate": 3.9759036144578314e-05,
      "loss": 1.8023,
      "step": 6800
    },
    {
      "epoch": 4.156626506024097,
      "grad_norm": 14.416407585144043,
      "learning_rate": 3.960843373493976e-05,
      "loss": 1.8683,
      "step": 6900
    },
    {
      "epoch": 4.216867469879518,
      "grad_norm": 9.453887939453125,
      "learning_rate": 3.9457831325301206e-05,
      "loss": 1.7555,
      "step": 7000
    },
    {
      "epoch": 4.27710843373494,
      "grad_norm": 13.100165367126465,
      "learning_rate": 3.930722891566265e-05,
      "loss": 1.7378,
      "step": 7100
    },
    {
      "epoch": 4.337349397590361,
      "grad_norm": 9.170035362243652,
      "learning_rate": 3.91566265060241e-05,
      "loss": 1.7086,
      "step": 7200
    },
    {
      "epoch": 4.397590361445783,
      "grad_norm": 10.296388626098633,
      "learning_rate": 3.9006024096385544e-05,
      "loss": 1.7103,
      "step": 7300
    },
    {
      "epoch": 4.457831325301205,
      "grad_norm": 15.319788932800293,
      "learning_rate": 3.885542168674699e-05,
      "loss": 1.6796,
      "step": 7400
    },
    {
      "epoch": 4.518072289156627,
      "grad_norm": 9.869747161865234,
      "learning_rate": 3.8704819277108436e-05,
      "loss": 1.7866,
      "step": 7500
    },
    {
      "epoch": 4.578313253012048,
      "grad_norm": 12.082571983337402,
      "learning_rate": 3.855421686746988e-05,
      "loss": 1.8185,
      "step": 7600
    },
    {
      "epoch": 4.63855421686747,
      "grad_norm": 15.896597862243652,
      "learning_rate": 3.840361445783133e-05,
      "loss": 1.8585,
      "step": 7700
    },
    {
      "epoch": 4.698795180722891,
      "grad_norm": 28.280805587768555,
      "learning_rate": 3.8253012048192774e-05,
      "loss": 1.5909,
      "step": 7800
    },
    {
      "epoch": 4.759036144578313,
      "grad_norm": 17.74687957763672,
      "learning_rate": 3.810240963855422e-05,
      "loss": 1.6391,
      "step": 7900
    },
    {
      "epoch": 4.8192771084337345,
      "grad_norm": 13.179413795471191,
      "learning_rate": 3.7951807228915666e-05,
      "loss": 1.7113,
      "step": 8000
    },
    {
      "epoch": 4.879518072289157,
      "grad_norm": 16.63109016418457,
      "learning_rate": 3.780120481927711e-05,
      "loss": 1.8335,
      "step": 8100
    },
    {
      "epoch": 4.9397590361445785,
      "grad_norm": 9.811738014221191,
      "learning_rate": 3.765060240963856e-05,
      "loss": 1.7725,
      "step": 8200
    },
    {
      "epoch": 5.0,
      "grad_norm": 6.602686882019043,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.8289,
      "step": 8300
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.6335326433181763,
      "eval_runtime": 11.3993,
      "eval_samples_per_second": 153.694,
      "eval_steps_per_second": 19.212,
      "step": 8300
    },
    {
      "epoch": 5.0602409638554215,
      "grad_norm": 18.48902702331543,
      "learning_rate": 3.734939759036144e-05,
      "loss": 1.5587,
      "step": 8400
    },
    {
      "epoch": 5.120481927710843,
      "grad_norm": 14.65427303314209,
      "learning_rate": 3.7198795180722895e-05,
      "loss": 1.5918,
      "step": 8500
    },
    {
      "epoch": 5.180722891566265,
      "grad_norm": 9.68189525604248,
      "learning_rate": 3.704819277108434e-05,
      "loss": 1.5175,
      "step": 8600
    },
    {
      "epoch": 5.240963855421687,
      "grad_norm": 17.23786163330078,
      "learning_rate": 3.689759036144578e-05,
      "loss": 1.7319,
      "step": 8700
    },
    {
      "epoch": 5.301204819277109,
      "grad_norm": 11.7000732421875,
      "learning_rate": 3.674698795180723e-05,
      "loss": 1.5835,
      "step": 8800
    },
    {
      "epoch": 5.36144578313253,
      "grad_norm": 14.141972541809082,
      "learning_rate": 3.659638554216868e-05,
      "loss": 1.6795,
      "step": 8900
    },
    {
      "epoch": 5.421686746987952,
      "grad_norm": 9.759533882141113,
      "learning_rate": 3.644578313253012e-05,
      "loss": 1.7765,
      "step": 9000
    },
    {
      "epoch": 5.481927710843373,
      "grad_norm": 15.48832893371582,
      "learning_rate": 3.629518072289157e-05,
      "loss": 1.5856,
      "step": 9100
    },
    {
      "epoch": 5.542168674698795,
      "grad_norm": 14.641043663024902,
      "learning_rate": 3.614457831325301e-05,
      "loss": 1.6983,
      "step": 9200
    },
    {
      "epoch": 5.602409638554217,
      "grad_norm": 9.530623435974121,
      "learning_rate": 3.5993975903614456e-05,
      "loss": 1.5043,
      "step": 9300
    },
    {
      "epoch": 5.662650602409639,
      "grad_norm": 11.244812965393066,
      "learning_rate": 3.584337349397591e-05,
      "loss": 1.6332,
      "step": 9400
    },
    {
      "epoch": 5.72289156626506,
      "grad_norm": 15.62564468383789,
      "learning_rate": 3.569277108433735e-05,
      "loss": 1.491,
      "step": 9500
    },
    {
      "epoch": 5.783132530120482,
      "grad_norm": 10.549548149108887,
      "learning_rate": 3.5542168674698794e-05,
      "loss": 1.4605,
      "step": 9600
    },
    {
      "epoch": 5.843373493975903,
      "grad_norm": 9.955592155456543,
      "learning_rate": 3.539156626506025e-05,
      "loss": 1.6365,
      "step": 9700
    },
    {
      "epoch": 5.903614457831325,
      "grad_norm": 11.588690757751465,
      "learning_rate": 3.5240963855421686e-05,
      "loss": 1.5964,
      "step": 9800
    },
    {
      "epoch": 5.9638554216867465,
      "grad_norm": 12.48564624786377,
      "learning_rate": 3.509036144578313e-05,
      "loss": 1.6654,
      "step": 9900
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.5032378435134888,
      "eval_runtime": 11.3579,
      "eval_samples_per_second": 154.253,
      "eval_steps_per_second": 19.282,
      "step": 9960
    },
    {
      "epoch": 6.024096385542169,
      "grad_norm": 19.7486515045166,
      "learning_rate": 3.4939759036144585e-05,
      "loss": 1.4084,
      "step": 10000
    },
    {
      "epoch": 6.0843373493975905,
      "grad_norm": 17.985260009765625,
      "learning_rate": 3.4789156626506024e-05,
      "loss": 1.657,
      "step": 10100
    },
    {
      "epoch": 6.144578313253012,
      "grad_norm": 64.9218978881836,
      "learning_rate": 3.463855421686747e-05,
      "loss": 1.5403,
      "step": 10200
    },
    {
      "epoch": 6.204819277108434,
      "grad_norm": 18.071834564208984,
      "learning_rate": 3.4487951807228916e-05,
      "loss": 1.5316,
      "step": 10300
    },
    {
      "epoch": 6.265060240963855,
      "grad_norm": 15.38783073425293,
      "learning_rate": 3.433734939759036e-05,
      "loss": 1.4527,
      "step": 10400
    },
    {
      "epoch": 6.325301204819277,
      "grad_norm": 17.156309127807617,
      "learning_rate": 3.418674698795181e-05,
      "loss": 1.5789,
      "step": 10500
    },
    {
      "epoch": 6.385542168674699,
      "grad_norm": 11.39363956451416,
      "learning_rate": 3.4036144578313254e-05,
      "loss": 1.479,
      "step": 10600
    },
    {
      "epoch": 6.445783132530121,
      "grad_norm": 10.872298240661621,
      "learning_rate": 3.38855421686747e-05,
      "loss": 1.5959,
      "step": 10700
    },
    {
      "epoch": 6.506024096385542,
      "grad_norm": 12.718156814575195,
      "learning_rate": 3.3734939759036146e-05,
      "loss": 1.3448,
      "step": 10800
    },
    {
      "epoch": 6.566265060240964,
      "grad_norm": 12.404745101928711,
      "learning_rate": 3.358433734939759e-05,
      "loss": 1.4738,
      "step": 10900
    },
    {
      "epoch": 6.626506024096385,
      "grad_norm": 15.985270500183105,
      "learning_rate": 3.343373493975904e-05,
      "loss": 1.4862,
      "step": 11000
    },
    {
      "epoch": 6.686746987951807,
      "grad_norm": 9.7705717086792,
      "learning_rate": 3.3283132530120484e-05,
      "loss": 1.4686,
      "step": 11100
    },
    {
      "epoch": 6.746987951807229,
      "grad_norm": 11.564517974853516,
      "learning_rate": 3.313253012048193e-05,
      "loss": 1.4413,
      "step": 11200
    },
    {
      "epoch": 6.807228915662651,
      "grad_norm": 9.479694366455078,
      "learning_rate": 3.2981927710843376e-05,
      "loss": 1.3757,
      "step": 11300
    },
    {
      "epoch": 6.867469879518072,
      "grad_norm": 14.673465728759766,
      "learning_rate": 3.283132530120482e-05,
      "loss": 1.4969,
      "step": 11400
    },
    {
      "epoch": 6.927710843373494,
      "grad_norm": 11.105268478393555,
      "learning_rate": 3.268072289156627e-05,
      "loss": 1.4102,
      "step": 11500
    },
    {
      "epoch": 6.9879518072289155,
      "grad_norm": 14.122148513793945,
      "learning_rate": 3.253012048192771e-05,
      "loss": 1.3636,
      "step": 11600
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.4501343965530396,
      "eval_runtime": 11.3875,
      "eval_samples_per_second": 153.853,
      "eval_steps_per_second": 19.232,
      "step": 11620
    },
    {
      "epoch": 7.048192771084337,
      "grad_norm": 11.752198219299316,
      "learning_rate": 3.237951807228915e-05,
      "loss": 1.4791,
      "step": 11700
    },
    {
      "epoch": 7.108433734939759,
      "grad_norm": 10.282132148742676,
      "learning_rate": 3.2228915662650605e-05,
      "loss": 1.254,
      "step": 11800
    },
    {
      "epoch": 7.168674698795181,
      "grad_norm": 8.556117057800293,
      "learning_rate": 3.207831325301205e-05,
      "loss": 1.4138,
      "step": 11900
    },
    {
      "epoch": 7.228915662650603,
      "grad_norm": 7.7907023429870605,
      "learning_rate": 3.192771084337349e-05,
      "loss": 1.4502,
      "step": 12000
    },
    {
      "epoch": 7.289156626506024,
      "grad_norm": 11.813681602478027,
      "learning_rate": 3.177710843373494e-05,
      "loss": 1.3514,
      "step": 12100
    },
    {
      "epoch": 7.349397590361446,
      "grad_norm": 11.132240295410156,
      "learning_rate": 3.162650602409639e-05,
      "loss": 1.3042,
      "step": 12200
    },
    {
      "epoch": 7.409638554216867,
      "grad_norm": 14.963016510009766,
      "learning_rate": 3.147590361445783e-05,
      "loss": 1.3528,
      "step": 12300
    },
    {
      "epoch": 7.469879518072289,
      "grad_norm": 12.805548667907715,
      "learning_rate": 3.132530120481928e-05,
      "loss": 1.4289,
      "step": 12400
    },
    {
      "epoch": 7.530120481927711,
      "grad_norm": 11.272311210632324,
      "learning_rate": 3.117469879518072e-05,
      "loss": 1.472,
      "step": 12500
    },
    {
      "epoch": 7.590361445783133,
      "grad_norm": 11.962569236755371,
      "learning_rate": 3.102409638554217e-05,
      "loss": 1.4174,
      "step": 12600
    },
    {
      "epoch": 7.650602409638554,
      "grad_norm": 5.944775104522705,
      "learning_rate": 3.087349397590362e-05,
      "loss": 1.3821,
      "step": 12700
    },
    {
      "epoch": 7.710843373493976,
      "grad_norm": 12.201842308044434,
      "learning_rate": 3.072289156626506e-05,
      "loss": 1.4039,
      "step": 12800
    },
    {
      "epoch": 7.771084337349397,
      "grad_norm": 10.036520957946777,
      "learning_rate": 3.057228915662651e-05,
      "loss": 1.5097,
      "step": 12900
    },
    {
      "epoch": 7.831325301204819,
      "grad_norm": 15.294747352600098,
      "learning_rate": 3.0421686746987953e-05,
      "loss": 1.4186,
      "step": 13000
    },
    {
      "epoch": 7.891566265060241,
      "grad_norm": 10.1000337600708,
      "learning_rate": 3.02710843373494e-05,
      "loss": 1.4828,
      "step": 13100
    },
    {
      "epoch": 7.951807228915663,
      "grad_norm": 11.080130577087402,
      "learning_rate": 3.012048192771085e-05,
      "loss": 1.3529,
      "step": 13200
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.3938015699386597,
      "eval_runtime": 11.3823,
      "eval_samples_per_second": 153.923,
      "eval_steps_per_second": 19.24,
      "step": 13280
    },
    {
      "epoch": 8.012048192771084,
      "grad_norm": 21.008869171142578,
      "learning_rate": 2.996987951807229e-05,
      "loss": 1.4411,
      "step": 13300
    },
    {
      "epoch": 8.072289156626505,
      "grad_norm": 10.383241653442383,
      "learning_rate": 2.9819277108433734e-05,
      "loss": 1.2509,
      "step": 13400
    },
    {
      "epoch": 8.132530120481928,
      "grad_norm": 8.569910049438477,
      "learning_rate": 2.9668674698795183e-05,
      "loss": 1.423,
      "step": 13500
    },
    {
      "epoch": 8.19277108433735,
      "grad_norm": 10.418980598449707,
      "learning_rate": 2.951807228915663e-05,
      "loss": 1.3344,
      "step": 13600
    },
    {
      "epoch": 8.25301204819277,
      "grad_norm": 7.6838226318359375,
      "learning_rate": 2.9367469879518072e-05,
      "loss": 1.439,
      "step": 13700
    },
    {
      "epoch": 8.313253012048193,
      "grad_norm": 11.086836814880371,
      "learning_rate": 2.921686746987952e-05,
      "loss": 1.533,
      "step": 13800
    },
    {
      "epoch": 8.373493975903614,
      "grad_norm": 10.093668937683105,
      "learning_rate": 2.9066265060240967e-05,
      "loss": 1.274,
      "step": 13900
    },
    {
      "epoch": 8.433734939759036,
      "grad_norm": 22.526185989379883,
      "learning_rate": 2.891566265060241e-05,
      "loss": 1.2318,
      "step": 14000
    },
    {
      "epoch": 8.493975903614459,
      "grad_norm": 11.227142333984375,
      "learning_rate": 2.876506024096386e-05,
      "loss": 1.3555,
      "step": 14100
    },
    {
      "epoch": 8.55421686746988,
      "grad_norm": 11.270291328430176,
      "learning_rate": 2.86144578313253e-05,
      "loss": 1.3689,
      "step": 14200
    },
    {
      "epoch": 8.614457831325302,
      "grad_norm": 11.621393203735352,
      "learning_rate": 2.8463855421686748e-05,
      "loss": 1.25,
      "step": 14300
    },
    {
      "epoch": 8.674698795180722,
      "grad_norm": 11.599798202514648,
      "learning_rate": 2.8313253012048197e-05,
      "loss": 1.3667,
      "step": 14400
    },
    {
      "epoch": 8.734939759036145,
      "grad_norm": 15.827962875366211,
      "learning_rate": 2.816265060240964e-05,
      "loss": 1.3459,
      "step": 14500
    },
    {
      "epoch": 8.795180722891565,
      "grad_norm": 8.4318208694458,
      "learning_rate": 2.8012048192771085e-05,
      "loss": 1.298,
      "step": 14600
    },
    {
      "epoch": 8.855421686746988,
      "grad_norm": 12.372626304626465,
      "learning_rate": 2.7861445783132535e-05,
      "loss": 1.39,
      "step": 14700
    },
    {
      "epoch": 8.91566265060241,
      "grad_norm": 8.125541687011719,
      "learning_rate": 2.7710843373493977e-05,
      "loss": 1.2506,
      "step": 14800
    },
    {
      "epoch": 8.975903614457831,
      "grad_norm": 12.88272762298584,
      "learning_rate": 2.756024096385542e-05,
      "loss": 1.2836,
      "step": 14900
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.4289798736572266,
      "eval_runtime": 11.347,
      "eval_samples_per_second": 154.402,
      "eval_steps_per_second": 19.3,
      "step": 14940
    },
    {
      "epoch": 9.036144578313253,
      "grad_norm": 10.552845001220703,
      "learning_rate": 2.7409638554216873e-05,
      "loss": 1.3776,
      "step": 15000
    },
    {
      "epoch": 9.096385542168674,
      "grad_norm": 23.88954734802246,
      "learning_rate": 2.7259036144578315e-05,
      "loss": 1.3754,
      "step": 15100
    },
    {
      "epoch": 9.156626506024097,
      "grad_norm": 11.470412254333496,
      "learning_rate": 2.7108433734939758e-05,
      "loss": 1.2734,
      "step": 15200
    },
    {
      "epoch": 9.216867469879517,
      "grad_norm": 7.7690534591674805,
      "learning_rate": 2.6957831325301207e-05,
      "loss": 1.3126,
      "step": 15300
    },
    {
      "epoch": 9.27710843373494,
      "grad_norm": 9.873538970947266,
      "learning_rate": 2.6807228915662653e-05,
      "loss": 1.2444,
      "step": 15400
    },
    {
      "epoch": 9.337349397590362,
      "grad_norm": 12.724671363830566,
      "learning_rate": 2.6656626506024096e-05,
      "loss": 1.2599,
      "step": 15500
    },
    {
      "epoch": 9.397590361445783,
      "grad_norm": 12.066143989562988,
      "learning_rate": 2.6506024096385545e-05,
      "loss": 1.3983,
      "step": 15600
    },
    {
      "epoch": 9.457831325301205,
      "grad_norm": 20.180023193359375,
      "learning_rate": 2.635542168674699e-05,
      "loss": 1.1637,
      "step": 15700
    },
    {
      "epoch": 9.518072289156626,
      "grad_norm": 12.861213684082031,
      "learning_rate": 2.6204819277108434e-05,
      "loss": 1.1891,
      "step": 15800
    },
    {
      "epoch": 9.578313253012048,
      "grad_norm": 16.292415618896484,
      "learning_rate": 2.6054216867469883e-05,
      "loss": 1.1817,
      "step": 15900
    },
    {
      "epoch": 9.638554216867469,
      "grad_norm": 22.94566535949707,
      "learning_rate": 2.5903614457831325e-05,
      "loss": 1.2492,
      "step": 16000
    },
    {
      "epoch": 9.698795180722891,
      "grad_norm": 11.102869987487793,
      "learning_rate": 2.575301204819277e-05,
      "loss": 1.2799,
      "step": 16100
    },
    {
      "epoch": 9.759036144578314,
      "grad_norm": 11.77105712890625,
      "learning_rate": 2.560240963855422e-05,
      "loss": 1.173,
      "step": 16200
    },
    {
      "epoch": 9.819277108433734,
      "grad_norm": 20.022459030151367,
      "learning_rate": 2.5451807228915663e-05,
      "loss": 1.2207,
      "step": 16300
    },
    {
      "epoch": 9.879518072289157,
      "grad_norm": 9.913677215576172,
      "learning_rate": 2.530120481927711e-05,
      "loss": 1.257,
      "step": 16400
    },
    {
      "epoch": 9.939759036144578,
      "grad_norm": 12.063939094543457,
      "learning_rate": 2.515060240963856e-05,
      "loss": 1.2964,
      "step": 16500
    },
    {
      "epoch": 10.0,
      "grad_norm": 8.951476097106934,
      "learning_rate": 2.5e-05,
      "loss": 1.2387,
      "step": 16600
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.3861788511276245,
      "eval_runtime": 11.3492,
      "eval_samples_per_second": 154.372,
      "eval_steps_per_second": 19.297,
      "step": 16600
    },
    {
      "epoch": 10.060240963855422,
      "grad_norm": 14.363774299621582,
      "learning_rate": 2.4849397590361447e-05,
      "loss": 1.2148,
      "step": 16700
    },
    {
      "epoch": 10.120481927710843,
      "grad_norm": 11.544727325439453,
      "learning_rate": 2.4698795180722893e-05,
      "loss": 1.2163,
      "step": 16800
    },
    {
      "epoch": 10.180722891566266,
      "grad_norm": 9.617605209350586,
      "learning_rate": 2.454819277108434e-05,
      "loss": 1.2506,
      "step": 16900
    },
    {
      "epoch": 10.240963855421686,
      "grad_norm": 18.351829528808594,
      "learning_rate": 2.4397590361445785e-05,
      "loss": 1.1822,
      "step": 17000
    },
    {
      "epoch": 10.301204819277109,
      "grad_norm": 13.121030807495117,
      "learning_rate": 2.4246987951807228e-05,
      "loss": 1.1228,
      "step": 17100
    },
    {
      "epoch": 10.36144578313253,
      "grad_norm": 9.531158447265625,
      "learning_rate": 2.4096385542168677e-05,
      "loss": 1.199,
      "step": 17200
    },
    {
      "epoch": 10.421686746987952,
      "grad_norm": 10.535569190979004,
      "learning_rate": 2.3945783132530123e-05,
      "loss": 1.2232,
      "step": 17300
    },
    {
      "epoch": 10.481927710843374,
      "grad_norm": 12.721637725830078,
      "learning_rate": 2.3795180722891565e-05,
      "loss": 1.1949,
      "step": 17400
    },
    {
      "epoch": 10.542168674698795,
      "grad_norm": 10.206429481506348,
      "learning_rate": 2.364457831325301e-05,
      "loss": 1.2739,
      "step": 17500
    },
    {
      "epoch": 10.602409638554217,
      "grad_norm": 12.536561012268066,
      "learning_rate": 2.349397590361446e-05,
      "loss": 1.2913,
      "step": 17600
    },
    {
      "epoch": 10.662650602409638,
      "grad_norm": 10.108543395996094,
      "learning_rate": 2.3343373493975903e-05,
      "loss": 1.2312,
      "step": 17700
    },
    {
      "epoch": 10.72289156626506,
      "grad_norm": 8.800677299499512,
      "learning_rate": 2.319277108433735e-05,
      "loss": 1.261,
      "step": 17800
    },
    {
      "epoch": 10.783132530120483,
      "grad_norm": 14.488253593444824,
      "learning_rate": 2.3042168674698795e-05,
      "loss": 1.2391,
      "step": 17900
    },
    {
      "epoch": 10.843373493975903,
      "grad_norm": 8.705944061279297,
      "learning_rate": 2.289156626506024e-05,
      "loss": 1.1804,
      "step": 18000
    },
    {
      "epoch": 10.903614457831326,
      "grad_norm": 12.08498764038086,
      "learning_rate": 2.2740963855421687e-05,
      "loss": 1.2507,
      "step": 18100
    },
    {
      "epoch": 10.963855421686747,
      "grad_norm": 19.188106536865234,
      "learning_rate": 2.2590361445783133e-05,
      "loss": 1.2565,
      "step": 18200
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.3607308864593506,
      "eval_runtime": 11.4062,
      "eval_samples_per_second": 153.601,
      "eval_steps_per_second": 19.2,
      "step": 18260
    },
    {
      "epoch": 11.024096385542169,
      "grad_norm": 11.430047035217285,
      "learning_rate": 2.243975903614458e-05,
      "loss": 1.1766,
      "step": 18300
    },
    {
      "epoch": 11.08433734939759,
      "grad_norm": 11.373278617858887,
      "learning_rate": 2.2289156626506025e-05,
      "loss": 1.2337,
      "step": 18400
    },
    {
      "epoch": 11.144578313253012,
      "grad_norm": 15.047148704528809,
      "learning_rate": 2.213855421686747e-05,
      "loss": 1.1296,
      "step": 18500
    },
    {
      "epoch": 11.204819277108435,
      "grad_norm": 10.538644790649414,
      "learning_rate": 2.1987951807228917e-05,
      "loss": 1.1366,
      "step": 18600
    },
    {
      "epoch": 11.265060240963855,
      "grad_norm": 10.448634147644043,
      "learning_rate": 2.1837349397590363e-05,
      "loss": 1.1152,
      "step": 18700
    },
    {
      "epoch": 11.325301204819278,
      "grad_norm": 13.68704605102539,
      "learning_rate": 2.168674698795181e-05,
      "loss": 1.1109,
      "step": 18800
    },
    {
      "epoch": 11.385542168674698,
      "grad_norm": 13.066086769104004,
      "learning_rate": 2.1536144578313255e-05,
      "loss": 1.2895,
      "step": 18900
    },
    {
      "epoch": 11.44578313253012,
      "grad_norm": 12.866724967956543,
      "learning_rate": 2.13855421686747e-05,
      "loss": 1.2311,
      "step": 19000
    },
    {
      "epoch": 11.506024096385541,
      "grad_norm": 12.817682266235352,
      "learning_rate": 2.1234939759036147e-05,
      "loss": 1.0472,
      "step": 19100
    },
    {
      "epoch": 11.566265060240964,
      "grad_norm": 12.746133804321289,
      "learning_rate": 2.1084337349397593e-05,
      "loss": 1.17,
      "step": 19200
    },
    {
      "epoch": 11.626506024096386,
      "grad_norm": 10.369388580322266,
      "learning_rate": 2.0933734939759035e-05,
      "loss": 1.1709,
      "step": 19300
    },
    {
      "epoch": 11.686746987951807,
      "grad_norm": 7.8968305587768555,
      "learning_rate": 2.0783132530120485e-05,
      "loss": 1.171,
      "step": 19400
    },
    {
      "epoch": 11.74698795180723,
      "grad_norm": 12.812141418457031,
      "learning_rate": 2.063253012048193e-05,
      "loss": 1.1621,
      "step": 19500
    },
    {
      "epoch": 11.80722891566265,
      "grad_norm": 10.340561866760254,
      "learning_rate": 2.0481927710843373e-05,
      "loss": 1.1619,
      "step": 19600
    },
    {
      "epoch": 11.867469879518072,
      "grad_norm": 10.079941749572754,
      "learning_rate": 2.033132530120482e-05,
      "loss": 1.0876,
      "step": 19700
    },
    {
      "epoch": 11.927710843373493,
      "grad_norm": 11.732240676879883,
      "learning_rate": 2.018072289156627e-05,
      "loss": 1.1816,
      "step": 19800
    },
    {
      "epoch": 11.987951807228916,
      "grad_norm": 7.403336048126221,
      "learning_rate": 2.003012048192771e-05,
      "loss": 1.1365,
      "step": 19900
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.3579391241073608,
      "eval_runtime": 11.3672,
      "eval_samples_per_second": 154.127,
      "eval_steps_per_second": 19.266,
      "step": 19920
    },
    {
      "epoch": 12.048192771084338,
      "grad_norm": 14.382280349731445,
      "learning_rate": 1.9879518072289157e-05,
      "loss": 0.9954,
      "step": 20000
    },
    {
      "epoch": 12.108433734939759,
      "grad_norm": 11.834844589233398,
      "learning_rate": 1.9728915662650603e-05,
      "loss": 1.1092,
      "step": 20100
    },
    {
      "epoch": 12.168674698795181,
      "grad_norm": 18.390636444091797,
      "learning_rate": 1.957831325301205e-05,
      "loss": 1.0981,
      "step": 20200
    },
    {
      "epoch": 12.228915662650602,
      "grad_norm": 8.512686729431152,
      "learning_rate": 1.9427710843373495e-05,
      "loss": 1.1334,
      "step": 20300
    },
    {
      "epoch": 12.289156626506024,
      "grad_norm": 12.758221626281738,
      "learning_rate": 1.927710843373494e-05,
      "loss": 1.1305,
      "step": 20400
    },
    {
      "epoch": 12.349397590361447,
      "grad_norm": 14.011373519897461,
      "learning_rate": 1.9126506024096387e-05,
      "loss": 1.1125,
      "step": 20500
    },
    {
      "epoch": 12.409638554216867,
      "grad_norm": 13.368366241455078,
      "learning_rate": 1.8975903614457833e-05,
      "loss": 1.1024,
      "step": 20600
    },
    {
      "epoch": 12.46987951807229,
      "grad_norm": 10.231287956237793,
      "learning_rate": 1.882530120481928e-05,
      "loss": 1.1464,
      "step": 20700
    },
    {
      "epoch": 12.53012048192771,
      "grad_norm": 10.385316848754883,
      "learning_rate": 1.867469879518072e-05,
      "loss": 1.1346,
      "step": 20800
    },
    {
      "epoch": 12.590361445783133,
      "grad_norm": 9.355488777160645,
      "learning_rate": 1.852409638554217e-05,
      "loss": 1.1349,
      "step": 20900
    },
    {
      "epoch": 12.650602409638553,
      "grad_norm": 10.312233924865723,
      "learning_rate": 1.8373493975903617e-05,
      "loss": 1.2255,
      "step": 21000
    },
    {
      "epoch": 12.710843373493976,
      "grad_norm": 11.611814498901367,
      "learning_rate": 1.822289156626506e-05,
      "loss": 1.0606,
      "step": 21100
    },
    {
      "epoch": 12.771084337349398,
      "grad_norm": 12.441028594970703,
      "learning_rate": 1.8072289156626505e-05,
      "loss": 1.1469,
      "step": 21200
    },
    {
      "epoch": 12.831325301204819,
      "grad_norm": 8.98608684539795,
      "learning_rate": 1.7921686746987955e-05,
      "loss": 1.107,
      "step": 21300
    },
    {
      "epoch": 12.891566265060241,
      "grad_norm": 13.582423210144043,
      "learning_rate": 1.7771084337349397e-05,
      "loss": 1.0636,
      "step": 21400
    },
    {
      "epoch": 12.951807228915662,
      "grad_norm": 12.650341033935547,
      "learning_rate": 1.7620481927710843e-05,
      "loss": 1.1956,
      "step": 21500
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.3200454711914062,
      "eval_runtime": 11.3359,
      "eval_samples_per_second": 154.554,
      "eval_steps_per_second": 19.319,
      "step": 21580
    },
    {
      "epoch": 13.012048192771084,
      "grad_norm": 11.300423622131348,
      "learning_rate": 1.7469879518072292e-05,
      "loss": 1.0744,
      "step": 21600
    },
    {
      "epoch": 13.072289156626505,
      "grad_norm": 12.582840919494629,
      "learning_rate": 1.7319277108433735e-05,
      "loss": 1.1027,
      "step": 21700
    },
    {
      "epoch": 13.132530120481928,
      "grad_norm": 9.820621490478516,
      "learning_rate": 1.716867469879518e-05,
      "loss": 1.1481,
      "step": 21800
    },
    {
      "epoch": 13.19277108433735,
      "grad_norm": 9.921083450317383,
      "learning_rate": 1.7018072289156627e-05,
      "loss": 1.1077,
      "step": 21900
    },
    {
      "epoch": 13.25301204819277,
      "grad_norm": 11.326681137084961,
      "learning_rate": 1.6867469879518073e-05,
      "loss": 1.0287,
      "step": 22000
    },
    {
      "epoch": 13.313253012048193,
      "grad_norm": 13.990468978881836,
      "learning_rate": 1.671686746987952e-05,
      "loss": 1.1252,
      "step": 22100
    },
    {
      "epoch": 13.373493975903614,
      "grad_norm": 8.685561180114746,
      "learning_rate": 1.6566265060240965e-05,
      "loss": 1.142,
      "step": 22200
    },
    {
      "epoch": 13.433734939759036,
      "grad_norm": 20.40462303161621,
      "learning_rate": 1.641566265060241e-05,
      "loss": 1.1174,
      "step": 22300
    },
    {
      "epoch": 13.493975903614459,
      "grad_norm": 8.983270645141602,
      "learning_rate": 1.6265060240963857e-05,
      "loss": 1.0486,
      "step": 22400
    },
    {
      "epoch": 13.55421686746988,
      "grad_norm": 15.42318058013916,
      "learning_rate": 1.6114457831325303e-05,
      "loss": 1.0688,
      "step": 22500
    },
    {
      "epoch": 13.614457831325302,
      "grad_norm": 10.727433204650879,
      "learning_rate": 1.5963855421686745e-05,
      "loss": 1.0938,
      "step": 22600
    },
    {
      "epoch": 13.674698795180722,
      "grad_norm": 7.469228267669678,
      "learning_rate": 1.5813253012048195e-05,
      "loss": 1.0276,
      "step": 22700
    },
    {
      "epoch": 13.734939759036145,
      "grad_norm": 8.020904541015625,
      "learning_rate": 1.566265060240964e-05,
      "loss": 1.0679,
      "step": 22800
    },
    {
      "epoch": 13.795180722891565,
      "grad_norm": 11.020441055297852,
      "learning_rate": 1.5512048192771086e-05,
      "loss": 1.0308,
      "step": 22900
    },
    {
      "epoch": 13.855421686746988,
      "grad_norm": 11.694198608398438,
      "learning_rate": 1.536144578313253e-05,
      "loss": 1.007,
      "step": 23000
    },
    {
      "epoch": 13.91566265060241,
      "grad_norm": 10.344999313354492,
      "learning_rate": 1.5210843373493977e-05,
      "loss": 1.0718,
      "step": 23100
    },
    {
      "epoch": 13.975903614457831,
      "grad_norm": 7.232461929321289,
      "learning_rate": 1.5060240963855424e-05,
      "loss": 1.1625,
      "step": 23200
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.2677441835403442,
      "eval_runtime": 11.3833,
      "eval_samples_per_second": 153.909,
      "eval_steps_per_second": 19.239,
      "step": 23240
    },
    {
      "epoch": 14.036144578313253,
      "grad_norm": 11.557265281677246,
      "learning_rate": 1.4909638554216867e-05,
      "loss": 1.1117,
      "step": 23300
    },
    {
      "epoch": 14.096385542168674,
      "grad_norm": 16.577966690063477,
      "learning_rate": 1.4759036144578315e-05,
      "loss": 1.0954,
      "step": 23400
    },
    {
      "epoch": 14.156626506024097,
      "grad_norm": 10.381375312805176,
      "learning_rate": 1.460843373493976e-05,
      "loss": 1.0175,
      "step": 23500
    },
    {
      "epoch": 14.216867469879517,
      "grad_norm": 12.81830883026123,
      "learning_rate": 1.4457831325301205e-05,
      "loss": 1.0655,
      "step": 23600
    },
    {
      "epoch": 14.27710843373494,
      "grad_norm": 13.313157081604004,
      "learning_rate": 1.430722891566265e-05,
      "loss": 1.0729,
      "step": 23700
    },
    {
      "epoch": 14.337349397590362,
      "grad_norm": 11.433950424194336,
      "learning_rate": 1.4156626506024098e-05,
      "loss": 1.0109,
      "step": 23800
    },
    {
      "epoch": 14.397590361445783,
      "grad_norm": 9.781850814819336,
      "learning_rate": 1.4006024096385543e-05,
      "loss": 1.0521,
      "step": 23900
    },
    {
      "epoch": 14.457831325301205,
      "grad_norm": 8.60302734375,
      "learning_rate": 1.3855421686746989e-05,
      "loss": 1.0086,
      "step": 24000
    },
    {
      "epoch": 14.518072289156626,
      "grad_norm": 8.849427223205566,
      "learning_rate": 1.3704819277108436e-05,
      "loss": 1.0749,
      "step": 24100
    },
    {
      "epoch": 14.578313253012048,
      "grad_norm": 7.00809383392334,
      "learning_rate": 1.3554216867469879e-05,
      "loss": 0.9989,
      "step": 24200
    },
    {
      "epoch": 14.638554216867469,
      "grad_norm": 11.409808158874512,
      "learning_rate": 1.3403614457831327e-05,
      "loss": 1.0898,
      "step": 24300
    },
    {
      "epoch": 14.698795180722891,
      "grad_norm": 11.488344192504883,
      "learning_rate": 1.3253012048192772e-05,
      "loss": 1.0277,
      "step": 24400
    },
    {
      "epoch": 14.759036144578314,
      "grad_norm": 8.087493896484375,
      "learning_rate": 1.3102409638554217e-05,
      "loss": 1.0867,
      "step": 24500
    },
    {
      "epoch": 14.819277108433734,
      "grad_norm": 9.060237884521484,
      "learning_rate": 1.2951807228915663e-05,
      "loss": 1.0529,
      "step": 24600
    },
    {
      "epoch": 14.879518072289157,
      "grad_norm": 7.573003768920898,
      "learning_rate": 1.280120481927711e-05,
      "loss": 1.0012,
      "step": 24700
    },
    {
      "epoch": 14.939759036144578,
      "grad_norm": 10.743865013122559,
      "learning_rate": 1.2650602409638555e-05,
      "loss": 1.0704,
      "step": 24800
    },
    {
      "epoch": 15.0,
      "grad_norm": 18.159446716308594,
      "learning_rate": 1.25e-05,
      "loss": 0.9872,
      "step": 24900
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.269851565361023,
      "eval_runtime": 11.3707,
      "eval_samples_per_second": 154.081,
      "eval_steps_per_second": 19.26,
      "step": 24900
    },
    {
      "epoch": 15.060240963855422,
      "grad_norm": 13.396170616149902,
      "learning_rate": 1.2349397590361447e-05,
      "loss": 1.0607,
      "step": 25000
    },
    {
      "epoch": 15.120481927710843,
      "grad_norm": 11.264839172363281,
      "learning_rate": 1.2198795180722893e-05,
      "loss": 1.0518,
      "step": 25100
    },
    {
      "epoch": 15.180722891566266,
      "grad_norm": 9.797898292541504,
      "learning_rate": 1.2048192771084338e-05,
      "loss": 1.0726,
      "step": 25200
    },
    {
      "epoch": 15.240963855421686,
      "grad_norm": 10.527647018432617,
      "learning_rate": 1.1897590361445783e-05,
      "loss": 1.025,
      "step": 25300
    },
    {
      "epoch": 15.301204819277109,
      "grad_norm": 19.43389320373535,
      "learning_rate": 1.174698795180723e-05,
      "loss": 1.1248,
      "step": 25400
    },
    {
      "epoch": 15.36144578313253,
      "grad_norm": 6.4705305099487305,
      "learning_rate": 1.1596385542168675e-05,
      "loss": 1.0024,
      "step": 25500
    },
    {
      "epoch": 15.421686746987952,
      "grad_norm": 16.065309524536133,
      "learning_rate": 1.144578313253012e-05,
      "loss": 1.0676,
      "step": 25600
    },
    {
      "epoch": 15.481927710843374,
      "grad_norm": 10.359960556030273,
      "learning_rate": 1.1295180722891567e-05,
      "loss": 0.9335,
      "step": 25700
    },
    {
      "epoch": 15.542168674698795,
      "grad_norm": 20.04489517211914,
      "learning_rate": 1.1144578313253013e-05,
      "loss": 1.0259,
      "step": 25800
    },
    {
      "epoch": 15.602409638554217,
      "grad_norm": 8.553235054016113,
      "learning_rate": 1.0993975903614459e-05,
      "loss": 0.9879,
      "step": 25900
    },
    {
      "epoch": 15.662650602409638,
      "grad_norm": 10.640336990356445,
      "learning_rate": 1.0843373493975904e-05,
      "loss": 1.0643,
      "step": 26000
    },
    {
      "epoch": 15.72289156626506,
      "grad_norm": 10.223756790161133,
      "learning_rate": 1.069277108433735e-05,
      "loss": 1.0747,
      "step": 26100
    },
    {
      "epoch": 15.783132530120483,
      "grad_norm": 11.056544303894043,
      "learning_rate": 1.0542168674698796e-05,
      "loss": 1.0228,
      "step": 26200
    },
    {
      "epoch": 15.843373493975903,
      "grad_norm": 17.399890899658203,
      "learning_rate": 1.0391566265060242e-05,
      "loss": 0.9546,
      "step": 26300
    },
    {
      "epoch": 15.903614457831326,
      "grad_norm": 7.775315761566162,
      "learning_rate": 1.0240963855421687e-05,
      "loss": 0.9971,
      "step": 26400
    },
    {
      "epoch": 15.963855421686747,
      "grad_norm": 7.162292003631592,
      "learning_rate": 1.0090361445783134e-05,
      "loss": 0.949,
      "step": 26500
    },
    {
      "epoch": 16.0,
      "eval_loss": 1.3093409538269043,
      "eval_runtime": 11.4304,
      "eval_samples_per_second": 153.276,
      "eval_steps_per_second": 19.159,
      "step": 26560
    },
    {
      "epoch": 16.02409638554217,
      "grad_norm": 6.922979831695557,
      "learning_rate": 9.939759036144579e-06,
      "loss": 1.0047,
      "step": 26600
    },
    {
      "epoch": 16.08433734939759,
      "grad_norm": 14.687314987182617,
      "learning_rate": 9.789156626506024e-06,
      "loss": 1.0366,
      "step": 26700
    },
    {
      "epoch": 16.14457831325301,
      "grad_norm": 13.286215782165527,
      "learning_rate": 9.63855421686747e-06,
      "loss": 0.9333,
      "step": 26800
    },
    {
      "epoch": 16.204819277108435,
      "grad_norm": 13.639678955078125,
      "learning_rate": 9.487951807228916e-06,
      "loss": 0.9359,
      "step": 26900
    },
    {
      "epoch": 16.265060240963855,
      "grad_norm": 10.03246021270752,
      "learning_rate": 9.33734939759036e-06,
      "loss": 1.0475,
      "step": 27000
    },
    {
      "epoch": 16.325301204819276,
      "grad_norm": 12.864795684814453,
      "learning_rate": 9.186746987951808e-06,
      "loss": 0.9553,
      "step": 27100
    },
    {
      "epoch": 16.3855421686747,
      "grad_norm": 11.572866439819336,
      "learning_rate": 9.036144578313253e-06,
      "loss": 0.8961,
      "step": 27200
    },
    {
      "epoch": 16.44578313253012,
      "grad_norm": 10.029648780822754,
      "learning_rate": 8.885542168674699e-06,
      "loss": 0.957,
      "step": 27300
    },
    {
      "epoch": 16.50602409638554,
      "grad_norm": 9.556832313537598,
      "learning_rate": 8.734939759036146e-06,
      "loss": 0.9418,
      "step": 27400
    },
    {
      "epoch": 16.566265060240966,
      "grad_norm": 14.621384620666504,
      "learning_rate": 8.58433734939759e-06,
      "loss": 1.0649,
      "step": 27500
    },
    {
      "epoch": 16.626506024096386,
      "grad_norm": 9.895530700683594,
      "learning_rate": 8.433734939759036e-06,
      "loss": 1.0329,
      "step": 27600
    },
    {
      "epoch": 16.686746987951807,
      "grad_norm": 9.046972274780273,
      "learning_rate": 8.283132530120482e-06,
      "loss": 0.9993,
      "step": 27700
    },
    {
      "epoch": 16.746987951807228,
      "grad_norm": 15.892102241516113,
      "learning_rate": 8.132530120481928e-06,
      "loss": 0.9957,
      "step": 27800
    },
    {
      "epoch": 16.80722891566265,
      "grad_norm": 17.13658905029297,
      "learning_rate": 7.981927710843373e-06,
      "loss": 1.009,
      "step": 27900
    },
    {
      "epoch": 16.867469879518072,
      "grad_norm": 18.900188446044922,
      "learning_rate": 7.83132530120482e-06,
      "loss": 1.005,
      "step": 28000
    },
    {
      "epoch": 16.927710843373493,
      "grad_norm": 10.360817909240723,
      "learning_rate": 7.680722891566265e-06,
      "loss": 0.9689,
      "step": 28100
    },
    {
      "epoch": 16.987951807228917,
      "grad_norm": 7.83504581451416,
      "learning_rate": 7.530120481927712e-06,
      "loss": 1.0665,
      "step": 28200
    },
    {
      "epoch": 17.0,
      "eval_loss": 1.2435475587844849,
      "eval_runtime": 11.4234,
      "eval_samples_per_second": 153.369,
      "eval_steps_per_second": 19.171,
      "step": 28220
    },
    {
      "epoch": 17.048192771084338,
      "grad_norm": 12.293147087097168,
      "learning_rate": 7.379518072289157e-06,
      "loss": 0.9852,
      "step": 28300
    },
    {
      "epoch": 17.10843373493976,
      "grad_norm": 11.013635635375977,
      "learning_rate": 7.228915662650602e-06,
      "loss": 0.9432,
      "step": 28400
    },
    {
      "epoch": 17.16867469879518,
      "grad_norm": 10.684069633483887,
      "learning_rate": 7.078313253012049e-06,
      "loss": 0.9564,
      "step": 28500
    },
    {
      "epoch": 17.228915662650603,
      "grad_norm": 11.607410430908203,
      "learning_rate": 6.927710843373494e-06,
      "loss": 0.9363,
      "step": 28600
    },
    {
      "epoch": 17.289156626506024,
      "grad_norm": 16.399436950683594,
      "learning_rate": 6.7771084337349394e-06,
      "loss": 0.9922,
      "step": 28700
    },
    {
      "epoch": 17.349397590361445,
      "grad_norm": 13.71933364868164,
      "learning_rate": 6.626506024096386e-06,
      "loss": 1.0631,
      "step": 28800
    },
    {
      "epoch": 17.40963855421687,
      "grad_norm": 13.38804817199707,
      "learning_rate": 6.475903614457831e-06,
      "loss": 0.9661,
      "step": 28900
    },
    {
      "epoch": 17.46987951807229,
      "grad_norm": 8.791848182678223,
      "learning_rate": 6.325301204819277e-06,
      "loss": 1.0031,
      "step": 29000
    },
    {
      "epoch": 17.53012048192771,
      "grad_norm": 10.696416854858398,
      "learning_rate": 6.174698795180723e-06,
      "loss": 1.0538,
      "step": 29100
    },
    {
      "epoch": 17.59036144578313,
      "grad_norm": 11.965747833251953,
      "learning_rate": 6.024096385542169e-06,
      "loss": 0.9366,
      "step": 29200
    },
    {
      "epoch": 17.650602409638555,
      "grad_norm": 13.458391189575195,
      "learning_rate": 5.873493975903615e-06,
      "loss": 0.9585,
      "step": 29300
    },
    {
      "epoch": 17.710843373493976,
      "grad_norm": 12.546916961669922,
      "learning_rate": 5.72289156626506e-06,
      "loss": 0.9033,
      "step": 29400
    },
    {
      "epoch": 17.771084337349397,
      "grad_norm": 11.905926704406738,
      "learning_rate": 5.572289156626506e-06,
      "loss": 0.9164,
      "step": 29500
    },
    {
      "epoch": 17.83132530120482,
      "grad_norm": 8.920300483703613,
      "learning_rate": 5.421686746987952e-06,
      "loss": 0.9527,
      "step": 29600
    },
    {
      "epoch": 17.89156626506024,
      "grad_norm": 10.951645851135254,
      "learning_rate": 5.271084337349398e-06,
      "loss": 0.9475,
      "step": 29700
    },
    {
      "epoch": 17.951807228915662,
      "grad_norm": 10.415894508361816,
      "learning_rate": 5.120481927710843e-06,
      "loss": 0.987,
      "step": 29800
    },
    {
      "epoch": 18.0,
      "eval_loss": 1.2112691402435303,
      "eval_runtime": 11.4537,
      "eval_samples_per_second": 152.964,
      "eval_steps_per_second": 19.12,
      "step": 29880
    },
    {
      "epoch": 18.012048192771083,
      "grad_norm": 6.14348840713501,
      "learning_rate": 4.969879518072289e-06,
      "loss": 0.9987,
      "step": 29900
    },
    {
      "epoch": 18.072289156626507,
      "grad_norm": 9.296491622924805,
      "learning_rate": 4.819277108433735e-06,
      "loss": 0.9884,
      "step": 30000
    },
    {
      "epoch": 18.132530120481928,
      "grad_norm": 9.98090934753418,
      "learning_rate": 4.66867469879518e-06,
      "loss": 0.9386,
      "step": 30100
    },
    {
      "epoch": 18.19277108433735,
      "grad_norm": 9.008808135986328,
      "learning_rate": 4.518072289156626e-06,
      "loss": 0.9683,
      "step": 30200
    },
    {
      "epoch": 18.253012048192772,
      "grad_norm": 10.225921630859375,
      "learning_rate": 4.367469879518073e-06,
      "loss": 0.9216,
      "step": 30300
    },
    {
      "epoch": 18.313253012048193,
      "grad_norm": 5.472142696380615,
      "learning_rate": 4.216867469879518e-06,
      "loss": 0.9159,
      "step": 30400
    },
    {
      "epoch": 18.373493975903614,
      "grad_norm": 7.348989963531494,
      "learning_rate": 4.066265060240964e-06,
      "loss": 0.9332,
      "step": 30500
    },
    {
      "epoch": 18.433734939759034,
      "grad_norm": 14.975149154663086,
      "learning_rate": 3.91566265060241e-06,
      "loss": 0.9267,
      "step": 30600
    },
    {
      "epoch": 18.49397590361446,
      "grad_norm": 12.088613510131836,
      "learning_rate": 3.765060240963856e-06,
      "loss": 0.9892,
      "step": 30700
    },
    {
      "epoch": 18.55421686746988,
      "grad_norm": 8.656229019165039,
      "learning_rate": 3.614457831325301e-06,
      "loss": 0.8911,
      "step": 30800
    },
    {
      "epoch": 18.6144578313253,
      "grad_norm": 8.866218566894531,
      "learning_rate": 3.463855421686747e-06,
      "loss": 0.9633,
      "step": 30900
    },
    {
      "epoch": 18.674698795180724,
      "grad_norm": 10.119933128356934,
      "learning_rate": 3.313253012048193e-06,
      "loss": 0.9472,
      "step": 31000
    },
    {
      "epoch": 18.734939759036145,
      "grad_norm": 13.955789566040039,
      "learning_rate": 3.1626506024096387e-06,
      "loss": 0.8676,
      "step": 31100
    },
    {
      "epoch": 18.795180722891565,
      "grad_norm": 10.823678970336914,
      "learning_rate": 3.0120481927710846e-06,
      "loss": 0.9492,
      "step": 31200
    },
    {
      "epoch": 18.855421686746986,
      "grad_norm": 10.458948135375977,
      "learning_rate": 2.86144578313253e-06,
      "loss": 0.9608,
      "step": 31300
    },
    {
      "epoch": 18.91566265060241,
      "grad_norm": 9.647998809814453,
      "learning_rate": 2.710843373493976e-06,
      "loss": 0.9961,
      "step": 31400
    },
    {
      "epoch": 18.97590361445783,
      "grad_norm": 7.645269870758057,
      "learning_rate": 2.5602409638554217e-06,
      "loss": 0.985,
      "step": 31500
    },
    {
      "epoch": 19.0,
      "eval_loss": 1.2694679498672485,
      "eval_runtime": 11.4504,
      "eval_samples_per_second": 153.008,
      "eval_steps_per_second": 19.126,
      "step": 31540
    },
    {
      "epoch": 19.03614457831325,
      "grad_norm": 7.6357035636901855,
      "learning_rate": 2.4096385542168676e-06,
      "loss": 0.9845,
      "step": 31600
    },
    {
      "epoch": 19.096385542168676,
      "grad_norm": 8.353412628173828,
      "learning_rate": 2.259036144578313e-06,
      "loss": 0.9675,
      "step": 31700
    },
    {
      "epoch": 19.156626506024097,
      "grad_norm": 11.187978744506836,
      "learning_rate": 2.108433734939759e-06,
      "loss": 0.9896,
      "step": 31800
    },
    {
      "epoch": 19.216867469879517,
      "grad_norm": 12.68245792388916,
      "learning_rate": 1.957831325301205e-06,
      "loss": 0.9715,
      "step": 31900
    },
    {
      "epoch": 19.27710843373494,
      "grad_norm": 12.05379867553711,
      "learning_rate": 1.8072289156626506e-06,
      "loss": 0.9188,
      "step": 32000
    },
    {
      "epoch": 19.337349397590362,
      "grad_norm": 7.922645092010498,
      "learning_rate": 1.6566265060240966e-06,
      "loss": 0.9302,
      "step": 32100
    },
    {
      "epoch": 19.397590361445783,
      "grad_norm": 9.55782413482666,
      "learning_rate": 1.5060240963855423e-06,
      "loss": 0.943,
      "step": 32200
    },
    {
      "epoch": 19.457831325301203,
      "grad_norm": 11.187516212463379,
      "learning_rate": 1.355421686746988e-06,
      "loss": 0.9723,
      "step": 32300
    },
    {
      "epoch": 19.518072289156628,
      "grad_norm": 11.290290832519531,
      "learning_rate": 1.2048192771084338e-06,
      "loss": 0.9114,
      "step": 32400
    },
    {
      "epoch": 19.57831325301205,
      "grad_norm": 17.855030059814453,
      "learning_rate": 1.0542168674698796e-06,
      "loss": 0.9383,
      "step": 32500
    },
    {
      "epoch": 19.63855421686747,
      "grad_norm": 12.675041198730469,
      "learning_rate": 9.036144578313253e-07,
      "loss": 0.8333,
      "step": 32600
    },
    {
      "epoch": 19.698795180722893,
      "grad_norm": 15.943073272705078,
      "learning_rate": 7.530120481927712e-07,
      "loss": 0.8922,
      "step": 32700
    },
    {
      "epoch": 19.759036144578314,
      "grad_norm": 5.006438255310059,
      "learning_rate": 6.024096385542169e-07,
      "loss": 0.8853,
      "step": 32800
    },
    {
      "epoch": 19.819277108433734,
      "grad_norm": 11.161233901977539,
      "learning_rate": 4.5180722891566265e-07,
      "loss": 1.0236,
      "step": 32900
    },
    {
      "epoch": 19.879518072289155,
      "grad_norm": 5.667096138000488,
      "learning_rate": 3.0120481927710845e-07,
      "loss": 0.9756,
      "step": 33000
    },
    {
      "epoch": 19.93975903614458,
      "grad_norm": 9.911526679992676,
      "learning_rate": 1.5060240963855423e-07,
      "loss": 1.0183,
      "step": 33100
    },
    {
      "epoch": 20.0,
      "grad_norm": 20.515098571777344,
      "learning_rate": 0.0,
      "loss": 0.9106,
      "step": 33200
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.2184041738510132,
      "eval_runtime": 11.3937,
      "eval_samples_per_second": 153.769,
      "eval_steps_per_second": 19.221,
      "step": 33200
    }
  ],
  "logging_steps": 100,
  "max_steps": 33200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.987000546779136e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
