{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 12420,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1610305958132045,
      "grad_norm": 4.7951507568359375,
      "learning_rate": 4.959742351046699e-05,
      "loss": 5.0146,
      "step": 100
    },
    {
      "epoch": 0.322061191626409,
      "grad_norm": 5.814887046813965,
      "learning_rate": 4.919484702093398e-05,
      "loss": 4.8792,
      "step": 200
    },
    {
      "epoch": 0.4830917874396135,
      "grad_norm": 3.9249470233917236,
      "learning_rate": 4.879227053140097e-05,
      "loss": 4.8347,
      "step": 300
    },
    {
      "epoch": 0.644122383252818,
      "grad_norm": 4.440197944641113,
      "learning_rate": 4.8389694041867956e-05,
      "loss": 4.7947,
      "step": 400
    },
    {
      "epoch": 0.8051529790660226,
      "grad_norm": 5.313521385192871,
      "learning_rate": 4.7987117552334945e-05,
      "loss": 4.7307,
      "step": 500
    },
    {
      "epoch": 0.966183574879227,
      "grad_norm": 4.792543411254883,
      "learning_rate": 4.7584541062801933e-05,
      "loss": 4.787,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_loss": 4.624929904937744,
      "eval_runtime": 2.3371,
      "eval_samples_per_second": 200.252,
      "eval_steps_per_second": 25.245,
      "step": 621
    },
    {
      "epoch": 1.1272141706924317,
      "grad_norm": 3.8203728199005127,
      "learning_rate": 4.718196457326892e-05,
      "loss": 4.7275,
      "step": 700
    },
    {
      "epoch": 1.288244766505636,
      "grad_norm": 8.389549255371094,
      "learning_rate": 4.677938808373592e-05,
      "loss": 4.6249,
      "step": 800
    },
    {
      "epoch": 1.4492753623188406,
      "grad_norm": 5.984747409820557,
      "learning_rate": 4.63768115942029e-05,
      "loss": 4.6579,
      "step": 900
    },
    {
      "epoch": 1.6103059581320451,
      "grad_norm": 5.312664031982422,
      "learning_rate": 4.597423510466989e-05,
      "loss": 4.6054,
      "step": 1000
    },
    {
      "epoch": 1.7713365539452495,
      "grad_norm": 5.197248935699463,
      "learning_rate": 4.557165861513688e-05,
      "loss": 4.6158,
      "step": 1100
    },
    {
      "epoch": 1.9323671497584543,
      "grad_norm": 5.931069850921631,
      "learning_rate": 4.5169082125603865e-05,
      "loss": 4.6307,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "eval_loss": 4.407584190368652,
      "eval_runtime": 2.2805,
      "eval_samples_per_second": 205.215,
      "eval_steps_per_second": 25.871,
      "step": 1242
    },
    {
      "epoch": 2.0933977455716586,
      "grad_norm": 4.860264778137207,
      "learning_rate": 4.476650563607085e-05,
      "loss": 4.5581,
      "step": 1300
    },
    {
      "epoch": 2.2544283413848634,
      "grad_norm": 7.592217922210693,
      "learning_rate": 4.436392914653785e-05,
      "loss": 4.4911,
      "step": 1400
    },
    {
      "epoch": 2.4154589371980677,
      "grad_norm": 5.591490745544434,
      "learning_rate": 4.396135265700484e-05,
      "loss": 4.4148,
      "step": 1500
    },
    {
      "epoch": 2.576489533011272,
      "grad_norm": 5.5408034324646,
      "learning_rate": 4.355877616747182e-05,
      "loss": 4.2204,
      "step": 1600
    },
    {
      "epoch": 2.7375201288244764,
      "grad_norm": 5.222095966339111,
      "learning_rate": 4.315619967793881e-05,
      "loss": 4.2542,
      "step": 1700
    },
    {
      "epoch": 2.898550724637681,
      "grad_norm": 8.236465454101562,
      "learning_rate": 4.27536231884058e-05,
      "loss": 4.1224,
      "step": 1800
    },
    {
      "epoch": 3.0,
      "eval_loss": 3.827338218688965,
      "eval_runtime": 2.2793,
      "eval_samples_per_second": 205.325,
      "eval_steps_per_second": 25.885,
      "step": 1863
    },
    {
      "epoch": 3.0595813204508855,
      "grad_norm": 7.469377040863037,
      "learning_rate": 4.2351046698872784e-05,
      "loss": 4.0348,
      "step": 1900
    },
    {
      "epoch": 3.2206119162640903,
      "grad_norm": 7.017388820648193,
      "learning_rate": 4.194847020933977e-05,
      "loss": 3.9061,
      "step": 2000
    },
    {
      "epoch": 3.3816425120772946,
      "grad_norm": 6.959563732147217,
      "learning_rate": 4.154589371980677e-05,
      "loss": 3.8397,
      "step": 2100
    },
    {
      "epoch": 3.542673107890499,
      "grad_norm": 10.036592483520508,
      "learning_rate": 4.1143317230273756e-05,
      "loss": 3.6828,
      "step": 2200
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 13.33142375946045,
      "learning_rate": 4.074074074074074e-05,
      "loss": 3.4136,
      "step": 2300
    },
    {
      "epoch": 3.864734299516908,
      "grad_norm": 10.768904685974121,
      "learning_rate": 4.0338164251207733e-05,
      "loss": 3.1471,
      "step": 2400
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.430609703063965,
      "eval_runtime": 2.3001,
      "eval_samples_per_second": 203.466,
      "eval_steps_per_second": 25.651,
      "step": 2484
    },
    {
      "epoch": 4.025764895330113,
      "grad_norm": 12.410099029541016,
      "learning_rate": 3.993558776167472e-05,
      "loss": 2.8641,
      "step": 2500
    },
    {
      "epoch": 4.186795491143317,
      "grad_norm": 12.471461296081543,
      "learning_rate": 3.9533011272141704e-05,
      "loss": 2.6828,
      "step": 2600
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 9.065108299255371,
      "learning_rate": 3.91304347826087e-05,
      "loss": 2.525,
      "step": 2700
    },
    {
      "epoch": 4.508856682769727,
      "grad_norm": 9.38520336151123,
      "learning_rate": 3.872785829307569e-05,
      "loss": 2.4082,
      "step": 2800
    },
    {
      "epoch": 4.669887278582931,
      "grad_norm": 10.58176040649414,
      "learning_rate": 3.8325281803542676e-05,
      "loss": 2.2887,
      "step": 2900
    },
    {
      "epoch": 4.830917874396135,
      "grad_norm": 9.04275131225586,
      "learning_rate": 3.7922705314009665e-05,
      "loss": 2.2683,
      "step": 3000
    },
    {
      "epoch": 4.99194847020934,
      "grad_norm": 9.386300086975098,
      "learning_rate": 3.752012882447665e-05,
      "loss": 2.2035,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.8291797637939453,
      "eval_runtime": 2.2869,
      "eval_samples_per_second": 204.643,
      "eval_steps_per_second": 25.799,
      "step": 3105
    },
    {
      "epoch": 5.152979066022544,
      "grad_norm": 8.08434772491455,
      "learning_rate": 3.711755233494364e-05,
      "loss": 2.0669,
      "step": 3200
    },
    {
      "epoch": 5.314009661835748,
      "grad_norm": 9.09067153930664,
      "learning_rate": 3.671497584541063e-05,
      "loss": 2.0001,
      "step": 3300
    },
    {
      "epoch": 5.475040257648954,
      "grad_norm": 12.239164352416992,
      "learning_rate": 3.631239935587762e-05,
      "loss": 1.9708,
      "step": 3400
    },
    {
      "epoch": 5.636070853462158,
      "grad_norm": 10.39382553100586,
      "learning_rate": 3.590982286634461e-05,
      "loss": 1.8658,
      "step": 3500
    },
    {
      "epoch": 5.797101449275362,
      "grad_norm": 9.4124755859375,
      "learning_rate": 3.5507246376811596e-05,
      "loss": 1.7425,
      "step": 3600
    },
    {
      "epoch": 5.958132045088567,
      "grad_norm": 7.761712074279785,
      "learning_rate": 3.5104669887278584e-05,
      "loss": 1.6517,
      "step": 3700
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.4471009969711304,
      "eval_runtime": 2.285,
      "eval_samples_per_second": 204.814,
      "eval_steps_per_second": 25.821,
      "step": 3726
    },
    {
      "epoch": 6.119162640901771,
      "grad_norm": 9.999380111694336,
      "learning_rate": 3.470209339774557e-05,
      "loss": 1.6581,
      "step": 3800
    },
    {
      "epoch": 6.280193236714976,
      "grad_norm": 7.050923824310303,
      "learning_rate": 3.429951690821256e-05,
      "loss": 1.5603,
      "step": 3900
    },
    {
      "epoch": 6.4412238325281805,
      "grad_norm": 8.847064018249512,
      "learning_rate": 3.389694041867955e-05,
      "loss": 1.527,
      "step": 4000
    },
    {
      "epoch": 6.602254428341385,
      "grad_norm": 10.000187873840332,
      "learning_rate": 3.349436392914654e-05,
      "loss": 1.5257,
      "step": 4100
    },
    {
      "epoch": 6.763285024154589,
      "grad_norm": 8.552372932434082,
      "learning_rate": 3.3091787439613533e-05,
      "loss": 1.5328,
      "step": 4200
    },
    {
      "epoch": 6.9243156199677935,
      "grad_norm": 7.615685939788818,
      "learning_rate": 3.2689210950080515e-05,
      "loss": 1.5456,
      "step": 4300
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3329739570617676,
      "eval_runtime": 2.2939,
      "eval_samples_per_second": 204.02,
      "eval_steps_per_second": 25.721,
      "step": 4347
    },
    {
      "epoch": 7.085346215780999,
      "grad_norm": 6.204887390136719,
      "learning_rate": 3.2286634460547504e-05,
      "loss": 1.4973,
      "step": 4400
    },
    {
      "epoch": 7.246376811594203,
      "grad_norm": 16.74822425842285,
      "learning_rate": 3.188405797101449e-05,
      "loss": 1.4372,
      "step": 4500
    },
    {
      "epoch": 7.407407407407407,
      "grad_norm": 7.01466178894043,
      "learning_rate": 3.148148148148148e-05,
      "loss": 1.4392,
      "step": 4600
    },
    {
      "epoch": 7.568438003220612,
      "grad_norm": 9.425312995910645,
      "learning_rate": 3.107890499194847e-05,
      "loss": 1.4797,
      "step": 4700
    },
    {
      "epoch": 7.729468599033816,
      "grad_norm": 6.35913610458374,
      "learning_rate": 3.067632850241546e-05,
      "loss": 1.4505,
      "step": 4800
    },
    {
      "epoch": 7.8904991948470204,
      "grad_norm": 8.510326385498047,
      "learning_rate": 3.027375201288245e-05,
      "loss": 1.4283,
      "step": 4900
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.2437288761138916,
      "eval_runtime": 2.3173,
      "eval_samples_per_second": 201.961,
      "eval_steps_per_second": 25.461,
      "step": 4968
    },
    {
      "epoch": 8.051529790660226,
      "grad_norm": 6.169023513793945,
      "learning_rate": 2.9871175523349438e-05,
      "loss": 1.4067,
      "step": 5000
    },
    {
      "epoch": 8.21256038647343,
      "grad_norm": 30.795148849487305,
      "learning_rate": 2.9468599033816423e-05,
      "loss": 1.3808,
      "step": 5100
    },
    {
      "epoch": 8.373590982286634,
      "grad_norm": 6.91514253616333,
      "learning_rate": 2.9066022544283415e-05,
      "loss": 1.3576,
      "step": 5200
    },
    {
      "epoch": 8.53462157809984,
      "grad_norm": 5.655375003814697,
      "learning_rate": 2.8663446054750404e-05,
      "loss": 1.3713,
      "step": 5300
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 6.169068813323975,
      "learning_rate": 2.826086956521739e-05,
      "loss": 1.3311,
      "step": 5400
    },
    {
      "epoch": 8.856682769726248,
      "grad_norm": 6.098912239074707,
      "learning_rate": 2.7858293075684384e-05,
      "loss": 1.3671,
      "step": 5500
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.196901559829712,
      "eval_runtime": 2.2871,
      "eval_samples_per_second": 204.629,
      "eval_steps_per_second": 25.797,
      "step": 5589
    },
    {
      "epoch": 9.017713365539452,
      "grad_norm": 6.0566253662109375,
      "learning_rate": 2.745571658615137e-05,
      "loss": 1.3712,
      "step": 5600
    },
    {
      "epoch": 9.178743961352657,
      "grad_norm": 8.182141304016113,
      "learning_rate": 2.7053140096618358e-05,
      "loss": 1.3361,
      "step": 5700
    },
    {
      "epoch": 9.339774557165862,
      "grad_norm": 7.819048881530762,
      "learning_rate": 2.665056360708535e-05,
      "loss": 1.2948,
      "step": 5800
    },
    {
      "epoch": 9.500805152979066,
      "grad_norm": 6.001546382904053,
      "learning_rate": 2.6247987117552335e-05,
      "loss": 1.291,
      "step": 5900
    },
    {
      "epoch": 9.66183574879227,
      "grad_norm": 6.498340606689453,
      "learning_rate": 2.5845410628019323e-05,
      "loss": 1.3002,
      "step": 6000
    },
    {
      "epoch": 9.822866344605474,
      "grad_norm": 8.016550064086914,
      "learning_rate": 2.5442834138486315e-05,
      "loss": 1.2923,
      "step": 6100
    },
    {
      "epoch": 9.98389694041868,
      "grad_norm": 7.654576301574707,
      "learning_rate": 2.5040257648953304e-05,
      "loss": 1.2979,
      "step": 6200
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.153708815574646,
      "eval_runtime": 2.286,
      "eval_samples_per_second": 204.728,
      "eval_steps_per_second": 25.81,
      "step": 6210
    },
    {
      "epoch": 10.144927536231885,
      "grad_norm": 5.855804443359375,
      "learning_rate": 2.4637681159420292e-05,
      "loss": 1.288,
      "step": 6300
    },
    {
      "epoch": 10.305958132045088,
      "grad_norm": 5.790511131286621,
      "learning_rate": 2.423510466988728e-05,
      "loss": 1.2522,
      "step": 6400
    },
    {
      "epoch": 10.466988727858293,
      "grad_norm": 10.850168228149414,
      "learning_rate": 2.383252818035427e-05,
      "loss": 1.2542,
      "step": 6500
    },
    {
      "epoch": 10.628019323671497,
      "grad_norm": 6.699300765991211,
      "learning_rate": 2.3429951690821258e-05,
      "loss": 1.2437,
      "step": 6600
    },
    {
      "epoch": 10.789049919484702,
      "grad_norm": 6.211131572723389,
      "learning_rate": 2.3027375201288246e-05,
      "loss": 1.257,
      "step": 6700
    },
    {
      "epoch": 10.950080515297907,
      "grad_norm": 6.0249924659729,
      "learning_rate": 2.2624798711755235e-05,
      "loss": 1.244,
      "step": 6800
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.134065866470337,
      "eval_runtime": 2.2879,
      "eval_samples_per_second": 204.556,
      "eval_steps_per_second": 25.788,
      "step": 6831
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 6.64976167678833,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 1.2524,
      "step": 6900
    },
    {
      "epoch": 11.272141706924316,
      "grad_norm": 5.588869094848633,
      "learning_rate": 2.1819645732689212e-05,
      "loss": 1.2076,
      "step": 7000
    },
    {
      "epoch": 11.43317230273752,
      "grad_norm": 7.2848358154296875,
      "learning_rate": 2.14170692431562e-05,
      "loss": 1.2222,
      "step": 7100
    },
    {
      "epoch": 11.594202898550725,
      "grad_norm": 5.846545219421387,
      "learning_rate": 2.101449275362319e-05,
      "loss": 1.2165,
      "step": 7200
    },
    {
      "epoch": 11.75523349436393,
      "grad_norm": 5.397076606750488,
      "learning_rate": 2.0611916264090177e-05,
      "loss": 1.1988,
      "step": 7300
    },
    {
      "epoch": 11.916264090177133,
      "grad_norm": 6.074864864349365,
      "learning_rate": 2.020933977455717e-05,
      "loss": 1.2043,
      "step": 7400
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.0964465141296387,
      "eval_runtime": 2.2833,
      "eval_samples_per_second": 204.964,
      "eval_steps_per_second": 25.84,
      "step": 7452
    },
    {
      "epoch": 12.077294685990339,
      "grad_norm": 5.960419654846191,
      "learning_rate": 1.9806763285024154e-05,
      "loss": 1.1921,
      "step": 7500
    },
    {
      "epoch": 12.238325281803542,
      "grad_norm": 5.41005802154541,
      "learning_rate": 1.9404186795491143e-05,
      "loss": 1.1795,
      "step": 7600
    },
    {
      "epoch": 12.399355877616747,
      "grad_norm": 5.734086513519287,
      "learning_rate": 1.9001610305958135e-05,
      "loss": 1.1694,
      "step": 7700
    },
    {
      "epoch": 12.560386473429952,
      "grad_norm": 6.866467475891113,
      "learning_rate": 1.859903381642512e-05,
      "loss": 1.1783,
      "step": 7800
    },
    {
      "epoch": 12.721417069243156,
      "grad_norm": 5.96259069442749,
      "learning_rate": 1.8196457326892112e-05,
      "loss": 1.1984,
      "step": 7900
    },
    {
      "epoch": 12.882447665056361,
      "grad_norm": 7.390145301818848,
      "learning_rate": 1.77938808373591e-05,
      "loss": 1.1627,
      "step": 8000
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.0408865213394165,
      "eval_runtime": 2.2879,
      "eval_samples_per_second": 204.555,
      "eval_steps_per_second": 25.788,
      "step": 8073
    },
    {
      "epoch": 13.043478260869565,
      "grad_norm": 5.670037746429443,
      "learning_rate": 1.739130434782609e-05,
      "loss": 1.1747,
      "step": 8100
    },
    {
      "epoch": 13.20450885668277,
      "grad_norm": 7.175532341003418,
      "learning_rate": 1.6988727858293077e-05,
      "loss": 1.1462,
      "step": 8200
    },
    {
      "epoch": 13.365539452495975,
      "grad_norm": 6.238275051116943,
      "learning_rate": 1.6586151368760062e-05,
      "loss": 1.1587,
      "step": 8300
    },
    {
      "epoch": 13.526570048309178,
      "grad_norm": 5.566137790679932,
      "learning_rate": 1.6183574879227054e-05,
      "loss": 1.1544,
      "step": 8400
    },
    {
      "epoch": 13.687600644122384,
      "grad_norm": 5.701809883117676,
      "learning_rate": 1.5780998389694043e-05,
      "loss": 1.1319,
      "step": 8500
    },
    {
      "epoch": 13.848631239935587,
      "grad_norm": 5.710341930389404,
      "learning_rate": 1.537842190016103e-05,
      "loss": 1.1394,
      "step": 8600
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.0386120080947876,
      "eval_runtime": 2.2855,
      "eval_samples_per_second": 204.769,
      "eval_steps_per_second": 25.815,
      "step": 8694
    },
    {
      "epoch": 14.009661835748792,
      "grad_norm": 5.711899280548096,
      "learning_rate": 1.497584541062802e-05,
      "loss": 1.1543,
      "step": 8700
    },
    {
      "epoch": 14.170692431561998,
      "grad_norm": 6.329565048217773,
      "learning_rate": 1.457326892109501e-05,
      "loss": 1.1469,
      "step": 8800
    },
    {
      "epoch": 14.331723027375201,
      "grad_norm": 7.536128044128418,
      "learning_rate": 1.4170692431561997e-05,
      "loss": 1.1283,
      "step": 8900
    },
    {
      "epoch": 14.492753623188406,
      "grad_norm": 5.229131698608398,
      "learning_rate": 1.3768115942028985e-05,
      "loss": 1.1198,
      "step": 9000
    },
    {
      "epoch": 14.65378421900161,
      "grad_norm": 5.1551833152771,
      "learning_rate": 1.3365539452495976e-05,
      "loss": 1.1082,
      "step": 9100
    },
    {
      "epoch": 14.814814814814815,
      "grad_norm": 4.593730926513672,
      "learning_rate": 1.2962962962962962e-05,
      "loss": 1.115,
      "step": 9200
    },
    {
      "epoch": 14.97584541062802,
      "grad_norm": 5.170806884765625,
      "learning_rate": 1.2560386473429953e-05,
      "loss": 1.1129,
      "step": 9300
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.0466055870056152,
      "eval_runtime": 2.287,
      "eval_samples_per_second": 204.636,
      "eval_steps_per_second": 25.798,
      "step": 9315
    },
    {
      "epoch": 15.136876006441224,
      "grad_norm": 5.361586093902588,
      "learning_rate": 1.2157809983896941e-05,
      "loss": 1.1106,
      "step": 9400
    },
    {
      "epoch": 15.297906602254429,
      "grad_norm": 4.253791332244873,
      "learning_rate": 1.175523349436393e-05,
      "loss": 1.0897,
      "step": 9500
    },
    {
      "epoch": 15.458937198067632,
      "grad_norm": 5.467985153198242,
      "learning_rate": 1.1352657004830918e-05,
      "loss": 1.1082,
      "step": 9600
    },
    {
      "epoch": 15.619967793880837,
      "grad_norm": 7.9926838874816895,
      "learning_rate": 1.0950080515297907e-05,
      "loss": 1.074,
      "step": 9700
    },
    {
      "epoch": 15.780998389694043,
      "grad_norm": 7.622003078460693,
      "learning_rate": 1.0547504025764895e-05,
      "loss": 1.0928,
      "step": 9800
    },
    {
      "epoch": 15.942028985507246,
      "grad_norm": 5.229886531829834,
      "learning_rate": 1.0144927536231885e-05,
      "loss": 1.0713,
      "step": 9900
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.9930967688560486,
      "eval_runtime": 2.2826,
      "eval_samples_per_second": 205.027,
      "eval_steps_per_second": 25.847,
      "step": 9936
    },
    {
      "epoch": 16.10305958132045,
      "grad_norm": 5.8994245529174805,
      "learning_rate": 9.742351046698874e-06,
      "loss": 1.0905,
      "step": 10000
    },
    {
      "epoch": 16.264090177133657,
      "grad_norm": 4.6811933517456055,
      "learning_rate": 9.339774557165862e-06,
      "loss": 1.0843,
      "step": 10100
    },
    {
      "epoch": 16.42512077294686,
      "grad_norm": 4.559504508972168,
      "learning_rate": 8.93719806763285e-06,
      "loss": 1.073,
      "step": 10200
    },
    {
      "epoch": 16.586151368760063,
      "grad_norm": 5.361327648162842,
      "learning_rate": 8.53462157809984e-06,
      "loss": 1.0922,
      "step": 10300
    },
    {
      "epoch": 16.74718196457327,
      "grad_norm": 5.677231788635254,
      "learning_rate": 8.132045088566828e-06,
      "loss": 1.0714,
      "step": 10400
    },
    {
      "epoch": 16.908212560386474,
      "grad_norm": 5.099385738372803,
      "learning_rate": 7.729468599033817e-06,
      "loss": 1.0841,
      "step": 10500
    },
    {
      "epoch": 17.0,
      "eval_loss": 1.0068448781967163,
      "eval_runtime": 2.2922,
      "eval_samples_per_second": 204.172,
      "eval_steps_per_second": 25.74,
      "step": 10557
    },
    {
      "epoch": 17.06924315619968,
      "grad_norm": 6.72300910949707,
      "learning_rate": 7.326892109500806e-06,
      "loss": 1.0788,
      "step": 10600
    },
    {
      "epoch": 17.23027375201288,
      "grad_norm": 5.402454853057861,
      "learning_rate": 6.924315619967794e-06,
      "loss": 1.0668,
      "step": 10700
    },
    {
      "epoch": 17.391304347826086,
      "grad_norm": 4.98821496963501,
      "learning_rate": 6.521739130434783e-06,
      "loss": 1.0488,
      "step": 10800
    },
    {
      "epoch": 17.55233494363929,
      "grad_norm": 7.579389572143555,
      "learning_rate": 6.119162640901771e-06,
      "loss": 1.0586,
      "step": 10900
    },
    {
      "epoch": 17.713365539452496,
      "grad_norm": 5.196390628814697,
      "learning_rate": 5.71658615136876e-06,
      "loss": 1.0617,
      "step": 11000
    },
    {
      "epoch": 17.8743961352657,
      "grad_norm": 5.619093418121338,
      "learning_rate": 5.314009661835749e-06,
      "loss": 1.0841,
      "step": 11100
    },
    {
      "epoch": 18.0,
      "eval_loss": 0.9776548147201538,
      "eval_runtime": 2.2984,
      "eval_samples_per_second": 203.618,
      "eval_steps_per_second": 25.67,
      "step": 11178
    },
    {
      "epoch": 18.035426731078903,
      "grad_norm": 5.766378402709961,
      "learning_rate": 4.911433172302738e-06,
      "loss": 1.0563,
      "step": 11200
    },
    {
      "epoch": 18.19645732689211,
      "grad_norm": 5.048425197601318,
      "learning_rate": 4.508856682769726e-06,
      "loss": 1.062,
      "step": 11300
    },
    {
      "epoch": 18.357487922705314,
      "grad_norm": 5.78023624420166,
      "learning_rate": 4.106280193236716e-06,
      "loss": 1.0715,
      "step": 11400
    },
    {
      "epoch": 18.51851851851852,
      "grad_norm": 6.6068878173828125,
      "learning_rate": 3.7037037037037037e-06,
      "loss": 1.0698,
      "step": 11500
    },
    {
      "epoch": 18.679549114331724,
      "grad_norm": 5.526206970214844,
      "learning_rate": 3.3011272141706927e-06,
      "loss": 1.0533,
      "step": 11600
    },
    {
      "epoch": 18.840579710144926,
      "grad_norm": 5.369484901428223,
      "learning_rate": 2.898550724637681e-06,
      "loss": 1.0722,
      "step": 11700
    },
    {
      "epoch": 19.0,
      "eval_loss": 0.9653410315513611,
      "eval_runtime": 2.2939,
      "eval_samples_per_second": 204.018,
      "eval_steps_per_second": 25.72,
      "step": 11799
    },
    {
      "epoch": 19.00161030595813,
      "grad_norm": 12.3502779006958,
      "learning_rate": 2.49597423510467e-06,
      "loss": 1.0586,
      "step": 11800
    },
    {
      "epoch": 19.162640901771336,
      "grad_norm": 6.021647930145264,
      "learning_rate": 2.0933977455716586e-06,
      "loss": 1.0701,
      "step": 11900
    },
    {
      "epoch": 19.32367149758454,
      "grad_norm": 4.360307693481445,
      "learning_rate": 1.6908212560386474e-06,
      "loss": 1.0529,
      "step": 12000
    },
    {
      "epoch": 19.484702093397747,
      "grad_norm": 4.933597564697266,
      "learning_rate": 1.288244766505636e-06,
      "loss": 1.0702,
      "step": 12100
    },
    {
      "epoch": 19.64573268921095,
      "grad_norm": 4.55692720413208,
      "learning_rate": 8.856682769726248e-07,
      "loss": 1.0564,
      "step": 12200
    },
    {
      "epoch": 19.806763285024154,
      "grad_norm": 5.182620525360107,
      "learning_rate": 4.830917874396135e-07,
      "loss": 1.063,
      "step": 12300
    },
    {
      "epoch": 19.96779388083736,
      "grad_norm": 5.395143985748291,
      "learning_rate": 8.051529790660226e-08,
      "loss": 1.0277,
      "step": 12400
    }
  ],
  "logging_steps": 100,
  "max_steps": 12420,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6141502007296e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
