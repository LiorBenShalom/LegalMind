{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 17640,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11337868480725624,
      "grad_norm": 6.027104377746582,
      "learning_rate": 4.971655328798186e-05,
      "loss": 4.9874,
      "step": 100
    },
    {
      "epoch": 0.22675736961451248,
      "grad_norm": 4.294640064239502,
      "learning_rate": 4.9433106575963725e-05,
      "loss": 4.8505,
      "step": 200
    },
    {
      "epoch": 0.3401360544217687,
      "grad_norm": 7.536070346832275,
      "learning_rate": 4.914965986394558e-05,
      "loss": 4.821,
      "step": 300
    },
    {
      "epoch": 0.45351473922902497,
      "grad_norm": 6.61704158782959,
      "learning_rate": 4.886621315192744e-05,
      "loss": 4.7997,
      "step": 400
    },
    {
      "epoch": 0.5668934240362812,
      "grad_norm": 5.517167568206787,
      "learning_rate": 4.85827664399093e-05,
      "loss": 4.7671,
      "step": 500
    },
    {
      "epoch": 0.6802721088435374,
      "grad_norm": 4.950119972229004,
      "learning_rate": 4.8299319727891155e-05,
      "loss": 4.7765,
      "step": 600
    },
    {
      "epoch": 0.7936507936507936,
      "grad_norm": 5.954761981964111,
      "learning_rate": 4.801587301587302e-05,
      "loss": 4.7937,
      "step": 700
    },
    {
      "epoch": 0.9070294784580499,
      "grad_norm": 4.494885444641113,
      "learning_rate": 4.773242630385488e-05,
      "loss": 4.7246,
      "step": 800
    },
    {
      "epoch": 1.0,
      "eval_loss": 4.43478536605835,
      "eval_runtime": 3.7524,
      "eval_samples_per_second": 203.336,
      "eval_steps_per_second": 25.584,
      "step": 882
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 4.334460258483887,
      "learning_rate": 4.744897959183674e-05,
      "loss": 4.6911,
      "step": 900
    },
    {
      "epoch": 1.1337868480725624,
      "grad_norm": 5.485892295837402,
      "learning_rate": 4.71655328798186e-05,
      "loss": 4.6236,
      "step": 1000
    },
    {
      "epoch": 1.2471655328798186,
      "grad_norm": 6.236968517303467,
      "learning_rate": 4.688208616780046e-05,
      "loss": 4.6081,
      "step": 1100
    },
    {
      "epoch": 1.3605442176870748,
      "grad_norm": 5.892882823944092,
      "learning_rate": 4.6598639455782315e-05,
      "loss": 4.6262,
      "step": 1200
    },
    {
      "epoch": 1.473922902494331,
      "grad_norm": 6.509307384490967,
      "learning_rate": 4.631519274376417e-05,
      "loss": 4.6158,
      "step": 1300
    },
    {
      "epoch": 1.5873015873015874,
      "grad_norm": 5.9601945877075195,
      "learning_rate": 4.603174603174603e-05,
      "loss": 4.5758,
      "step": 1400
    },
    {
      "epoch": 1.7006802721088436,
      "grad_norm": 5.6146931648254395,
      "learning_rate": 4.5748299319727895e-05,
      "loss": 4.5218,
      "step": 1500
    },
    {
      "epoch": 1.8140589569160999,
      "grad_norm": 5.04169225692749,
      "learning_rate": 4.546485260770975e-05,
      "loss": 4.3418,
      "step": 1600
    },
    {
      "epoch": 1.927437641723356,
      "grad_norm": 6.7006072998046875,
      "learning_rate": 4.518140589569162e-05,
      "loss": 4.3208,
      "step": 1700
    },
    {
      "epoch": 2.0,
      "eval_loss": 4.013889312744141,
      "eval_runtime": 3.6865,
      "eval_samples_per_second": 206.97,
      "eval_steps_per_second": 26.041,
      "step": 1764
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 6.600740432739258,
      "learning_rate": 4.4897959183673474e-05,
      "loss": 4.3213,
      "step": 1800
    },
    {
      "epoch": 2.1541950113378685,
      "grad_norm": 7.1390275955200195,
      "learning_rate": 4.461451247165533e-05,
      "loss": 4.2253,
      "step": 1900
    },
    {
      "epoch": 2.2675736961451247,
      "grad_norm": 7.690454483032227,
      "learning_rate": 4.433106575963719e-05,
      "loss": 4.094,
      "step": 2000
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 8.52344036102295,
      "learning_rate": 4.404761904761905e-05,
      "loss": 4.0424,
      "step": 2100
    },
    {
      "epoch": 2.494331065759637,
      "grad_norm": 7.194545269012451,
      "learning_rate": 4.376417233560091e-05,
      "loss": 3.9184,
      "step": 2200
    },
    {
      "epoch": 2.6077097505668934,
      "grad_norm": 8.149218559265137,
      "learning_rate": 4.348072562358277e-05,
      "loss": 3.9695,
      "step": 2300
    },
    {
      "epoch": 2.7210884353741496,
      "grad_norm": 7.684770107269287,
      "learning_rate": 4.319727891156463e-05,
      "loss": 3.8763,
      "step": 2400
    },
    {
      "epoch": 2.834467120181406,
      "grad_norm": 6.44078254699707,
      "learning_rate": 4.291383219954649e-05,
      "loss": 3.8517,
      "step": 2500
    },
    {
      "epoch": 2.947845804988662,
      "grad_norm": 8.970874786376953,
      "learning_rate": 4.263038548752835e-05,
      "loss": 3.6368,
      "step": 2600
    },
    {
      "epoch": 3.0,
      "eval_loss": 3.227980375289917,
      "eval_runtime": 3.7108,
      "eval_samples_per_second": 205.615,
      "eval_steps_per_second": 25.87,
      "step": 2646
    },
    {
      "epoch": 3.061224489795918,
      "grad_norm": 15.48202896118164,
      "learning_rate": 4.234693877551021e-05,
      "loss": 3.5091,
      "step": 2700
    },
    {
      "epoch": 3.1746031746031744,
      "grad_norm": 12.000862121582031,
      "learning_rate": 4.2063492063492065e-05,
      "loss": 3.304,
      "step": 2800
    },
    {
      "epoch": 3.287981859410431,
      "grad_norm": 9.654718399047852,
      "learning_rate": 4.178004535147392e-05,
      "loss": 3.0627,
      "step": 2900
    },
    {
      "epoch": 3.4013605442176873,
      "grad_norm": 10.747830390930176,
      "learning_rate": 4.149659863945579e-05,
      "loss": 2.8847,
      "step": 3000
    },
    {
      "epoch": 3.5147392290249435,
      "grad_norm": 12.429261207580566,
      "learning_rate": 4.1213151927437644e-05,
      "loss": 2.6803,
      "step": 3100
    },
    {
      "epoch": 3.6281179138321997,
      "grad_norm": 11.47896957397461,
      "learning_rate": 4.09297052154195e-05,
      "loss": 2.5007,
      "step": 3200
    },
    {
      "epoch": 3.741496598639456,
      "grad_norm": 11.745830535888672,
      "learning_rate": 4.0646258503401366e-05,
      "loss": 2.2783,
      "step": 3300
    },
    {
      "epoch": 3.854875283446712,
      "grad_norm": 10.300065994262695,
      "learning_rate": 4.036281179138322e-05,
      "loss": 2.1558,
      "step": 3400
    },
    {
      "epoch": 3.9682539682539684,
      "grad_norm": 10.563342094421387,
      "learning_rate": 4.007936507936508e-05,
      "loss": 2.0819,
      "step": 3500
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.6543315649032593,
      "eval_runtime": 3.6816,
      "eval_samples_per_second": 207.247,
      "eval_steps_per_second": 26.076,
      "step": 3528
    },
    {
      "epoch": 4.081632653061225,
      "grad_norm": 14.511330604553223,
      "learning_rate": 3.979591836734694e-05,
      "loss": 1.9455,
      "step": 3600
    },
    {
      "epoch": 4.195011337868481,
      "grad_norm": 10.80738639831543,
      "learning_rate": 3.95124716553288e-05,
      "loss": 1.8967,
      "step": 3700
    },
    {
      "epoch": 4.308390022675737,
      "grad_norm": 10.34873104095459,
      "learning_rate": 3.922902494331066e-05,
      "loss": 1.7789,
      "step": 3800
    },
    {
      "epoch": 4.421768707482993,
      "grad_norm": 10.524742126464844,
      "learning_rate": 3.894557823129252e-05,
      "loss": 1.7562,
      "step": 3900
    },
    {
      "epoch": 4.535147392290249,
      "grad_norm": 10.027032852172852,
      "learning_rate": 3.8662131519274384e-05,
      "loss": 1.7215,
      "step": 4000
    },
    {
      "epoch": 4.648526077097506,
      "grad_norm": 7.750009536743164,
      "learning_rate": 3.8378684807256235e-05,
      "loss": 1.6235,
      "step": 4100
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 9.11076831817627,
      "learning_rate": 3.809523809523809e-05,
      "loss": 1.6575,
      "step": 4200
    },
    {
      "epoch": 4.875283446712018,
      "grad_norm": 7.519784927368164,
      "learning_rate": 3.781179138321996e-05,
      "loss": 1.6318,
      "step": 4300
    },
    {
      "epoch": 4.988662131519274,
      "grad_norm": 9.47248363494873,
      "learning_rate": 3.7528344671201814e-05,
      "loss": 1.6237,
      "step": 4400
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.41038179397583,
      "eval_runtime": 3.7069,
      "eval_samples_per_second": 205.833,
      "eval_steps_per_second": 25.898,
      "step": 4410
    },
    {
      "epoch": 5.1020408163265305,
      "grad_norm": 7.3231096267700195,
      "learning_rate": 3.724489795918368e-05,
      "loss": 1.5725,
      "step": 4500
    },
    {
      "epoch": 5.215419501133787,
      "grad_norm": 6.950335502624512,
      "learning_rate": 3.6961451247165536e-05,
      "loss": 1.5483,
      "step": 4600
    },
    {
      "epoch": 5.328798185941043,
      "grad_norm": 8.493583679199219,
      "learning_rate": 3.6678004535147394e-05,
      "loss": 1.5423,
      "step": 4700
    },
    {
      "epoch": 5.442176870748299,
      "grad_norm": 7.049373149871826,
      "learning_rate": 3.639455782312925e-05,
      "loss": 1.4942,
      "step": 4800
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 6.686850070953369,
      "learning_rate": 3.611111111111111e-05,
      "loss": 1.5402,
      "step": 4900
    },
    {
      "epoch": 5.668934240362812,
      "grad_norm": 7.236340522766113,
      "learning_rate": 3.5827664399092974e-05,
      "loss": 1.4839,
      "step": 5000
    },
    {
      "epoch": 5.782312925170068,
      "grad_norm": 7.245247840881348,
      "learning_rate": 3.554421768707483e-05,
      "loss": 1.4977,
      "step": 5100
    },
    {
      "epoch": 5.895691609977324,
      "grad_norm": 6.835656642913818,
      "learning_rate": 3.526077097505669e-05,
      "loss": 1.4961,
      "step": 5200
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.3094717264175415,
      "eval_runtime": 3.6852,
      "eval_samples_per_second": 207.045,
      "eval_steps_per_second": 26.05,
      "step": 5292
    },
    {
      "epoch": 6.00907029478458,
      "grad_norm": 5.764326572418213,
      "learning_rate": 3.4977324263038554e-05,
      "loss": 1.4572,
      "step": 5300
    },
    {
      "epoch": 6.122448979591836,
      "grad_norm": 6.454386234283447,
      "learning_rate": 3.469387755102041e-05,
      "loss": 1.4283,
      "step": 5400
    },
    {
      "epoch": 6.235827664399093,
      "grad_norm": 6.825048923492432,
      "learning_rate": 3.441043083900227e-05,
      "loss": 1.4173,
      "step": 5500
    },
    {
      "epoch": 6.349206349206349,
      "grad_norm": 6.4525346755981445,
      "learning_rate": 3.412698412698413e-05,
      "loss": 1.4159,
      "step": 5600
    },
    {
      "epoch": 6.462585034013605,
      "grad_norm": 6.147701740264893,
      "learning_rate": 3.3843537414965984e-05,
      "loss": 1.4096,
      "step": 5700
    },
    {
      "epoch": 6.575963718820862,
      "grad_norm": 6.573841571807861,
      "learning_rate": 3.356009070294785e-05,
      "loss": 1.4472,
      "step": 5800
    },
    {
      "epoch": 6.6893424036281175,
      "grad_norm": 7.645493507385254,
      "learning_rate": 3.3276643990929706e-05,
      "loss": 1.4119,
      "step": 5900
    },
    {
      "epoch": 6.802721088435375,
      "grad_norm": 5.754786968231201,
      "learning_rate": 3.2993197278911564e-05,
      "loss": 1.3942,
      "step": 6000
    },
    {
      "epoch": 6.91609977324263,
      "grad_norm": 7.183341979980469,
      "learning_rate": 3.270975056689343e-05,
      "loss": 1.3987,
      "step": 6100
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.2301197052001953,
      "eval_runtime": 3.724,
      "eval_samples_per_second": 204.885,
      "eval_steps_per_second": 25.778,
      "step": 6174
    },
    {
      "epoch": 7.029478458049887,
      "grad_norm": 6.551328182220459,
      "learning_rate": 3.2426303854875286e-05,
      "loss": 1.3685,
      "step": 6200
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 6.07344388961792,
      "learning_rate": 3.2142857142857144e-05,
      "loss": 1.3836,
      "step": 6300
    },
    {
      "epoch": 7.2562358276643995,
      "grad_norm": 8.749151229858398,
      "learning_rate": 3.1859410430839e-05,
      "loss": 1.3309,
      "step": 6400
    },
    {
      "epoch": 7.369614512471656,
      "grad_norm": 6.6116108894348145,
      "learning_rate": 3.157596371882086e-05,
      "loss": 1.3657,
      "step": 6500
    },
    {
      "epoch": 7.482993197278912,
      "grad_norm": 10.664787292480469,
      "learning_rate": 3.1292517006802724e-05,
      "loss": 1.2841,
      "step": 6600
    },
    {
      "epoch": 7.596371882086168,
      "grad_norm": 7.802356243133545,
      "learning_rate": 3.100907029478458e-05,
      "loss": 1.3175,
      "step": 6700
    },
    {
      "epoch": 7.709750566893424,
      "grad_norm": 6.8671040534973145,
      "learning_rate": 3.0725623582766446e-05,
      "loss": 1.3504,
      "step": 6800
    },
    {
      "epoch": 7.8231292517006805,
      "grad_norm": 12.248555183410645,
      "learning_rate": 3.04421768707483e-05,
      "loss": 1.3045,
      "step": 6900
    },
    {
      "epoch": 7.936507936507937,
      "grad_norm": 5.925039768218994,
      "learning_rate": 3.0158730158730158e-05,
      "loss": 1.3352,
      "step": 7000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.209032654762268,
      "eval_runtime": 3.6835,
      "eval_samples_per_second": 207.142,
      "eval_steps_per_second": 26.062,
      "step": 7056
    },
    {
      "epoch": 8.049886621315192,
      "grad_norm": 5.492751598358154,
      "learning_rate": 2.9875283446712022e-05,
      "loss": 1.2993,
      "step": 7100
    },
    {
      "epoch": 8.16326530612245,
      "grad_norm": 7.597293376922607,
      "learning_rate": 2.959183673469388e-05,
      "loss": 1.2748,
      "step": 7200
    },
    {
      "epoch": 8.276643990929704,
      "grad_norm": 6.680474281311035,
      "learning_rate": 2.9308390022675734e-05,
      "loss": 1.3025,
      "step": 7300
    },
    {
      "epoch": 8.390022675736962,
      "grad_norm": 5.046880722045898,
      "learning_rate": 2.90249433106576e-05,
      "loss": 1.2777,
      "step": 7400
    },
    {
      "epoch": 8.503401360544217,
      "grad_norm": 6.613433837890625,
      "learning_rate": 2.8741496598639456e-05,
      "loss": 1.2826,
      "step": 7500
    },
    {
      "epoch": 8.616780045351474,
      "grad_norm": 6.366246700286865,
      "learning_rate": 2.8458049886621317e-05,
      "loss": 1.2619,
      "step": 7600
    },
    {
      "epoch": 8.73015873015873,
      "grad_norm": 6.095068454742432,
      "learning_rate": 2.8174603174603175e-05,
      "loss": 1.271,
      "step": 7700
    },
    {
      "epoch": 8.843537414965986,
      "grad_norm": 5.822577953338623,
      "learning_rate": 2.7891156462585033e-05,
      "loss": 1.3067,
      "step": 7800
    },
    {
      "epoch": 8.956916099773242,
      "grad_norm": 8.44662094116211,
      "learning_rate": 2.7607709750566897e-05,
      "loss": 1.305,
      "step": 7900
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.1602095365524292,
      "eval_runtime": 3.6815,
      "eval_samples_per_second": 207.253,
      "eval_steps_per_second": 26.076,
      "step": 7938
    },
    {
      "epoch": 9.070294784580499,
      "grad_norm": 7.643445014953613,
      "learning_rate": 2.732426303854875e-05,
      "loss": 1.2248,
      "step": 8000
    },
    {
      "epoch": 9.183673469387756,
      "grad_norm": 6.459489822387695,
      "learning_rate": 2.7040816326530616e-05,
      "loss": 1.2392,
      "step": 8100
    },
    {
      "epoch": 9.297052154195011,
      "grad_norm": 5.743943214416504,
      "learning_rate": 2.6757369614512473e-05,
      "loss": 1.2551,
      "step": 8200
    },
    {
      "epoch": 9.410430839002268,
      "grad_norm": 5.2578935623168945,
      "learning_rate": 2.647392290249433e-05,
      "loss": 1.2278,
      "step": 8300
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 6.488659858703613,
      "learning_rate": 2.6190476190476192e-05,
      "loss": 1.2202,
      "step": 8400
    },
    {
      "epoch": 9.63718820861678,
      "grad_norm": 6.745948791503906,
      "learning_rate": 2.590702947845805e-05,
      "loss": 1.2373,
      "step": 8500
    },
    {
      "epoch": 9.750566893424036,
      "grad_norm": 5.678566932678223,
      "learning_rate": 2.5623582766439914e-05,
      "loss": 1.2311,
      "step": 8600
    },
    {
      "epoch": 9.863945578231293,
      "grad_norm": 5.350887775421143,
      "learning_rate": 2.534013605442177e-05,
      "loss": 1.2325,
      "step": 8700
    },
    {
      "epoch": 9.977324263038549,
      "grad_norm": 6.468733310699463,
      "learning_rate": 2.5056689342403626e-05,
      "loss": 1.2584,
      "step": 8800
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.1315664052963257,
      "eval_runtime": 3.726,
      "eval_samples_per_second": 204.78,
      "eval_steps_per_second": 25.765,
      "step": 8820
    },
    {
      "epoch": 10.090702947845806,
      "grad_norm": 6.449577331542969,
      "learning_rate": 2.4773242630385487e-05,
      "loss": 1.2281,
      "step": 8900
    },
    {
      "epoch": 10.204081632653061,
      "grad_norm": 6.975862503051758,
      "learning_rate": 2.448979591836735e-05,
      "loss": 1.193,
      "step": 9000
    },
    {
      "epoch": 10.317460317460318,
      "grad_norm": 6.318471431732178,
      "learning_rate": 2.4206349206349206e-05,
      "loss": 1.1912,
      "step": 9100
    },
    {
      "epoch": 10.430839002267573,
      "grad_norm": 5.354465007781982,
      "learning_rate": 2.3922902494331067e-05,
      "loss": 1.2056,
      "step": 9200
    },
    {
      "epoch": 10.54421768707483,
      "grad_norm": 6.379837989807129,
      "learning_rate": 2.3639455782312928e-05,
      "loss": 1.1911,
      "step": 9300
    },
    {
      "epoch": 10.657596371882086,
      "grad_norm": 6.278853893280029,
      "learning_rate": 2.3356009070294786e-05,
      "loss": 1.2218,
      "step": 9400
    },
    {
      "epoch": 10.770975056689343,
      "grad_norm": 6.387054920196533,
      "learning_rate": 2.3072562358276644e-05,
      "loss": 1.1934,
      "step": 9500
    },
    {
      "epoch": 10.884353741496598,
      "grad_norm": 7.172741413116455,
      "learning_rate": 2.2789115646258505e-05,
      "loss": 1.1861,
      "step": 9600
    },
    {
      "epoch": 10.997732426303855,
      "grad_norm": 5.649715423583984,
      "learning_rate": 2.2505668934240366e-05,
      "loss": 1.1795,
      "step": 9700
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.0898724794387817,
      "eval_runtime": 3.6888,
      "eval_samples_per_second": 206.84,
      "eval_steps_per_second": 26.024,
      "step": 9702
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 18.342121124267578,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 1.1746,
      "step": 9800
    },
    {
      "epoch": 11.224489795918368,
      "grad_norm": 7.0818891525268555,
      "learning_rate": 2.193877551020408e-05,
      "loss": 1.1425,
      "step": 9900
    },
    {
      "epoch": 11.337868480725623,
      "grad_norm": 4.894710063934326,
      "learning_rate": 2.1655328798185942e-05,
      "loss": 1.1729,
      "step": 10000
    },
    {
      "epoch": 11.45124716553288,
      "grad_norm": 6.288606643676758,
      "learning_rate": 2.1371882086167803e-05,
      "loss": 1.1567,
      "step": 10100
    },
    {
      "epoch": 11.564625850340136,
      "grad_norm": 5.719718933105469,
      "learning_rate": 2.108843537414966e-05,
      "loss": 1.1425,
      "step": 10200
    },
    {
      "epoch": 11.678004535147393,
      "grad_norm": 8.491762161254883,
      "learning_rate": 2.080498866213152e-05,
      "loss": 1.1686,
      "step": 10300
    },
    {
      "epoch": 11.791383219954648,
      "grad_norm": 5.876428127288818,
      "learning_rate": 2.052154195011338e-05,
      "loss": 1.1669,
      "step": 10400
    },
    {
      "epoch": 11.904761904761905,
      "grad_norm": 6.075804710388184,
      "learning_rate": 2.023809523809524e-05,
      "loss": 1.1697,
      "step": 10500
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.05331289768219,
      "eval_runtime": 3.6861,
      "eval_samples_per_second": 206.996,
      "eval_steps_per_second": 26.044,
      "step": 10584
    },
    {
      "epoch": 12.01814058956916,
      "grad_norm": 6.6972336769104,
      "learning_rate": 1.9954648526077098e-05,
      "loss": 1.1867,
      "step": 10600
    },
    {
      "epoch": 12.131519274376418,
      "grad_norm": 7.193966388702393,
      "learning_rate": 1.9671201814058956e-05,
      "loss": 1.1691,
      "step": 10700
    },
    {
      "epoch": 12.244897959183673,
      "grad_norm": 5.129908084869385,
      "learning_rate": 1.9387755102040817e-05,
      "loss": 1.158,
      "step": 10800
    },
    {
      "epoch": 12.35827664399093,
      "grad_norm": 5.542757034301758,
      "learning_rate": 1.9104308390022678e-05,
      "loss": 1.1471,
      "step": 10900
    },
    {
      "epoch": 12.471655328798185,
      "grad_norm": 6.100045204162598,
      "learning_rate": 1.8820861678004536e-05,
      "loss": 1.1548,
      "step": 11000
    },
    {
      "epoch": 12.585034013605442,
      "grad_norm": 6.258656024932861,
      "learning_rate": 1.8537414965986397e-05,
      "loss": 1.1547,
      "step": 11100
    },
    {
      "epoch": 12.698412698412698,
      "grad_norm": 6.2342939376831055,
      "learning_rate": 1.8253968253968254e-05,
      "loss": 1.115,
      "step": 11200
    },
    {
      "epoch": 12.811791383219955,
      "grad_norm": 9.279199600219727,
      "learning_rate": 1.7970521541950115e-05,
      "loss": 1.1205,
      "step": 11300
    },
    {
      "epoch": 12.92517006802721,
      "grad_norm": 7.485772609710693,
      "learning_rate": 1.7687074829931973e-05,
      "loss": 1.1224,
      "step": 11400
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.0216610431671143,
      "eval_runtime": 3.6899,
      "eval_samples_per_second": 206.779,
      "eval_steps_per_second": 26.017,
      "step": 11466
    },
    {
      "epoch": 13.038548752834467,
      "grad_norm": 7.163214683532715,
      "learning_rate": 1.7403628117913834e-05,
      "loss": 1.1078,
      "step": 11500
    },
    {
      "epoch": 13.151927437641723,
      "grad_norm": 4.889723777770996,
      "learning_rate": 1.7120181405895692e-05,
      "loss": 1.1322,
      "step": 11600
    },
    {
      "epoch": 13.26530612244898,
      "grad_norm": 5.788083076477051,
      "learning_rate": 1.683673469387755e-05,
      "loss": 1.1112,
      "step": 11700
    },
    {
      "epoch": 13.378684807256235,
      "grad_norm": 5.42486572265625,
      "learning_rate": 1.655328798185941e-05,
      "loss": 1.1035,
      "step": 11800
    },
    {
      "epoch": 13.492063492063492,
      "grad_norm": 4.556550025939941,
      "learning_rate": 1.626984126984127e-05,
      "loss": 1.1141,
      "step": 11900
    },
    {
      "epoch": 13.60544217687075,
      "grad_norm": 6.10031270980835,
      "learning_rate": 1.5986394557823133e-05,
      "loss": 1.1257,
      "step": 12000
    },
    {
      "epoch": 13.718820861678005,
      "grad_norm": 5.9269490242004395,
      "learning_rate": 1.5702947845804987e-05,
      "loss": 1.1331,
      "step": 12100
    },
    {
      "epoch": 13.83219954648526,
      "grad_norm": 5.535986423492432,
      "learning_rate": 1.5419501133786848e-05,
      "loss": 1.0905,
      "step": 12200
    },
    {
      "epoch": 13.945578231292517,
      "grad_norm": 6.400557994842529,
      "learning_rate": 1.5136054421768709e-05,
      "loss": 1.0872,
      "step": 12300
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.03401517868042,
      "eval_runtime": 3.6846,
      "eval_samples_per_second": 207.078,
      "eval_steps_per_second": 26.054,
      "step": 12348
    },
    {
      "epoch": 14.058956916099774,
      "grad_norm": 6.279899597167969,
      "learning_rate": 1.4852607709750568e-05,
      "loss": 1.1083,
      "step": 12400
    },
    {
      "epoch": 14.17233560090703,
      "grad_norm": 7.180805206298828,
      "learning_rate": 1.4569160997732428e-05,
      "loss": 1.0769,
      "step": 12500
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 5.644887924194336,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 1.0849,
      "step": 12600
    },
    {
      "epoch": 14.399092970521542,
      "grad_norm": 4.910469055175781,
      "learning_rate": 1.4002267573696145e-05,
      "loss": 1.0824,
      "step": 12700
    },
    {
      "epoch": 14.512471655328799,
      "grad_norm": 6.600747585296631,
      "learning_rate": 1.3718820861678006e-05,
      "loss": 1.0901,
      "step": 12800
    },
    {
      "epoch": 14.625850340136054,
      "grad_norm": 5.948789119720459,
      "learning_rate": 1.3435374149659865e-05,
      "loss": 1.0821,
      "step": 12900
    },
    {
      "epoch": 14.739229024943311,
      "grad_norm": 5.647185802459717,
      "learning_rate": 1.3151927437641723e-05,
      "loss": 1.0936,
      "step": 13000
    },
    {
      "epoch": 14.852607709750567,
      "grad_norm": 5.145318508148193,
      "learning_rate": 1.2868480725623582e-05,
      "loss": 1.0951,
      "step": 13100
    },
    {
      "epoch": 14.965986394557824,
      "grad_norm": 6.750669002532959,
      "learning_rate": 1.2585034013605443e-05,
      "loss": 1.097,
      "step": 13200
    },
    {
      "epoch": 15.0,
      "eval_loss": 0.9749947786331177,
      "eval_runtime": 3.7079,
      "eval_samples_per_second": 205.774,
      "eval_steps_per_second": 25.89,
      "step": 13230
    },
    {
      "epoch": 15.079365079365079,
      "grad_norm": 7.356658458709717,
      "learning_rate": 1.2301587301587301e-05,
      "loss": 1.1008,
      "step": 13300
    },
    {
      "epoch": 15.192743764172336,
      "grad_norm": 6.188194751739502,
      "learning_rate": 1.2018140589569162e-05,
      "loss": 1.0827,
      "step": 13400
    },
    {
      "epoch": 15.306122448979592,
      "grad_norm": 5.795267105102539,
      "learning_rate": 1.1734693877551021e-05,
      "loss": 1.0815,
      "step": 13500
    },
    {
      "epoch": 15.419501133786849,
      "grad_norm": 4.683194637298584,
      "learning_rate": 1.145124716553288e-05,
      "loss": 1.0774,
      "step": 13600
    },
    {
      "epoch": 15.532879818594104,
      "grad_norm": 7.093980312347412,
      "learning_rate": 1.116780045351474e-05,
      "loss": 1.031,
      "step": 13700
    },
    {
      "epoch": 15.646258503401361,
      "grad_norm": 7.161130905151367,
      "learning_rate": 1.08843537414966e-05,
      "loss": 1.0469,
      "step": 13800
    },
    {
      "epoch": 15.759637188208616,
      "grad_norm": 5.680654048919678,
      "learning_rate": 1.0600907029478459e-05,
      "loss": 1.069,
      "step": 13900
    },
    {
      "epoch": 15.873015873015873,
      "grad_norm": 5.808386325836182,
      "learning_rate": 1.0317460317460318e-05,
      "loss": 1.0698,
      "step": 14000
    },
    {
      "epoch": 15.986394557823129,
      "grad_norm": 5.780760288238525,
      "learning_rate": 1.0034013605442178e-05,
      "loss": 1.0848,
      "step": 14100
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.9468830227851868,
      "eval_runtime": 3.7121,
      "eval_samples_per_second": 205.545,
      "eval_steps_per_second": 25.861,
      "step": 14112
    },
    {
      "epoch": 16.099773242630384,
      "grad_norm": 5.907843589782715,
      "learning_rate": 9.750566893424037e-06,
      "loss": 1.055,
      "step": 14200
    },
    {
      "epoch": 16.213151927437643,
      "grad_norm": 6.5748820304870605,
      "learning_rate": 9.467120181405896e-06,
      "loss": 1.0697,
      "step": 14300
    },
    {
      "epoch": 16.3265306122449,
      "grad_norm": 6.9682769775390625,
      "learning_rate": 9.183673469387756e-06,
      "loss": 1.0461,
      "step": 14400
    },
    {
      "epoch": 16.439909297052154,
      "grad_norm": 4.3152079582214355,
      "learning_rate": 8.900226757369615e-06,
      "loss": 1.0682,
      "step": 14500
    },
    {
      "epoch": 16.55328798185941,
      "grad_norm": 6.03415584564209,
      "learning_rate": 8.616780045351474e-06,
      "loss": 1.0572,
      "step": 14600
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 5.642674922943115,
      "learning_rate": 8.333333333333334e-06,
      "loss": 1.0589,
      "step": 14700
    },
    {
      "epoch": 16.780045351473923,
      "grad_norm": 5.953596591949463,
      "learning_rate": 8.049886621315193e-06,
      "loss": 1.0595,
      "step": 14800
    },
    {
      "epoch": 16.89342403628118,
      "grad_norm": 6.533293724060059,
      "learning_rate": 7.766439909297052e-06,
      "loss": 1.0672,
      "step": 14900
    },
    {
      "epoch": 17.0,
      "eval_loss": 0.9284417629241943,
      "eval_runtime": 3.6868,
      "eval_samples_per_second": 206.953,
      "eval_steps_per_second": 26.039,
      "step": 14994
    },
    {
      "epoch": 17.006802721088434,
      "grad_norm": 7.383225917816162,
      "learning_rate": 7.482993197278912e-06,
      "loss": 1.0838,
      "step": 15000
    },
    {
      "epoch": 17.120181405895693,
      "grad_norm": 8.244114875793457,
      "learning_rate": 7.199546485260772e-06,
      "loss": 1.042,
      "step": 15100
    },
    {
      "epoch": 17.233560090702948,
      "grad_norm": 33.508880615234375,
      "learning_rate": 6.9160997732426305e-06,
      "loss": 1.0409,
      "step": 15200
    },
    {
      "epoch": 17.346938775510203,
      "grad_norm": 5.0255656242370605,
      "learning_rate": 6.632653061224491e-06,
      "loss": 1.0264,
      "step": 15300
    },
    {
      "epoch": 17.46031746031746,
      "grad_norm": 6.4291791915893555,
      "learning_rate": 6.349206349206349e-06,
      "loss": 1.0405,
      "step": 15400
    },
    {
      "epoch": 17.573696145124718,
      "grad_norm": 5.062648773193359,
      "learning_rate": 6.0657596371882095e-06,
      "loss": 1.0271,
      "step": 15500
    },
    {
      "epoch": 17.687074829931973,
      "grad_norm": 5.258663654327393,
      "learning_rate": 5.782312925170069e-06,
      "loss": 1.062,
      "step": 15600
    },
    {
      "epoch": 17.800453514739228,
      "grad_norm": 6.597703456878662,
      "learning_rate": 5.498866213151928e-06,
      "loss": 1.0512,
      "step": 15700
    },
    {
      "epoch": 17.913832199546484,
      "grad_norm": 5.9516777992248535,
      "learning_rate": 5.215419501133787e-06,
      "loss": 1.0413,
      "step": 15800
    },
    {
      "epoch": 18.0,
      "eval_loss": 0.9571252465248108,
      "eval_runtime": 3.7038,
      "eval_samples_per_second": 206.007,
      "eval_steps_per_second": 25.92,
      "step": 15876
    },
    {
      "epoch": 18.027210884353742,
      "grad_norm": 6.597229480743408,
      "learning_rate": 4.931972789115646e-06,
      "loss": 1.0313,
      "step": 15900
    },
    {
      "epoch": 18.140589569160998,
      "grad_norm": 5.846039772033691,
      "learning_rate": 4.6485260770975054e-06,
      "loss": 1.0246,
      "step": 16000
    },
    {
      "epoch": 18.253968253968253,
      "grad_norm": 6.321107864379883,
      "learning_rate": 4.365079365079365e-06,
      "loss": 1.0466,
      "step": 16100
    },
    {
      "epoch": 18.367346938775512,
      "grad_norm": 6.78146505355835,
      "learning_rate": 4.081632653061224e-06,
      "loss": 1.0386,
      "step": 16200
    },
    {
      "epoch": 18.480725623582767,
      "grad_norm": 4.6055707931518555,
      "learning_rate": 3.7981859410430844e-06,
      "loss": 1.0548,
      "step": 16300
    },
    {
      "epoch": 18.594104308390023,
      "grad_norm": 5.645637512207031,
      "learning_rate": 3.5147392290249437e-06,
      "loss": 1.0243,
      "step": 16400
    },
    {
      "epoch": 18.707482993197278,
      "grad_norm": 5.072022914886475,
      "learning_rate": 3.231292517006803e-06,
      "loss": 1.0188,
      "step": 16500
    },
    {
      "epoch": 18.820861678004537,
      "grad_norm": 5.936455249786377,
      "learning_rate": 2.9478458049886625e-06,
      "loss": 1.0285,
      "step": 16600
    },
    {
      "epoch": 18.934240362811792,
      "grad_norm": 6.726651668548584,
      "learning_rate": 2.664399092970522e-06,
      "loss": 1.0208,
      "step": 16700
    },
    {
      "epoch": 19.0,
      "eval_loss": 0.9294476509094238,
      "eval_runtime": 3.702,
      "eval_samples_per_second": 206.105,
      "eval_steps_per_second": 25.932,
      "step": 16758
    },
    {
      "epoch": 19.047619047619047,
      "grad_norm": 5.396237850189209,
      "learning_rate": 2.3809523809523808e-06,
      "loss": 1.0183,
      "step": 16800
    },
    {
      "epoch": 19.160997732426303,
      "grad_norm": 5.384241580963135,
      "learning_rate": 2.0975056689342405e-06,
      "loss": 1.0291,
      "step": 16900
    },
    {
      "epoch": 19.27437641723356,
      "grad_norm": 4.638104438781738,
      "learning_rate": 1.8140589569161e-06,
      "loss": 1.0279,
      "step": 17000
    },
    {
      "epoch": 19.387755102040817,
      "grad_norm": 5.747803211212158,
      "learning_rate": 1.5306122448979593e-06,
      "loss": 1.0245,
      "step": 17100
    },
    {
      "epoch": 19.501133786848072,
      "grad_norm": 4.465655326843262,
      "learning_rate": 1.2471655328798186e-06,
      "loss": 1.0384,
      "step": 17200
    },
    {
      "epoch": 19.614512471655328,
      "grad_norm": 5.824102401733398,
      "learning_rate": 9.63718820861678e-07,
      "loss": 1.0057,
      "step": 17300
    },
    {
      "epoch": 19.727891156462587,
      "grad_norm": 5.313168525695801,
      "learning_rate": 6.802721088435375e-07,
      "loss": 1.0046,
      "step": 17400
    },
    {
      "epoch": 19.841269841269842,
      "grad_norm": 5.462247848510742,
      "learning_rate": 3.9682539682539683e-07,
      "loss": 1.0309,
      "step": 17500
    },
    {
      "epoch": 19.954648526077097,
      "grad_norm": 6.283760070800781,
      "learning_rate": 1.1337868480725624e-07,
      "loss": 1.0558,
      "step": 17600
    }
  ],
  "logging_steps": 100,
  "max_steps": 17640,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.7127670893568e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
