{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts= \"/home/liorkob/thesis/lcp/processed_verdicts_with_gpt.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "הנאשם הורשע על פי הכרעת דין בעבירות של חבלה בכוונה מחמירה לפי סעיף 329(א)(1)+(2) לחוק העונשין, התשל\"ז-1977 והחזקת ונשיאת נשק ותחמושת לפי סעיפים 144(א) רישא וסיפא + 144(ב) רישא וסיפא לחוק העונשין. כאמור בהכרעת הדין על רקע סכסוך משפחתי הגיע הנאשם מול ביתו של המתלונן כשהוא ואחיו שיפצו קיר מחוץ לבית, כאשר הוא הוסע במכונית על ידי אחר וירה עליהם באמצעות נשק חם- תת מקלע. כדור אחד פגע ברגלו של המתלונן. המתלונן אושפז למשך חמישה ימים ועבר מספר ניתוחים.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def load_text_for_verdict(df, verdict, part):\n",
    "    # Filter the DataFrame for the specific verdict\n",
    "    verdict_df = df[df['verdict'] == verdict]\n",
    "    \n",
    "    # Extract the text column based on the 'part' (can be 'extracted_facts' or 'extracted_gpt_facts')\n",
    "    text = \" \".join(verdict_df[part].values)\n",
    "    \n",
    "    # Slice the text based on start_part and end_part indices (if they are numerical)\n",
    "    return text\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"/home/liorkob/thesis/lcp/processed_verdicts_with_gpt.csv\")  \n",
    "\n",
    "# Parameters\n",
    "part = 'extracted_gpt_facts'  # Define the part to extract features from\n",
    "\n",
    "# Load text for each verdict (A, B, C)\n",
    "text_a = load_text_for_verdict(df, 'ת\"פ 16420-10-16', part)\n",
    "text_b = load_text_for_verdict(df, 'ת\"פ 40313-09-15', part)\n",
    "text_c = load_text_for_verdict(df, 'ת\"פ 1995-03-17', part)\n",
    "print(text_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant Features: set()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_matrix = vectorizer.fit_transform([text_a, text_b, text_c])\n",
    "\n",
    "# Get feature names\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Extract important tokens\n",
    "a_b_common = set(features[tfidf_matrix[0].toarray().argsort()[0][-10:]]) & \\\n",
    "             set(features[tfidf_matrix[1].toarray().argsort()[0][-10:]])\n",
    "a_c_diff = set(features[tfidf_matrix[0].toarray().argsort()[0][-10:]]) - \\\n",
    "           set(features[tfidf_matrix[2].toarray().argsort()[0][-10:]])\n",
    "\n",
    "# Significant features\n",
    "significant_features = a_b_common - a_c_diff\n",
    "print(\"Significant Features:\", significant_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at avichr/Legal-heBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'text_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavichr/Legal-heBERT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Tokenize inputs\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[43mtext_a\u001b[49m, text_b, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Forward pass with output_attentions=True\u001b[39;00m\n\u001b[1;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_a' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"avichr/Legal-heBERT\")\n",
    "model = AutoModel.from_pretrained(\"avichr/Legal-heBERT\")\n",
    "\n",
    "# Tokenize inputs\n",
    "inputs = tokenizer(text_a, text_b, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "# Forward pass with output_attentions=True\n",
    "outputs = model(**inputs, output_attentions=True)\n",
    "\n",
    "# Get attention weights from the last layer\n",
    "attention_weights = outputs.attentions[-1]  # shape: (batch_size, num_heads, seq_len, seq_len)\n",
    "print(\"Attention weights shape:\", attention_weights.shape)\n",
    "\n",
    "# Average over heads\n",
    "avg_attention = attention_weights[0].mean(dim=0).detach().numpy()\n",
    "\n",
    "# Convert tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(avg_attention, xticklabels=tokens, yticklabels=tokens, cmap='viridis')\n",
    "plt.title(\"Average Attention - Last Layer\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f0538d3a4f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/liorkob/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "duplicate registrations for aten.linspace.Tensor_Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get average attention across all heads\u001b[39;00m\n\u001b[1;32m      4\u001b[0m avg_attention \u001b[38;5;241m=\u001b[39m attention_weights[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# (seq_len, seq_len)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/lcp/lib/python3.9/site-packages/torch/__init__.py:2604\u001b[0m\n\u001b[1;32m   2600\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n\u001b[1;32m   2603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m-> 2604\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[1;32m   2606\u001b[0m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCH_CUDA_SANITIZER\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "File \u001b[0;32m~/.conda/envs/lcp/lib/python3.9/site-packages/torch/_meta_registrations.py:99\u001b[0m\n\u001b[1;32m     90\u001b[0m     broadcasted_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_broadcast_shapes(self_shape, \u001b[38;5;241m*\u001b[39margs_shape))\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_check(\n\u001b[1;32m     92\u001b[0m         broadcasted_shape \u001b[38;5;241m==\u001b[39m self_shape,\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mself_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match the broadcast shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbroadcasted_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m     )\n\u001b[1;32m     97\u001b[0m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43maten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogspace\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;129;43m@out_wrapper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43mmeta_linspace_logspace\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrided\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlinspace only supports 0-dimensional start and end tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/lcp/lib/python3.9/site-packages/torch/_meta_registrations.py:54\u001b[0m, in \u001b[0;36mregister_meta.<locals>.wrapper\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mregister\u001b[39m(op):\n\u001b[1;32m     52\u001b[0m     _add_op_to_registry(meta_table, op, fn)\n\u001b[0;32m---> 54\u001b[0m \u001b[43mpytree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregister\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "File \u001b[0;32m~/.conda/envs/lcp/lib/python3.9/site-packages/torch/utils/_pytree.py:1024\u001b[0m, in \u001b[0;36mtree_map_\u001b[0;34m(func, tree, is_leaf, *rests)\u001b[0m\n\u001b[1;32m   1022\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf\u001b[38;5;241m=\u001b[39mis_leaf)\n\u001b[1;32m   1023\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m-> 1024\u001b[0m \u001b[43mdeque\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# consume and exhaust the iterable\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/.conda/envs/lcp/lib/python3.9/site-packages/torch/_meta_registrations.py:52\u001b[0m, in \u001b[0;36mregister_meta.<locals>.wrapper.<locals>.register\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mregister\u001b[39m(op):\n\u001b[0;32m---> 52\u001b[0m     \u001b[43m_add_op_to_registry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/lcp/lib/python3.9/site-packages/torch/_decomp/__init__.py:95\u001b[0m, in \u001b[0;36m_add_op_to_registry\u001b[0;34m(registry, op, fn)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op_overload \u001b[38;5;129;01min\u001b[39;00m overloads:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op_overload \u001b[38;5;129;01min\u001b[39;00m registry:\n\u001b[0;32m---> 95\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduplicate registrations for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_overload\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# TorchScript dumps a bunch of extra nonsense overloads\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# which don't have corresponding dispatcher entries, we need\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# to filter those out, e.g aten.add.float_int\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dispatch_has_kernel(op_overload\u001b[38;5;241m.\u001b[39mname()):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: duplicate registrations for aten.linspace.Tensor_Tensor"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get average attention across all heads\n",
    "avg_attention = attention_weights[0].mean(dim=0)  # (seq_len, seq_len)\n",
    "\n",
    "# Sum attention received by each token (columns)\n",
    "attention_to_token = avg_attention.sum(dim=0)\n",
    "\n",
    "# Get top tokens by attention score\n",
    "topk = torch.topk(attention_to_token, k=10)\n",
    "top_token_indices = topk.indices.tolist()\n",
    "top_tokens = [tokens[i] for i in top_token_indices]\n",
    "\n",
    "import re\n",
    "\n",
    "def is_informative(token):\n",
    "    return token not in ['[CLS]', '[SEP]'] and not re.fullmatch(r'[.,!?״׳:;…\"\\-(){}\\[\\]]+', token)\n",
    "\n",
    "# Filter top tokens\n",
    "filtered_top_tokens = [t for t in top_tokens if is_informative(t)]\n",
    "print(\"Filtered top-attended tokens:\", filtered_top_tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
