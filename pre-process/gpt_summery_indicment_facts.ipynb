{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing: 100%|██████████| 2987/2987 [2:39:39<00:00,  3.21s/it]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ========== Setup ==========\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"  \n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/home/liorkob/M.Sc/thesis/data/drugs_3k/gpt/processed_verdicts_with_gpt.csv\")\n",
    "facts = df[\"extracted_gpt_facts\"].dropna().tolist()\n",
    "\n",
    "\n",
    "# פונקציית סיכום\n",
    "def summarize_with_gpt(text, model=\"gpt-4.1-mini\"):\n",
    "    text = text.strip()\n",
    "    prompt = f\"\"\"סכם בקצרה ובבהירות את העובדות של כתב האישום הבא. המטרה היא לתמצת למקסימום שני משפטים שמתארים את המקרה בצורה הטובה ביותר:\n",
    "{text}\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model, \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"אתה מודל בינה מלאכותית שתפקידו לסכם עובדות כתב אישום מתיקים פליליים.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=1,\n",
    "            max_tokens=150\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "    # הפעלת הסיכום על כל הקלטים\n",
    "summaries = []\n",
    "for text in tqdm(facts, desc=\"Summarizing\"):\n",
    "    summary = summarize_with_gpt(text)\n",
    "    summaries.append(summary)\n",
    "    time.sleep(1.2)  # להימנע מ-rate limit\n",
    "\n",
    "# שמירת הקובץ\n",
    "df = df[df[\"extracted_gpt_facts\"].notna()].copy()\n",
    "df[\"summary\"] = summaries\n",
    "df[[\"extracted_gpt_facts\", \"summary\"]].to_csv(\"/home/liorkob/M.Sc/thesis/data/drugs_3k/gpt/summarization_dataset.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
