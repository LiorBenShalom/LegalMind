{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 15:53:00,429 - INFO - üöÄ Starting data splitting pipeline...\n",
      "2025-08-03 15:53:00,431 - INFO - Loading original data files...\n",
      "2025-08-03 15:53:01,151 - INFO - Loaded 4052 train + 869 val + 870 test = 5791 total samples\n",
      "2025-08-03 15:53:01,159 - INFO - Label distribution: {0: np.int64(3857), 1: np.int64(1934)}\n",
      "2025-08-03 15:53:01,160 - INFO - Class balance: 33.4% positive\n",
      "2025-08-03 15:53:01,160 - INFO - Creating 5-fold stratified splits...\n",
      "2025-08-03 15:53:01,178 - INFO - Fold 1: Train=3705, Val=927, Test=1159\n",
      "2025-08-03 15:53:01,179 - INFO -   Positive ratios - Train: 0.334, Val: 0.334, Test: 0.334\n",
      "2025-08-03 15:53:01,187 - INFO - Fold 2: Train=3706, Val=927, Test=1158\n",
      "2025-08-03 15:53:01,188 - INFO -   Positive ratios - Train: 0.334, Val: 0.334, Test: 0.332\n",
      "2025-08-03 15:53:01,197 - INFO - Fold 3: Train=3706, Val=927, Test=1158\n",
      "2025-08-03 15:53:01,198 - INFO -   Positive ratios - Train: 0.330, Val: 0.330, Test: 0.350\n",
      "2025-08-03 15:53:01,207 - INFO - Fold 4: Train=3706, Val=927, Test=1158\n",
      "2025-08-03 15:53:01,207 - INFO -   Positive ratios - Train: 0.334, Val: 0.334, Test: 0.333\n",
      "2025-08-03 15:53:01,216 - INFO - Fold 5: Train=3706, Val=927, Test=1158\n",
      "2025-08-03 15:53:01,217 - INFO -   Positive ratios - Train: 0.337, Val: 0.338, Test: 0.320\n",
      "2025-08-03 15:53:01,219 - INFO - Saving fold data to CSV files...\n",
      "2025-08-03 15:53:01,874 - INFO - Saved fold 1: 3705 train, 927 val, 1159 test\n",
      "2025-08-03 15:53:02,522 - INFO - Saved fold 2: 3706 train, 927 val, 1158 test\n",
      "2025-08-03 15:53:03,158 - INFO - Saved fold 3: 3706 train, 927 val, 1158 test\n",
      "2025-08-03 15:53:03,815 - INFO - Saved fold 4: 3706 train, 927 val, 1158 test\n",
      "2025-08-03 15:53:04,452 - INFO - Saved fold 5: 3706 train, 927 val, 1158 test\n",
      "2025-08-03 15:53:04,453 - INFO - Saving original data splits...\n",
      "2025-08-03 15:53:05,689 - INFO - Saved original splits to data_splits_5fold/original\n",
      "2025-08-03 15:53:05,729 - INFO - Saved fold information to data_splits_5fold/fold_info.json\n",
      "2025-08-03 15:53:05,730 - INFO - Creating summary statistics...\n",
      "2025-08-03 15:53:05,734 - INFO - ‚úÖ Data splitting pipeline completed successfully!\n",
      "2025-08-03 15:53:05,734 - INFO - üìÅ Data splits saved to: /mnt/new_home/liorkob/M.Sc/thesis/citation-prediction/data_splits_5fold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä FOLD SUMMARY STATISTICS\n",
      "============================================================\n",
      "Average sizes: Train=3706, Val=927, Test=1158\n",
      "Positive class ratios:\n",
      "  Train: 0.334 ¬± 0.002\n",
      "  Val:   0.334 ¬± 0.002\n",
      "  Test:  0.334 ¬± 0.009\n",
      "\n",
      "üéØ PIPELINE COMPLETE!\n",
      "Created 5 folds with consistent stratified splits\n",
      "Each fold maintains similar class distributions\n",
      "Ready for reproducible cross-validation experiments!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Data Splitter for 5-Fold Cross-Validation\n",
    "==========================================\n",
    "\n",
    "Creates consistent train/val/test splits for 5-fold CV experiments.\n",
    "Saves each fold as separate CSV files for reproducible experiments.\n",
    "\n",
    "Usage:\n",
    "    python create_data_splits.py\n",
    "    \n",
    "Output:\n",
    "    data_splits/\n",
    "    ‚îú‚îÄ‚îÄ original/\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ train.csv\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ val.csv\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ test.csv\n",
    "    ‚îú‚îÄ‚îÄ fold_1/\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ train.csv\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ val.csv\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ test.csv\n",
    "    ‚îú‚îÄ‚îÄ fold_2/\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ train.csv\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ val.csv\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ test.csv\n",
    "    ‚îú‚îÄ‚îÄ ...\n",
    "    ‚îî‚îÄ‚îÄ fold_info.json\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DataSplitter:\n",
    "    def __init__(self, \n",
    "                 train_file: str,\n",
    "                 val_file: str, \n",
    "                 test_file: str,\n",
    "                 output_dir: str = \"data_splits\",\n",
    "                 n_folds: int = 5,\n",
    "                 random_seed: int = 42,\n",
    "                 val_split_ratio: float = 0.2):\n",
    "        \"\"\"\n",
    "        Initialize DataSplitter\n",
    "        \n",
    "        Args:\n",
    "            train_file: Path to original training CSV\n",
    "            val_file: Path to original validation CSV  \n",
    "            test_file: Path to original test CSV\n",
    "            output_dir: Directory to save split data\n",
    "            n_folds: Number of folds for cross-validation\n",
    "            random_seed: Random seed for reproducibility\n",
    "            val_split_ratio: Ratio for train/val split within each fold\n",
    "        \"\"\"\n",
    "        self.train_file = train_file\n",
    "        self.val_file = val_file\n",
    "        self.test_file = test_file\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.n_folds = n_folds\n",
    "        self.random_seed = random_seed\n",
    "        self.val_split_ratio = val_split_ratio\n",
    "        \n",
    "        # Create output directory\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Set random seeds\n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and combine all data for k-fold splitting\"\"\"\n",
    "        logger.info(\"Loading original data files...\")\n",
    "        \n",
    "        # Load datasets\n",
    "        self.df_train = pd.read_csv(self.train_file)\n",
    "        self.df_val = pd.read_csv(self.val_file)\n",
    "        self.df_test = pd.read_csv(self.test_file)\n",
    "        \n",
    "        # Combine all data for k-fold CV\n",
    "        self.df_full = pd.concat([self.df_train, self.df_val, self.df_test], ignore_index=True)\n",
    "        \n",
    "        logger.info(f\"Loaded {len(self.df_train)} train + {len(self.df_val)} val + {len(self.df_test)} test = {len(self.df_full)} total samples\")\n",
    "        \n",
    "        # Check label distribution\n",
    "        label_dist = self.df_full['label'].value_counts().sort_index()\n",
    "        logger.info(f\"Label distribution: {dict(label_dist)}\")\n",
    "        logger.info(f\"Class balance: {label_dist[1]/len(self.df_full)*100:.1f}% positive\")\n",
    "        \n",
    "        return self.df_full\n",
    "    \n",
    "    def create_stratified_folds(self):\n",
    "        \"\"\"Create stratified k-fold splits\"\"\"\n",
    "        logger.info(f\"Creating {self.n_folds}-fold stratified splits...\")\n",
    "        \n",
    "        # Create stratified k-fold splitter\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_seed)\n",
    "        \n",
    "        # Get labels for stratification\n",
    "        X = self.df_full.index.values\n",
    "        y = self.df_full['label'].values\n",
    "        \n",
    "        self.fold_splits = []\n",
    "        \n",
    "        for fold_idx, (train_val_indices, test_indices) in enumerate(kfold.split(X, y)):\n",
    "            fold_info = {\n",
    "                'fold': fold_idx + 1,\n",
    "                'train_val_indices': train_val_indices.tolist(),\n",
    "                'test_indices': test_indices.tolist(),\n",
    "                'train_val_size': len(train_val_indices),\n",
    "                'test_size': len(test_indices)\n",
    "            }\n",
    "            \n",
    "            # Further split train_val into train and val\n",
    "            train_val_data = self.df_full.iloc[train_val_indices]\n",
    "            train_val_labels = train_val_data['label'].values\n",
    "            \n",
    "            # Stratified split for train/val\n",
    "            train_indices_rel, val_indices_rel = train_test_split(\n",
    "                range(len(train_val_indices)),\n",
    "                test_size=self.val_split_ratio,\n",
    "                stratify=train_val_labels,\n",
    "                random_state=self.random_seed + fold_idx  # Different seed per fold\n",
    "            )\n",
    "            \n",
    "            # Convert relative indices back to absolute indices\n",
    "            train_indices_abs = train_val_indices[train_indices_rel]\n",
    "            val_indices_abs = train_val_indices[val_indices_rel]\n",
    "            \n",
    "            fold_info.update({\n",
    "                'train_indices': train_indices_abs.tolist(),\n",
    "                'val_indices': val_indices_abs.tolist(),\n",
    "                'train_size': len(train_indices_abs),\n",
    "                'val_size': len(val_indices_abs)\n",
    "            })\n",
    "            \n",
    "            # Check label distribution in each split\n",
    "            train_labels = self.df_full.iloc[train_indices_abs]['label'].values\n",
    "            val_labels = self.df_full.iloc[val_indices_abs]['label'].values\n",
    "            test_labels = self.df_full.iloc[test_indices]['label'].values\n",
    "            \n",
    "            fold_info.update({\n",
    "                'train_label_dist': np.bincount(train_labels).tolist(),\n",
    "                'val_label_dist': np.bincount(val_labels).tolist(),\n",
    "                'test_label_dist': np.bincount(test_labels).tolist(),\n",
    "                'train_pos_ratio': np.mean(train_labels),\n",
    "                'val_pos_ratio': np.mean(val_labels), \n",
    "                'test_pos_ratio': np.mean(test_labels)\n",
    "            })\n",
    "            \n",
    "            self.fold_splits.append(fold_info)\n",
    "            \n",
    "            logger.info(f\"Fold {fold_idx + 1}: Train={len(train_indices_abs)}, Val={len(val_indices_abs)}, Test={len(test_indices)}\")\n",
    "            logger.info(f\"  Positive ratios - Train: {np.mean(train_labels):.3f}, Val: {np.mean(val_labels):.3f}, Test: {np.mean(test_labels):.3f}\")\n",
    "        \n",
    "        return self.fold_splits\n",
    "    \n",
    "    def save_fold_data(self):\n",
    "        \"\"\"Save each fold's data to separate CSV files\"\"\"\n",
    "        logger.info(\"Saving fold data to CSV files...\")\n",
    "        \n",
    "        for fold_info in self.fold_splits:\n",
    "            fold_num = fold_info['fold']\n",
    "            fold_dir = self.output_dir / f\"fold_{fold_num}\"\n",
    "            fold_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Extract data for this fold\n",
    "            train_data = self.df_full.iloc[fold_info['train_indices']].copy()\n",
    "            val_data = self.df_full.iloc[fold_info['val_indices']].copy()\n",
    "            test_data = self.df_full.iloc[fold_info['test_indices']].copy()\n",
    "            \n",
    "            # Add fold information\n",
    "            train_data['fold'] = fold_num\n",
    "            val_data['fold'] = fold_num  \n",
    "            test_data['fold'] = fold_num\n",
    "            \n",
    "            train_data['split'] = 'train'\n",
    "            val_data['split'] = 'val'\n",
    "            test_data['split'] = 'test'\n",
    "            \n",
    "            # Save to CSV\n",
    "            train_data.to_csv(fold_dir / \"train.csv\", index=False)\n",
    "            val_data.to_csv(fold_dir / \"val.csv\", index=False)\n",
    "            test_data.to_csv(fold_dir / \"test.csv\", index=False)\n",
    "            \n",
    "            logger.info(f\"Saved fold {fold_num}: {len(train_data)} train, {len(val_data)} val, {len(test_data)} test\")\n",
    "    \n",
    "    def save_original_data(self):\n",
    "        \"\"\"Save original data splits for reference\"\"\"\n",
    "        logger.info(\"Saving original data splits...\")\n",
    "        \n",
    "        original_dir = self.output_dir / \"original\"\n",
    "        original_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Copy original files\n",
    "        self.df_train.to_csv(original_dir / \"train.csv\", index=False)\n",
    "        self.df_val.to_csv(original_dir / \"val.csv\", index=False)\n",
    "        self.df_test.to_csv(original_dir / \"test.csv\", index=False)\n",
    "        \n",
    "        # Also save combined data\n",
    "        self.df_full.to_csv(original_dir / \"combined.csv\", index=False)\n",
    "        \n",
    "        logger.info(f\"Saved original splits to {original_dir}\")\n",
    "    \n",
    "    def save_fold_info(self):\n",
    "        \"\"\"Save fold information and metadata\"\"\"\n",
    "        fold_info_file = self.output_dir / \"fold_info.json\"\n",
    "        \n",
    "        metadata = {\n",
    "            'n_folds': self.n_folds,\n",
    "            'random_seed': self.random_seed,\n",
    "            'val_split_ratio': self.val_split_ratio,\n",
    "            'total_samples': len(self.df_full),\n",
    "            'original_files': {\n",
    "                'train': self.train_file,\n",
    "                'val': self.val_file,\n",
    "                'test': self.test_file\n",
    "            },\n",
    "            'fold_splits': self.fold_splits\n",
    "        }\n",
    "        \n",
    "        with open(fold_info_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logger.info(f\"Saved fold information to {fold_info_file}\")\n",
    "    \n",
    "    def create_summary_stats(self):\n",
    "        \"\"\"Create summary statistics across all folds\"\"\"\n",
    "        logger.info(\"Creating summary statistics...\")\n",
    "        \n",
    "        # Calculate statistics across folds\n",
    "        stats = {\n",
    "            'avg_train_size': np.mean([fold['train_size'] for fold in self.fold_splits]),\n",
    "            'avg_val_size': np.mean([fold['val_size'] for fold in self.fold_splits]),\n",
    "            'avg_test_size': np.mean([fold['test_size'] for fold in self.fold_splits]),\n",
    "            'avg_train_pos_ratio': np.mean([fold['train_pos_ratio'] for fold in self.fold_splits]),\n",
    "            'avg_val_pos_ratio': np.mean([fold['val_pos_ratio'] for fold in self.fold_splits]),\n",
    "            'avg_test_pos_ratio': np.mean([fold['test_pos_ratio'] for fold in self.fold_splits]),\n",
    "            'std_train_pos_ratio': np.std([fold['train_pos_ratio'] for fold in self.fold_splits]),\n",
    "            'std_val_pos_ratio': np.std([fold['val_pos_ratio'] for fold in self.fold_splits]),\n",
    "            'std_test_pos_ratio': np.std([fold['test_pos_ratio'] for fold in self.fold_splits])\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"üìä FOLD SUMMARY STATISTICS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Average sizes: Train={stats['avg_train_size']:.0f}, Val={stats['avg_val_size']:.0f}, Test={stats['avg_test_size']:.0f}\")\n",
    "        print(f\"Positive class ratios:\")\n",
    "        print(f\"  Train: {stats['avg_train_pos_ratio']:.3f} ¬± {stats['std_train_pos_ratio']:.3f}\")\n",
    "        print(f\"  Val:   {stats['avg_val_pos_ratio']:.3f} ¬± {stats['std_val_pos_ratio']:.3f}\")\n",
    "        print(f\"  Test:  {stats['avg_test_pos_ratio']:.3f} ¬± {stats['std_test_pos_ratio']:.3f}\")\n",
    "        \n",
    "        # Save stats\n",
    "        stats_file = self.output_dir / \"summary_stats.json\"\n",
    "        with open(stats_file, 'w') as f:\n",
    "            json.dump(stats, f, indent=2)\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Execute the complete data splitting pipeline\"\"\"\n",
    "        logger.info(\"üöÄ Starting data splitting pipeline...\")\n",
    "        \n",
    "        # Step 1: Load data\n",
    "        self.load_data()\n",
    "        \n",
    "        # Step 2: Create stratified folds\n",
    "        self.create_stratified_folds()\n",
    "        \n",
    "        # Step 3: Save fold data\n",
    "        self.save_fold_data()\n",
    "        \n",
    "        # Step 4: Save original data\n",
    "        self.save_original_data()\n",
    "        \n",
    "        # Step 5: Save fold information\n",
    "        self.save_fold_info()\n",
    "        \n",
    "        # Step 6: Create summary statistics\n",
    "        self.create_summary_stats()\n",
    "        \n",
    "        logger.info(\"‚úÖ Data splitting pipeline completed successfully!\")\n",
    "        logger.info(f\"üìÅ Data splits saved to: {self.output_dir.absolute()}\")\n",
    "        \n",
    "        return self.fold_splits\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    # File paths - UPDATE THESE TO YOUR PATHS\n",
    "    train_file = \"/home/liorkob/M.Sc/thesis/citation-prediction/data_splits/crossencoder_train.csv\"\n",
    "    val_file = \"/home/liorkob/M.Sc/thesis/citation-prediction/data_splits/crossencoder_val.csv\"\n",
    "    test_file = \"/home/liorkob/M.Sc/thesis/citation-prediction/data_splits/crossencoder_test.csv\"\n",
    "    \n",
    "    # Create data splitter\n",
    "    splitter = DataSplitter(\n",
    "        train_file=train_file,\n",
    "        val_file=val_file,\n",
    "        test_file=test_file,\n",
    "        output_dir=\"data_splits_5fold\",\n",
    "        n_folds=5,\n",
    "        random_seed=42,\n",
    "        val_split_ratio=0.2\n",
    "    )\n",
    "    \n",
    "    # Run the pipeline\n",
    "    fold_splits = splitter.run()\n",
    "    \n",
    "    # Print final summary\n",
    "    print(f\"\\nüéØ PIPELINE COMPLETE!\")\n",
    "    print(f\"Created {len(fold_splits)} folds with consistent stratified splits\")\n",
    "    print(f\"Each fold maintains similar class distributions\")\n",
    "    print(f\"Ready for reproducible cross-validation experiments!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4gemma_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
