{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract indictment facts- no api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define start and end patterns based on the 'part' column (for partial matches)\n",
    "START_PARTS = [\n",
    "    \"×¢×•×‘×“×•×ª×\", \"×›×œ×œ×™\", \"×›×ª×‘ ×”××™×©×•×\", \"×”××™×©×•×\", \"××™×©×•×\", \"×¨×§×¢\", \"×’×–×¨\", \"×“×™×Ÿ\", \"×¤×¡×§\",\"××‘×•×\",\"×”×¨×©×¢×ª\" ,\"×‘×¢× ×™×™× ×•\",\"×¢×‘×™×¨×•×ª\",\"×”×•×¨×©×¢\",\"×¢×•×‘×“×•×ª\"\n",
    "]\n",
    "\n",
    "END_PARTS = [\n",
    "    \"×˜×¢× ×•×ª\", \"×¢××“×ª\", \"×ª×¡×§×™×¨\", \"×©×™×¨×•×ª\", \"××‘×—×Ÿ\", \"×“×™×•×Ÿ\", \"×”×ª×¡×§×™×¨\",\n",
    "    \"×˜×™×¢×•× ×™\", \"×”×¦×“×“×™×\", \"×¦×“×“×™×\", \"×•×”×›×¨×¢×”\", \"×”××™×©×•× ×”×©× ×™\", \"×¨××™×•×ª\"\n",
    "]\n",
    "\n",
    "def extract_indictment_facts(df):\n",
    "    \"\"\"\n",
    "    Extracts the 'Indictment Facts' section based on the 'part' column with partial matches.\n",
    "    Ensures:\n",
    "    - If start and end are the same, it extends the search.\n",
    "    - The text **does not** include the content of the end part, only up to it.\n",
    "    \"\"\"\n",
    "    if df.empty or \"part\" not in df.columns or \"text\" not in df.columns:\n",
    "        return \"âŒ No indictment facts found\", None, None\n",
    "\n",
    "    # Find the first row where 'part' contains a start pattern (case-insensitive, partial match)\n",
    "    start_row = df[df[\"part\"].str.contains('|'.join(START_PARTS), case=False, na=False, regex=True)]\n",
    "    if start_row.empty:\n",
    "        return \"âŒ No indictment facts found\", None, None\n",
    "    start_idx = start_row.index.min()\n",
    "    start_part_name = df.loc[start_idx, \"part\"]\n",
    "\n",
    "    # Find the first row where 'part' contains an end pattern **after** the start index\n",
    "    end_row = df[df.index > start_idx][df[\"part\"].str.contains('|'.join(END_PARTS), case=False, na=False, regex=True)]\n",
    "\n",
    "    # Ensure end is after start and not identical in name\n",
    "    if not end_row.empty:\n",
    "        potential_end_idx = end_row.index.min()\n",
    "\n",
    "        # If the end part is the same as the start part, look further down\n",
    "        if df.loc[potential_end_idx, \"part\"] == df.loc[start_idx, \"part\"]:\n",
    "            print(f\"âš ï¸ Warning: Start and End have the same name for verdict '{df['verdict'].iloc[0]}'. Searching for next distinct part.\")\n",
    "\n",
    "            # Find the next part that is different from the start part\n",
    "            extended_end_row = df[df.index > potential_end_idx][df[\"part\"] != df.loc[start_idx, \"part\"]]\n",
    "\n",
    "            if not extended_end_row.empty:\n",
    "                end_idx = extended_end_row.index.min()\n",
    "            else:\n",
    "                end_idx = len(df)  # Default to full text if no better match is found\n",
    "        else:\n",
    "            end_idx = potential_end_idx  # Use valid end index if found\n",
    "    else:\n",
    "        end_idx = len(df)  # Default to full text if no end marker is found\n",
    "\n",
    "    # Assign extracted part\n",
    "    end_part_name = df.loc[end_idx, \"part\"] if end_idx < len(df) else \"âŒ No end found (used full text)\"\n",
    "\n",
    "    # Extract text **only until** the end part, excluding it\n",
    "    extracted_text = \"\\n\".join(df.loc[start_idx:end_idx-1, \"text\"].dropna().astype(str))  # Exclude the last part\n",
    "\n",
    "    return extracted_text.strip() if extracted_text else \"âŒ No indictment facts found\", start_part_name, end_part_name\n",
    "\n",
    "# Tracking statistics\n",
    "total_files = 0\n",
    "successful_extractions = 0\n",
    "failed_extractions = 0\n",
    "failed_verdicts = []\n",
    "extracted_results = []\n",
    "for year in [2018,2019,2020]:\n",
    "    csv_directory = f\"/home/liorkob/thesis/lcp/data/docx_csv_{year}\"  # Change this to your actual directory\n",
    "\n",
    "    # Iterate through all CSV files in the directory\n",
    "    for filename in os.listdir(csv_directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            total_files += 1\n",
    "            file_path = os.path.join(csv_directory, filename)\n",
    "            \n",
    "            # Load CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Ensure necessary columns exist\n",
    "            if 'verdict' not in df.columns or 'text' not in df.columns or 'part' not in df.columns:\n",
    "                print(f\"Skipping {filename}, missing required columns.\")\n",
    "                continue\n",
    "\n",
    "            # Extract indictment facts based on 'part'\n",
    "            extracted_facts, start_part, end_part = extract_indictment_facts(df)\n",
    "\n",
    "            # Track statistics\n",
    "            if extracted_facts == \"âŒ No indictment facts found\":\n",
    "                failed_extractions += 1\n",
    "                failed_verdicts.append({\n",
    "                    \"verdict\": df[\"verdict\"].iloc[0],\n",
    "                    \"all_parts\": \"; \".join(df[\"part\"].dropna().astype(str).unique())  # Store all parts for debugging\n",
    "                })\n",
    "                print(f\"\\nâŒ **Failed Extraction for Verdict: {df['verdict'].iloc[0]}**\")\n",
    "                print(f\"ğŸ“Œ Available Parts: {failed_verdicts[-1]['all_parts']}\\n\")\n",
    "            else:\n",
    "                successful_extractions += 1\n",
    "\n",
    "            # Store results\n",
    "            extracted_results.append({\n",
    "                \"verdict\": df[\"verdict\"].iloc[0],\n",
    "                \"extracted_facts\": extracted_facts,\n",
    "                \"start_part\": start_part if start_part else \"âŒ Not Found\",\n",
    "                \"end_part\": end_part if end_part else \"âŒ Not Found\"\n",
    "            })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "final_df = pd.DataFrame(extracted_results)\n",
    "failed_df = pd.DataFrame(failed_verdicts) if failed_verdicts else pd.DataFrame(columns=[\"verdict\", \"all_parts\"])\n",
    "\n",
    "# Save results\n",
    "final_df.to_csv(\"processed_verdicts.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "failed_df.to_csv(\"failed_verdicts.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Display statistics\n",
    "stats = {\n",
    "    \"Total CSV Files Processed\": total_files,\n",
    "    \"Successful Extractions\": successful_extractions,\n",
    "    \"Failed Extractions\": failed_extractions\n",
    "}\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\n=== Statistics ===\")\n",
    "print(pd.DataFrame([stats]))\n",
    "\n",
    "# Show failed verdicts (if any)\n",
    "if not failed_df.empty:\n",
    "    print(\"\\n=== Sample of Failed Verdicts ===\")\n",
    "    print(failed_df.head())  # Print first few rows for review\n",
    "\n",
    "# Show extracted results with start and end parts\n",
    "print(\"\\n=== Sample of Successful Extractions (Start & End Parts) ===\")\n",
    "print(final_df[[\"verdict\", \"start_part\", \"end_part\"]].head())  # Print first few rows\n",
    "\n",
    "print(\"\\nâœ… Process complete. Results saved as 'processed_verdicts.csv' and 'failed_verdicts.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract indictment facts with API gpt-VERDICTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3491/3491 [00:04<00:00, 711.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Statistics ===\n",
      "   Total CSV Files Processed  Successful Extractions  Failed Extractions\n",
      "0                       3491                       0                   0\n",
      "\n",
      "âœ… Process complete. Results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# ========== API Setup ==========\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"  # Replace with actual key\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ========== File Paths ==========\n",
    "csv_directory = \"/home/liorkob/M.Sc/thesis/data/5k/verdict_csv\"\n",
    "out_dir = \"/home/liorkob/M.Sc/thesis/data/5k/gpt\"\n",
    "output_file = os.path.join(out_dir, \"processed_verdicts_with_gpt.csv\")\n",
    "failed_file = os.path.join(out_dir, \"failed_verdicts.csv\")\n",
    "\n",
    "# ========== Pattern Definitions ==========\n",
    "START_PARTS = [\"×¢×•×‘×“×•×ª×\", \"×›×œ×œ×™\", \"×›×ª×‘ ×”××™×©×•×\", \"×”××™×©×•×\", \"××™×©×•×\", \"×¨×§×¢\", \"×’×–×¨\", \"×“×™×Ÿ\", \"×¤×¡×§\",\"××‘×•×\",\"×”×¨×©×¢×ª\" ,\"×‘×¢× ×™×™× ×•\",\"×¢×‘×™×¨×•×ª\",\"×”×•×¨×©×¢\",\"×¢×•×‘×“×•×ª\",\"×”×©×ª×œ×©×œ×•×ª\", \"×’ ×– ×¨\",  \"×“ ×™ ×Ÿ\"]\n",
    "END_PARTS = [\"×˜×¢× ×•×ª\", \"×¢××“×ª\", \"×ª×¡×§×™×¨\",\"×ª×¡×§×™×¨×™\", \"×©×™×¨×•×ª\", \"××‘×—×Ÿ\", \"×“×™×•×Ÿ\", \"×”×ª×¡×§×™×¨\",\"×˜×™×¢×•× ×™\", \"×”×¦×“×“×™×\", \"×¦×“×“×™×\", \"×•×”×›×¨×¢×”\",  \"×¨××™×•×ª\",\"×”×—×œ×˜×”\"]\n",
    "\n",
    "# ========== Helper Functions ==========\n",
    "def extract_indictment_facts(df):\n",
    "    if df.empty or \"part\" not in df.columns or \"text\" not in df.columns:\n",
    "        return \"âŒ No indictment facts found\", None, None\n",
    "\n",
    "    df[\"part\"] = df[\"part\"].astype(str).str.strip()\n",
    "    start_row = df[df[\"part\"].str.contains('|'.join(START_PARTS), case=False, na=False, regex=True)]\n",
    "    if start_row.empty:\n",
    "        start_idx = 0\n",
    "        start_part_name = \"âŒ No start found (used full text)\"\n",
    "    else:\n",
    "        start_idx = start_row.index.min()\n",
    "        start_part_name = df.loc[start_idx, \"part\"]\n",
    "\n",
    "    end_row = df[df.index > start_idx][df[\"part\"].str.contains('|'.join(END_PARTS), case=False, na=False, regex=True)]\n",
    "    if not end_row.empty and end_row.index.min() == start_idx:\n",
    "        end_row = df[df.index > start_idx + 1][df[\"part\"].str.contains('|'.join(END_PARTS), case=False, na=False, regex=True)]\n",
    "\n",
    "    end_idx = end_row.index.min() if not end_row.empty else len(df)\n",
    "    end_part_name = df.loc[end_idx, \"part\"] if not end_row.empty else \"âŒ No end found (used full text)\"\n",
    "    extracted_text = \"\\n\".join(df.loc[start_idx:end_idx - 1, \"text\"].dropna().astype(str))\n",
    "    return extracted_text.strip() if extracted_text else \"âŒ No indictment facts found\", start_part_name, end_part_name\n",
    "\n",
    "\n",
    "def extract_facts_with_gpt(text):\n",
    "    \"\"\"\n",
    "    Sends extracted text to GPT API and extracts specific facts.\n",
    "    \"\"\"\n",
    "    if text == \"âŒ No indictment facts found\":\n",
    "        return \"GPT extraction error\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    **Task:** Extract only the factual allegations from the provided legal text, preserving the original wording without summarizing, rephrasing, or omitting details. Present the extracted facts as a single paragraph rather than a structured list.\n",
    "\n",
    "    **Guidelines:**\n",
    "    - Do not include conclusions, arguments, or legal interpretations.\n",
    "    - Keep the extracted text **exactly as it appears** in the original source.\n",
    "    - Maintain coherence when merging multiple allegations into a single paragraph.\n",
    "\n",
    "    **Example:**\n",
    "    \n",
    "    **Input:**\n",
    "    ×”× ××©× ×”×•×¨×©×¢ ×¢×œ ×¤×™ ×”×•×“××ª×• ×‘×¢×‘×™×¨×•×ª ×©×œ ×”×—×–×§×ª ×—×œ×§ ×©×œ × ×©×§ ××• ×ª×—××•×©×ª, ×œ×¤×™ ×¡×¢×™×£ 144 (×) ×œ×—×•×§ ×”×¢×•× ×©×™×Ÿ, ×ª×©×œ\"×– 1977 (×œ×”×œ×Ÿ: \"×—×•×§ ×”×¢×•× ×©×™×Ÿ\") ×•× ×©×™××”/×”×•×‘×œ×ª ×—×œ×§ ×©×œ × ×©×§ ××• ×ª×—××•×©×ª, ×œ×¤×™ ×¡×¢×™×£ 144(×‘) ×œ×—×•×§ ×”×¢×•× ×©×™×Ÿ. ×¢×œ ×¤×™ ×”× ×˜×¢×Ÿ ×‘×›×ª×‘ ×”××™×©×•× ×‘×™×•× 28.8.2022, ×‘×©×¢×” 00:20 ×œ×¢×¨×š, × ×”×’ ×”× ××©× ×‘×¨×›×‘ ××¡×•×’ ×§×™×” ×¡×¤×•×¨×˜×’' × ×•×©× ×œ×•×—×™×ª ×¨×™×©×•×™ ××¡×¤×¨ 13-608-201 ××œ ×¢×‘×¨ ××¢×‘×¨ ×”×œ\"×” ×‘×“×¨×›×• ×œ×©×˜×—×™ ×”××–×•×¨, ×›×œ ×–××ª ×›××©×¨ ×”×•× × ×•×©× ××ª×—×ª ×œ××•×©×‘ ×”× ×”×’ ×‘×¨×›×‘ ×©×§×™×ª ×•×‘×” 6 ××›×œ×•×œ×™× ×©×œ × ×©×§ ××¡×•×’ M16. ×‘× ×•×¡×£ ×‘×ª× ×”××˜×¢×Ÿ ×©×œ ×”×¨×›×‘ × ×©× ×”× ××©× ×©×‘×¢×” ××¨×’×–×™ ×ª×—××•×©×ª ×•××¨×’×– ×§×¨×˜×•×Ÿ ××©×¨ ×”×›×™×œ×• ×™×—×“×™×• ×›-9000 ×›×“×•×¨×™× ×‘×§×•×˜×¨ 5.56 ×\"× ××©×¨ ×”×™×• ××›×•×¡×™× ×•××•×¡×ª×¨×™×.\n",
    "\n",
    "    **Expected Output:**\n",
    "    ×”× ××©× ×”×•×¨×©×¢ ×¢×œ ×¤×™ ×”×•×“××ª×• ×‘×¢×‘×™×¨×•×ª ×©×œ ×”×—×–×§×ª ×—×œ×§ ×©×œ × ×©×§ ××• ×ª×—××•×©×ª, ×œ×¤×™ ×¡×¢×™×£ 144 (×) ×œ×—×•×§ ×”×¢×•× ×©×™×Ÿ, ×ª×©×œ\"×– 1977 ×•× ×©×™××”/×”×•×‘×œ×ª ×—×œ×§ ×©×œ × ×©×§ ××• ×ª×—××•×©×ª, ×œ×¤×™ ×¡×¢×™×£ 144(×‘) ×œ×—×•×§ ×”×¢×•× ×©×™×Ÿ. ×¢×œ ×¤×™ ×”× ×˜×¢×Ÿ ×‘×›×ª×‘ ×”××™×©×•×, ×‘×™×•× 28.8.2022 ×‘×©×¢×” 00:20 ×œ×¢×¨×š, × ×”×’ ×”× ××©× ×‘×¨×›×‘ ××¡×•×’ ×§×™×” ×¡×¤×•×¨×˜×’' ×¢× ×œ×•×—×™×ª ×¨×™×©×•×™ ××¡×¤×¨ 13-608-201 ×œ×›×™×•×•×Ÿ ××¢×‘×¨ ×”×œ\"×” ×‘×“×¨×›×• ×œ×©×˜×—×™ ×”××–×•×¨, ×›××©×¨ ××ª×—×ª ×œ××•×©×‘ ×”× ×”×’ ×‘×¨×›×‘ ×”×™×™×ª×” ×©×§×™×ª ×•×‘×” 6 ××›×œ×•×œ×™× ×©×œ × ×©×§ ××¡×•×’ M16. ×‘× ×•×¡×£, ×‘×ª× ×”××˜×¢×Ÿ ×©×œ ×”×¨×›×‘ × ×©× ×©×‘×¢×” ××¨×’×–×™ ×ª×—××•×©×ª ×•××¨×’×– ×§×¨×˜×•×Ÿ ×©×”×›×™×œ×• ×™×—×“×™×• ×›-9000 ×›×“×•×¨×™× ×‘×§×•×˜×¨ 5.56 ×\"×, ×©×”×™×• ××›×•×¡×™× ×•××•×¡×ª×¨×™×.\n",
    "\n",
    "    **Input Text:**\n",
    "    {text}\n",
    "\n",
    "    **Extracted Facts:**\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI trained to extract factual allegations from legal texts, ensuring no interpretation or rewording.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "     \n",
    "\n",
    "# ========== Load Existing Output ==========\n",
    "if os.path.exists(output_file):\n",
    "    processed_df = pd.read_csv(output_file)\n",
    "else:\n",
    "    processed_df = pd.DataFrame(columns=[\"verdict\", \"extracted_facts\", \"extracted_gpt_facts\", \"start_part\", \"end_part\"])\n",
    "\n",
    "processed_df[\"verdict\"] = processed_df[\"verdict\"].astype(str).str.strip()\n",
    "\n",
    "# ========== Processing Loop ==========\n",
    "total_files = 0\n",
    "successful_extractions = 0\n",
    "failed_extractions = 0\n",
    "failed_verdicts = []\n",
    "\n",
    "file_list = [f for f in os.listdir(csv_directory) if f.endswith(\".csv\")]\n",
    "\n",
    "for filename in tqdm(file_list, desc=\"Processing verdicts\"):\n",
    "    total_files += 1\n",
    "    file_path = os.path.join(csv_directory, filename)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        verdict_id = str(df[\"verdict\"].iloc[0]).strip()\n",
    "\n",
    "        # Check if already processed successfully\n",
    "        existing = processed_df[processed_df[\"verdict\"] == verdict_id]\n",
    "        if not existing.empty and existing[\"extracted_gpt_facts\"].iloc[0] != \"GPT extraction error\":\n",
    "            print(f\"â­ï¸ Skipping GPT for verdict (already processed): {verdict_id}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"ğŸ“¨ Calling GPT for verdict: {verdict_id}\")\n",
    "        extracted_facts, start_part, end_part = extract_indictment_facts(df)\n",
    "        extracted_gpt_facts = extract_facts_with_gpt(extracted_facts)\n",
    "        time.sleep(1)\n",
    "\n",
    "        if extracted_facts.startswith(\"âŒ\") or extracted_gpt_facts == \"GPT extraction error\":\n",
    "            failed_extractions += 1\n",
    "            failed_verdicts.append({\"verdict\": verdict_id, \"all_parts\": \"; \".join(df[\"part\"].dropna().astype(str))})\n",
    "            print(f\"âŒ GPT failed for verdict: {verdict_id}\")\n",
    "\n",
    "            continue\n",
    "\n",
    "        successful_extractions += 1\n",
    "        processed_df = processed_df[processed_df[\"verdict\"] != verdict_id]\n",
    "\n",
    "        new_row = {\n",
    "            \"verdict\": verdict_id,\n",
    "            \"extracted_facts\": extracted_facts,\n",
    "            \"extracted_gpt_facts\": extracted_gpt_facts,\n",
    "            \"start_part\": start_part,\n",
    "            \"end_part\": end_part\n",
    "        }\n",
    "        processed_df = pd.concat([processed_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        # âœ… Save immediately after each verdict\n",
    "        processed_df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸ’¥ Error processing {filename}: {e}\")\n",
    "\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "# ========== Final Save ==========\n",
    "processed_df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "failed_df = pd.DataFrame(failed_verdicts)\n",
    "failed_df.to_csv(failed_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\n=== Statistics ===\")\n",
    "print(pd.DataFrame([{ \"Total CSV Files Processed\": total_files, \"Successful Extractions\": successful_extractions, \"Failed Extractions\": failed_extractions }]))\n",
    "if not failed_df.empty:\n",
    "    print(\"\\n=== Sample of Failed Verdicts ===\")\n",
    "    print(failed_df.head())\n",
    "print(\"\\nâœ… Process complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned CSV saved to: /home/liorkob/M.Sc/thesis/data/5k/gpt/processed_verdicts_with_gpt_clean.csv\n",
      "âœ”ï¸ Total rows after cleaning: 391\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # === Load the original CSV ===\n",
    "# csv_path = \"/home/liorkob/M.Sc/thesis/data/5k/gpt/processed_appeals_with_gpt.csv\"\n",
    "# df = pd.read_csv(csv_path)\n",
    "\n",
    "# # === Remove GPT error rows ===\n",
    "# df_clean = df[df[\"extracted_gpt_facts\"] != \"GPT extraction error\"].copy()\n",
    "\n",
    "# # === Drop duplicate verdicts (keep last one) ===\n",
    "# df_clean = df_clean.drop_duplicates(subset=\"verdict\", keep=\"last\")\n",
    "\n",
    "# # === Save cleaned CSV ===\n",
    "# cleaned_path = csv_path\n",
    "# df_clean.to_csv(cleaned_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# print(f\"âœ… Cleaned CSV saved to: {cleaned_path}\")\n",
    "# print(f\"âœ”ï¸ Total rows after cleaning: {len(df_clean)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compere o1 mini vs 4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# ========== Setup ==========\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"  # Replace with actual key\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ========== File Paths ==========\n",
    "input_file = \"/home/liorkob/M.Sc/thesis/data/5k/gpt/processed_verdicts_with_gpt.csv\"\n",
    "output_file = \"/home/liorkob/M.Sc/thesis/data/5k/gpt/comparison_gpt4o_vs_nano.csv\"\n",
    "\n",
    "# ========== Load Input Data ==========\n",
    "df = pd.read_csv(input_file)\n",
    "df[\"nano_output\"] = \"\"\n",
    "df[\"similarity_score\"] = 0.0\n",
    "\n",
    "# ========== Resume from Existing Output ==========\n",
    "if os.path.exists(output_file):\n",
    "    processed_df = pd.read_csv(output_file)\n",
    "    processed_verdicts = set(processed_df[\"verdict\"])\n",
    "    \n",
    "    # Fill previously processed values\n",
    "    df.set_index(\"verdict\", inplace=True)\n",
    "    processed_df.set_index(\"verdict\", inplace=True)\n",
    "    df.update(processed_df[[\"nano_output\", \"similarity_score\"]])\n",
    "    df.reset_index(inplace=True)\n",
    "    processed_df.reset_index(inplace=True)\n",
    "else:\n",
    "    processed_verdicts = set()\n",
    "\n",
    "# ========== Extraction Function ==========\n",
    "def extract_facts_with_model(text, model_name):\n",
    "    if text == \"âŒ No indictment facts found\":\n",
    "        return \"âŒ No facts extracted\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "**Task:** Extract only the factual allegations from the provided legal text, preserving the original wording without summarizing, rephrasing, or omitting details. Present the extracted facts as a single paragraph rather than a structured list.\n",
    "\n",
    "**Guidelines:**\n",
    "- Do not include conclusions, arguments, or legal interpretations.\n",
    "- Keep the extracted text **exactly as it appears** in the original source.\n",
    "- Maintain coherence when merging multiple allegations into a single paragraph.\n",
    "\n",
    "**Input Text:**\n",
    "{text}\n",
    "\n",
    "**Extracted Facts:**\n",
    "\"\"\".strip()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI trained to extract factual allegations from legal texts, ensuring no interpretation or rewording.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# ========== Similarity Function ==========\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, str(a), str(b)).ratio()\n",
    "\n",
    "# ========== Main Loop ==========\n",
    "autosave_every = 50\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Running GPT-4-1-nano\"):\n",
    "    verdict_id = row[\"verdict\"]\n",
    "    if verdict_id in processed_verdicts and pd.notna(row[\"nano_output\"]) and row[\"nano_output\"] != \"\":\n",
    "        continue\n",
    "\n",
    "    text = row[\"extracted_facts\"]\n",
    "    try:\n",
    "        nano_result = extract_facts_with_model(text, \"gpt-4.1-mini\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error on row {i}, verdict {verdict_id}: {e}\")\n",
    "        nano_result = \"GPT-nano extraction error\"\n",
    "    \n",
    "    df.at[i, \"nano_output\"] = nano_result\n",
    "    df.at[i, \"similarity_score\"] = similarity(row[\"extracted_gpt_facts\"], nano_result)\n",
    "\n",
    "    if i % autosave_every == 0:\n",
    "        df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "# ========== Final Save ==========\n",
    "df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"âœ… Done. Saved to\", output_file)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load results\n",
    "df = pd.read_csv(\"/home/liorkob/M.Sc/thesis/data/5k/gpt/comparison_gpt4o_vs_nano.csv\")\n",
    "\n",
    "# Filter out failed generations\n",
    "valid_df = df[\n",
    "    (df[\"extracted_gpt_facts\"] != \"GPT extraction error\") &\n",
    "    (df[\"nano_output\"] != \"GPT-nano extraction error\")\n",
    "]\n",
    "\n",
    "# Basic stats\n",
    "num_total = len(df)\n",
    "num_valid = len(valid_df)\n",
    "avg_similarity = valid_df[\"similarity_score\"].mean()\n",
    "min_similarity = valid_df[\"similarity_score\"].min()\n",
    "max_similarity = valid_df[\"similarity_score\"].max()\n",
    "\n",
    "# Distribution buckets\n",
    "similarity_bins = pd.cut(valid_df[\"similarity_score\"], bins=[0, 0.6, 0.8, 0.9, 0.95, 1.0])\n",
    "distribution = similarity_bins.value_counts().sort_index()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n=== ğŸ” Comparison Statistics ===\")\n",
    "print(f\"Total samples: {num_total}\")\n",
    "print(f\"Valid samples: {num_valid}\")\n",
    "print(f\"Average similarity: {avg_similarity:.3f}\")\n",
    "print(f\"Minimum similarity: {min_similarity:.3f}\")\n",
    "print(f\"Maximum similarity: {max_similarity:.3f}\")\n",
    "print(\"\\nSimilarity distribution:\")\n",
    "print(distribution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract indictment facts with API gpt-APPEALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   0%|          | 0/1111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â­ï¸ Skipping GPT for verdict (already processed): ×¢\"×¤ 8464âˆ•15\n",
      "â­ï¸ Skipping GPT for verdict (already processed): ×¢\"×¤ 5476âˆ•16\n",
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 5590âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   0%|          | 3/1111 [00:11<1:08:52,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 5611âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   0%|          | 4/1111 [00:14<1:09:07,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 5750âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   0%|          | 5/1111 [00:21<1:23:23,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 5795âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   1%|          | 6/1111 [00:26<1:29:01,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 5836âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   1%|          | 7/1111 [00:32<1:33:46,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 5889âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   1%|          | 8/1111 [00:40<1:52:09,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6101âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   1%|          | 9/1111 [00:47<1:57:49,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6162âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   1%|          | 10/1111 [01:02<2:45:02,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6336âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   1%|          | 11/1111 [01:10<2:39:28,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6339âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   1%|          | 12/1111 [01:13<2:05:46,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6506âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   1%|          | 13/1111 [01:20<2:04:52,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6538âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   1%|â–         | 14/1111 [01:25<1:56:13,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6544âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   1%|â–         | 15/1111 [01:33<2:06:18,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6545âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   1%|â–         | 16/1111 [01:38<1:52:58,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6568âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   2%|â–         | 17/1111 [01:45<1:57:28,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6716âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   2%|â–         | 18/1111 [01:56<2:21:21,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6729âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   2%|â–         | 19/1111 [02:03<2:17:47,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6734âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   2%|â–         | 20/1111 [02:11<2:21:21,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6736âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   2%|â–         | 21/1111 [02:18<2:15:29,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6766âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   2%|â–         | 22/1111 [02:21<1:55:07,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6812âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   2%|â–         | 23/1111 [02:33<2:22:40,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6813âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   2%|â–         | 24/1111 [02:40<2:17:44,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6814âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   2%|â–         | 25/1111 [02:44<2:01:42,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6833âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   2%|â–         | 26/1111 [02:47<1:40:32,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6861âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   2%|â–         | 27/1111 [02:54<1:48:33,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6869âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   3%|â–         | 28/1111 [03:04<2:09:39,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6873âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   3%|â–         | 29/1111 [03:08<1:51:13,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6921âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   3%|â–         | 30/1111 [03:17<2:04:00,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6922âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   3%|â–         | 31/1111 [03:26<2:17:18,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6931âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   3%|â–         | 32/1111 [03:32<2:10:01,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6943âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   3%|â–         | 33/1111 [03:36<1:53:11,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8415âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   3%|â–         | 34/1111 [03:42<1:48:03,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8450âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   3%|â–         | 35/1111 [03:46<1:37:49,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8479âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   3%|â–         | 36/1111 [03:52<1:39:55,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8717âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   3%|â–         | 37/1111 [03:54<1:20:35,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8862âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   3%|â–         | 38/1111 [04:25<3:45:23, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8988âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   4%|â–         | 39/1111 [04:30<3:00:49, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9031âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   4%|â–         | 40/1111 [04:36<2:42:36,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9045âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   4%|â–         | 41/1111 [04:46<2:42:28,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9057âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   4%|â–         | 42/1111 [04:56<2:47:55,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9058âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   4%|â–         | 43/1111 [05:11<3:17:48, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9079âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   4%|â–         | 44/1111 [05:20<3:05:50, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9180âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   4%|â–         | 45/1111 [05:30<3:03:52, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9190âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   4%|â–         | 46/1111 [05:34<2:28:46,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9283âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   4%|â–         | 47/1111 [05:54<3:31:32, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9399âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   4%|â–         | 48/1111 [06:00<3:02:26, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9552âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   4%|â–         | 49/1111 [06:09<2:53:13,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9598âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   5%|â–         | 50/1111 [06:15<2:31:37,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9633âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   5%|â–         | 51/1111 [06:18<2:06:29,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9668âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   5%|â–         | 52/1111 [06:28<2:20:10,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9702âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   5%|â–         | 53/1111 [06:32<1:56:41,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9723âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   5%|â–         | 54/1111 [06:37<1:52:05,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9728âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   5%|â–         | 55/1111 [06:45<1:57:54,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9741âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   5%|â–Œ         | 56/1111 [06:52<1:57:24,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9746âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   5%|â–Œ         | 57/1111 [06:57<1:51:11,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9813âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   5%|â–Œ         | 58/1111 [07:02<1:40:54,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9816âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   5%|â–Œ         | 59/1111 [07:07<1:36:55,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9821âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   5%|â–Œ         | 60/1111 [07:14<1:46:27,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9833âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   5%|â–Œ         | 61/1111 [07:20<1:45:07,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9928âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   6%|â–Œ         | 62/1111 [07:22<1:27:59,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9964âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   6%|â–Œ         | 63/1111 [07:28<1:29:43,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 10025âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   6%|â–Œ         | 64/1111 [07:35<1:37:26,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 10068âˆ•16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   6%|â–Œ         | 65/1111 [07:43<1:54:40,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 319âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   6%|â–Œ         | 66/1111 [07:55<2:20:15,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 390âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   6%|â–Œ         | 67/1111 [07:58<1:55:09,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 445âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   6%|â–Œ         | 68/1111 [08:05<1:58:20,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 514âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   6%|â–Œ         | 69/1111 [08:11<1:49:36,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 536âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   6%|â–‹         | 70/1111 [08:25<2:32:25,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 733âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   6%|â–‹         | 71/1111 [08:31<2:18:49,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 774âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   6%|â–‹         | 72/1111 [08:35<1:57:12,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 804âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   7%|â–‹         | 73/1111 [08:40<1:44:45,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 921âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   7%|â–‹         | 74/1111 [08:43<1:32:14,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 954âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   7%|â–‹         | 75/1111 [08:46<1:21:09,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1053âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   7%|â–‹         | 76/1111 [08:53<1:29:33,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1167âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   7%|â–‹         | 77/1111 [09:01<1:46:29,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1222âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   7%|â–‹         | 78/1111 [09:07<1:44:43,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1244âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   7%|â–‹         | 79/1111 [09:17<2:05:55,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1251âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   7%|â–‹         | 80/1111 [09:20<1:41:50,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1277âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   7%|â–‹         | 81/1111 [09:25<1:34:36,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1288âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   7%|â–‹         | 82/1111 [09:30<1:35:10,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1299âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   7%|â–‹         | 83/1111 [09:34<1:27:44,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1403âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   8%|â–Š         | 84/1111 [09:39<1:26:45,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1414âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   8%|â–Š         | 85/1111 [09:44<1:24:03,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1548âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   8%|â–Š         | 86/1111 [09:53<1:46:24,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1647âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   8%|â–Š         | 87/1111 [09:58<1:38:24,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1730âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   8%|â–Š         | 88/1111 [10:02<1:28:24,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1802âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   8%|â–Š         | 89/1111 [10:08<1:32:00,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1806âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   8%|â–Š         | 90/1111 [10:12<1:25:18,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1821âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   8%|â–Š         | 91/1111 [10:30<2:34:34,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1987âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   8%|â–Š         | 92/1111 [10:34<2:04:35,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2012âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   8%|â–Š         | 93/1111 [10:43<2:16:50,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2021âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   8%|â–Š         | 94/1111 [10:52<2:18:44,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2127âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   9%|â–Š         | 95/1111 [10:57<2:02:54,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2150âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   9%|â–Š         | 96/1111 [11:02<1:54:15,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2163âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   9%|â–Š         | 97/1111 [11:06<1:35:44,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3049âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   9%|â–‰         | 98/1111 [11:09<1:23:53,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3083âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   9%|â–‰         | 99/1111 [11:16<1:32:15,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3159âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   9%|â–‰         | 100/1111 [11:22<1:38:13,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3162âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   9%|â–‰         | 101/1111 [11:25<1:20:48,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3204âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   9%|â–‰         | 102/1111 [11:28<1:15:27,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3250âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   9%|â–‰         | 103/1111 [11:32<1:13:17,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3308âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   9%|â–‰         | 104/1111 [11:42<1:38:34,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3371âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:   9%|â–‰         | 105/1111 [11:50<1:48:07,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3373âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  10%|â–‰         | 106/1111 [11:54<1:35:58,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3450âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  10%|â–‰         | 107/1111 [12:00<1:40:27,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3473âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  10%|â–‰         | 108/1111 [12:15<2:21:32,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3509âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  10%|â–‰         | 109/1111 [12:20<2:06:40,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3511âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  10%|â–‰         | 110/1111 [12:26<2:00:54,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3524âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  10%|â–‰         | 111/1111 [12:31<1:48:06,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3541âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  10%|â–ˆ         | 112/1111 [12:39<1:54:05,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3558âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  10%|â–ˆ         | 113/1111 [12:42<1:36:29,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3591âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  10%|â–ˆ         | 114/1111 [13:03<2:48:27, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3613âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  10%|â–ˆ         | 115/1111 [13:08<2:24:00,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3680âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  10%|â–ˆ         | 116/1111 [13:15<2:15:23,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3705âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  11%|â–ˆ         | 117/1111 [13:23<2:17:17,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3745âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  11%|â–ˆ         | 118/1111 [13:31<2:16:20,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3776âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  11%|â–ˆ         | 119/1111 [13:37<2:04:10,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3780âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  11%|â–ˆ         | 120/1111 [13:45<2:03:26,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3880âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  11%|â–ˆ         | 121/1111 [13:54<2:11:46,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3924âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  11%|â–ˆ         | 122/1111 [14:01<2:09:36,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3998âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  11%|â–ˆ         | 123/1111 [14:08<2:02:09,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4060âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  11%|â–ˆ         | 124/1111 [14:12<1:47:52,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4143âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  11%|â–ˆâ–        | 125/1111 [14:16<1:31:56,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4161âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  11%|â–ˆâ–        | 126/1111 [14:20<1:26:21,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4603âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  11%|â–ˆâ–        | 127/1111 [14:28<1:37:35,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4713âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  12%|â–ˆâ–        | 128/1111 [14:31<1:23:55,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4737âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  12%|â–ˆâ–        | 129/1111 [14:42<1:51:51,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 5721âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  12%|â–ˆâ–        | 130/1111 [14:44<1:27:33,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 5762âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  12%|â–ˆâ–        | 131/1111 [14:52<1:42:33,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 5807âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  12%|â–ˆâ–        | 132/1111 [14:56<1:29:20,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 5928âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  12%|â–ˆâ–        | 133/1111 [15:03<1:39:04,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6072âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  12%|â–ˆâ–        | 134/1111 [15:18<2:21:52,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6098âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  12%|â–ˆâ–        | 135/1111 [15:25<2:13:08,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6326âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  12%|â–ˆâ–        | 136/1111 [15:30<1:59:13,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6459âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  12%|â–ˆâ–        | 137/1111 [15:39<2:04:59,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6532âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  12%|â–ˆâ–        | 138/1111 [15:50<2:21:10,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6539âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  13%|â–ˆâ–        | 139/1111 [15:54<1:59:33,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6557âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  13%|â–ˆâ–        | 140/1111 [15:58<1:42:16,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6590âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  13%|â–ˆâ–        | 141/1111 [16:03<1:36:06,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6622âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  13%|â–ˆâ–        | 142/1111 [16:10<1:41:47,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6637âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  13%|â–ˆâ–        | 143/1111 [16:15<1:35:05,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6691âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  13%|â–ˆâ–        | 144/1111 [16:18<1:19:16,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6773âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  13%|â–ˆâ–        | 145/1111 [16:26<1:34:19,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6807âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  13%|â–ˆâ–        | 146/1111 [16:43<2:30:24,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6838âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  13%|â–ˆâ–        | 147/1111 [16:50<2:18:19,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6876âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  13%|â–ˆâ–        | 148/1111 [17:03<2:37:50,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6886âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  13%|â–ˆâ–        | 149/1111 [17:07<2:08:18,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6888âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  14%|â–ˆâ–        | 150/1111 [17:16<2:14:48,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6893âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  14%|â–ˆâ–        | 151/1111 [17:21<1:56:30,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6898âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  14%|â–ˆâ–        | 152/1111 [17:28<1:53:57,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6899âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  14%|â–ˆâ–        | 153/1111 [17:37<2:04:00,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6928âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  14%|â–ˆâ–        | 154/1111 [17:45<2:03:46,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6932âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  14%|â–ˆâ–        | 155/1111 [17:55<2:14:27,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6938âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  14%|â–ˆâ–        | 156/1111 [18:11<2:51:35, 10.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6943âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  14%|â–ˆâ–        | 157/1111 [18:14<2:13:48,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6950âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  14%|â–ˆâ–        | 158/1111 [18:20<2:03:08,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6961âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  14%|â–ˆâ–        | 159/1111 [18:30<2:15:41,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6962âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  14%|â–ˆâ–        | 160/1111 [18:38<2:12:55,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7020âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  14%|â–ˆâ–        | 161/1111 [18:47<2:14:37,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8439âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  15%|â–ˆâ–        | 162/1111 [18:53<2:03:03,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8441âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  15%|â–ˆâ–        | 163/1111 [19:01<2:01:47,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8449âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  15%|â–ˆâ–        | 164/1111 [19:13<2:25:20,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8477âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  15%|â–ˆâ–        | 165/1111 [19:17<1:57:59,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8515âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  15%|â–ˆâ–        | 166/1111 [19:21<1:44:07,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8544âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  15%|â–ˆâ–Œ        | 167/1111 [19:24<1:22:45,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8574âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  15%|â–ˆâ–Œ        | 168/1111 [19:36<1:56:35,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8614âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  15%|â–ˆâ–Œ        | 169/1111 [19:41<1:45:33,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8671âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  15%|â–ˆâ–Œ        | 170/1111 [19:46<1:35:09,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8759âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  15%|â–ˆâ–Œ        | 171/1111 [19:55<1:48:58,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8881âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  15%|â–ˆâ–Œ        | 172/1111 [19:59<1:37:17,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8963âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  16%|â–ˆâ–Œ        | 173/1111 [20:02<1:19:20,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9147âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  16%|â–ˆâ–Œ        | 174/1111 [20:06<1:17:24,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9238âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  16%|â–ˆâ–Œ        | 175/1111 [20:11<1:18:28,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9284âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  16%|â–ˆâ–Œ        | 176/1111 [20:16<1:18:17,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9302âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  16%|â–ˆâ–Œ        | 177/1111 [20:28<1:50:22,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9560âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  16%|â–ˆâ–Œ        | 178/1111 [20:33<1:37:58,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9573âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  16%|â–ˆâ–Œ        | 179/1111 [20:35<1:16:26,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9629âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  16%|â–ˆâ–Œ        | 180/1111 [20:47<1:52:17,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9652âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  16%|â–ˆâ–‹        | 181/1111 [20:53<1:45:02,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9705âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  16%|â–ˆâ–‹        | 182/1111 [20:55<1:24:07,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9830âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  16%|â–ˆâ–‹        | 183/1111 [21:03<1:35:29,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9852âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  17%|â–ˆâ–‹        | 184/1111 [21:06<1:18:48,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9882âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  17%|â–ˆâ–‹        | 185/1111 [21:16<1:41:20,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9910âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  17%|â–ˆâ–‹        | 186/1111 [21:20<1:29:16,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9919âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  17%|â–ˆâ–‹        | 187/1111 [21:26<1:31:34,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9954âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  17%|â–ˆâ–‹        | 188/1111 [21:30<1:24:05,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9965âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  17%|â–ˆâ–‹        | 189/1111 [21:33<1:08:53,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 10033âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  17%|â–ˆâ–‹        | 190/1111 [21:39<1:17:58,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 10045âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  17%|â–ˆâ–‹        | 191/1111 [21:41<1:06:07,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 10152âˆ•17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  17%|â–ˆâ–‹        | 192/1111 [21:55<1:48:53,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 162âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  17%|â–ˆâ–‹        | 193/1111 [22:00<1:37:55,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1448âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  17%|â–ˆâ–‹        | 194/1111 [22:08<1:47:44,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1548âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  18%|â–ˆâ–Š        | 195/1111 [22:14<1:39:09,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1816âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  18%|â–ˆâ–Š        | 196/1111 [22:19<1:35:05,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1900âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  18%|â–ˆâ–Š        | 197/1111 [22:24<1:28:46,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1940âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  18%|â–ˆâ–Š        | 198/1111 [22:29<1:22:45,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1985âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  18%|â–ˆâ–Š        | 199/1111 [22:37<1:36:45,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 1993âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  18%|â–ˆâ–Š        | 200/1111 [22:44<1:39:19,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2002âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  18%|â–ˆâ–Š        | 201/1111 [22:50<1:34:16,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2048âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  18%|â–ˆâ–Š        | 202/1111 [22:59<1:49:03,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2068âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  18%|â–ˆâ–Š        | 203/1111 [23:01<1:26:49,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2078âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  18%|â–ˆâ–Š        | 204/1111 [23:04<1:10:43,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2104âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  18%|â–ˆâ–Š        | 205/1111 [23:07<1:02:41,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2125âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  19%|â–ˆâ–Š        | 206/1111 [23:09<55:20,  3.67s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2166âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  19%|â–ˆâ–Š        | 207/1111 [23:15<1:04:40,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2206âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  19%|â–ˆâ–Š        | 208/1111 [23:18<59:23,  3.95s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2207âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  19%|â–ˆâ–‰        | 209/1111 [23:34<1:53:31,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2249âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  19%|â–ˆâ–‰        | 210/1111 [23:40<1:47:08,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2433âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  19%|â–ˆâ–‰        | 211/1111 [23:51<2:03:40,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2454âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  19%|â–ˆâ–‰        | 212/1111 [23:54<1:38:13,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2457âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  19%|â–ˆâ–‰        | 213/1111 [23:56<1:20:49,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2487âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  19%|â–ˆâ–‰        | 214/1111 [23:59<1:07:52,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2490âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  19%|â–ˆâ–‰        | 215/1111 [24:05<1:17:05,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2594âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  19%|â–ˆâ–‰        | 216/1111 [24:08<1:06:47,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2596âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  20%|â–ˆâ–‰        | 217/1111 [24:18<1:28:08,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2648âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  20%|â–ˆâ–‰        | 218/1111 [24:22<1:23:13,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2667âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  20%|â–ˆâ–‰        | 219/1111 [24:32<1:40:23,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2702âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  20%|â–ˆâ–‰        | 220/1111 [24:39<1:43:16,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2745âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  20%|â–ˆâ–‰        | 221/1111 [24:43<1:29:16,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2748âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  20%|â–ˆâ–‰        | 222/1111 [24:50<1:34:55,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2802âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  20%|â–ˆâ–ˆ        | 223/1111 [24:54<1:21:29,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2814âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  20%|â–ˆâ–ˆ        | 224/1111 [25:02<1:31:26,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 2834âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  20%|â–ˆâ–ˆ        | 225/1111 [25:05<1:17:06,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3545âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  20%|â–ˆâ–ˆ        | 226/1111 [25:09<1:11:13,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3615âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  20%|â–ˆâ–ˆ        | 227/1111 [25:20<1:42:49,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3619âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  21%|â–ˆâ–ˆ        | 228/1111 [25:28<1:46:22,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3754âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  21%|â–ˆâ–ˆ        | 229/1111 [25:38<1:55:07,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3791âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  21%|â–ˆâ–ˆ        | 230/1111 [25:45<1:55:15,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3792âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  21%|â–ˆâ–ˆ        | 231/1111 [26:06<2:52:39, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3793âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  21%|â–ˆâ–ˆ        | 232/1111 [26:22<3:07:23, 12.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3817âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  21%|â–ˆâ–ˆ        | 233/1111 [26:33<3:00:25, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3903âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  21%|â–ˆâ–ˆ        | 234/1111 [26:35<2:17:28,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 3991âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  21%|â–ˆâ–ˆ        | 235/1111 [26:38<1:47:48,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4045âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  21%|â–ˆâ–ˆ        | 236/1111 [26:49<2:01:50,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4074âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  21%|â–ˆâ–ˆâ–       | 237/1111 [26:58<2:07:27,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4095âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  21%|â–ˆâ–ˆâ–       | 238/1111 [27:03<1:51:30,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4143âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  22%|â–ˆâ–ˆâ–       | 239/1111 [27:10<1:44:35,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4215âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  22%|â–ˆâ–ˆâ–       | 240/1111 [27:17<1:45:29,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4302âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  22%|â–ˆâ–ˆâ–       | 241/1111 [27:27<1:59:16,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4345âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  22%|â–ˆâ–ˆâ–       | 242/1111 [27:31<1:37:05,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4359âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  22%|â–ˆâ–ˆâ–       | 243/1111 [27:36<1:31:22,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4450âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  22%|â–ˆâ–ˆâ–       | 244/1111 [27:42<1:30:47,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4497âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  22%|â–ˆâ–ˆâ–       | 245/1111 [27:52<1:46:11,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4524âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  22%|â–ˆâ–ˆâ–       | 246/1111 [27:57<1:33:38,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4528âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  22%|â–ˆâ–ˆâ–       | 247/1111 [28:17<2:33:45, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4576âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  22%|â–ˆâ–ˆâ–       | 248/1111 [28:21<2:05:22,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4594âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  22%|â–ˆâ–ˆâ–       | 249/1111 [28:27<1:53:25,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4678âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  23%|â–ˆâ–ˆâ–       | 250/1111 [28:30<1:32:25,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4737âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  23%|â–ˆâ–ˆâ–       | 251/1111 [28:40<1:46:02,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4802âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  23%|â–ˆâ–ˆâ–       | 252/1111 [28:53<2:10:01,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4818âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  23%|â–ˆâ–ˆâ–       | 253/1111 [28:55<1:39:06,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4820âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  23%|â–ˆâ–ˆâ–       | 254/1111 [29:02<1:41:53,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 4908âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  23%|â–ˆâ–ˆâ–       | 255/1111 [29:07<1:30:48,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 5066âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  23%|â–ˆâ–ˆâ–       | 256/1111 [29:14<1:33:54,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 5090âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  23%|â–ˆâ–ˆâ–       | 257/1111 [29:19<1:26:58,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6483âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  23%|â–ˆâ–ˆâ–       | 258/1111 [29:24<1:21:44,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6501âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  23%|â–ˆâ–ˆâ–       | 259/1111 [29:31<1:26:32,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6533âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  23%|â–ˆâ–ˆâ–       | 260/1111 [29:36<1:21:30,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6651âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  23%|â–ˆâ–ˆâ–       | 261/1111 [29:43<1:27:14,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6767âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  24%|â–ˆâ–ˆâ–       | 262/1111 [29:49<1:28:25,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6790âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  24%|â–ˆâ–ˆâ–       | 263/1111 [29:57<1:34:04,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6808âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  24%|â–ˆâ–ˆâ–       | 264/1111 [30:04<1:35:50,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6823âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  24%|â–ˆâ–ˆâ–       | 265/1111 [30:07<1:20:46,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 6958âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  24%|â–ˆâ–ˆâ–       | 266/1111 [30:13<1:19:26,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7046âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  24%|â–ˆâ–ˆâ–       | 267/1111 [30:20<1:26:21,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7142âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  24%|â–ˆâ–ˆâ–       | 268/1111 [30:24<1:17:40,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7211âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  24%|â–ˆâ–ˆâ–       | 269/1111 [30:30<1:18:10,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7270âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  24%|â–ˆâ–ˆâ–       | 270/1111 [30:35<1:18:28,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7307âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  24%|â–ˆâ–ˆâ–       | 271/1111 [30:40<1:11:54,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7353âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  24%|â–ˆâ–ˆâ–       | 272/1111 [30:43<1:05:43,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7367âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  25%|â–ˆâ–ˆâ–       | 273/1111 [30:48<1:04:24,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7380âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  25%|â–ˆâ–ˆâ–       | 274/1111 [30:50<55:37,  3.99s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7519âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  25%|â–ˆâ–ˆâ–       | 275/1111 [30:59<1:16:52,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7651âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  25%|â–ˆâ–ˆâ–       | 276/1111 [31:03<1:09:57,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7682âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  25%|â–ˆâ–ˆâ–       | 277/1111 [31:08<1:10:31,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7760âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  25%|â–ˆâ–ˆâ–Œ       | 278/1111 [31:17<1:23:30,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7761âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  25%|â–ˆâ–ˆâ–Œ       | 279/1111 [31:26<1:38:25,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7931âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  25%|â–ˆâ–ˆâ–Œ       | 280/1111 [31:30<1:26:07,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 7984âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  25%|â–ˆâ–ˆâ–Œ       | 281/1111 [31:33<1:11:07,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8136âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  25%|â–ˆâ–ˆâ–Œ       | 282/1111 [31:35<59:57,  4.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8263âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  25%|â–ˆâ–ˆâ–Œ       | 283/1111 [31:57<2:12:45,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8328âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  26%|â–ˆâ–ˆâ–Œ       | 284/1111 [32:05<2:05:14,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8377âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  26%|â–ˆâ–ˆâ–Œ       | 285/1111 [32:19<2:24:18, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8507âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  26%|â–ˆâ–ˆâ–Œ       | 286/1111 [32:41<3:10:26, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8520âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  26%|â–ˆâ–ˆâ–Œ       | 287/1111 [32:43<2:22:05, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8538âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  26%|â–ˆâ–ˆâ–Œ       | 288/1111 [32:48<2:00:17,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8560âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  26%|â–ˆâ–ˆâ–Œ       | 289/1111 [32:57<2:00:17,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8603âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  26%|â–ˆâ–ˆâ–Œ       | 290/1111 [33:10<2:17:10, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8640âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  26%|â–ˆâ–ˆâ–Œ       | 291/1111 [33:17<2:04:57,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8700âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  26%|â–ˆâ–ˆâ–‹       | 292/1111 [33:23<1:52:50,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8777âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  26%|â–ˆâ–ˆâ–‹       | 293/1111 [33:27<1:36:12,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8915âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  26%|â–ˆâ–ˆâ–‹       | 294/1111 [33:32<1:26:03,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8965âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  27%|â–ˆâ–ˆâ–‹       | 295/1111 [33:39<1:29:02,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8978âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  27%|â–ˆâ–ˆâ–‹       | 296/1111 [33:41<1:09:49,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 8988âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  27%|â–ˆâ–ˆâ–‹       | 297/1111 [33:43<57:28,  4.24s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9009âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  27%|â–ˆâ–ˆâ–‹       | 298/1111 [33:45<47:30,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9035âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  27%|â–ˆâ–ˆâ–‹       | 299/1111 [33:53<1:07:39,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9168âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  27%|â–ˆâ–ˆâ–‹       | 300/1111 [33:59<1:11:56,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9197âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  27%|â–ˆâ–ˆâ–‹       | 301/1111 [34:02<1:03:01,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9201âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  27%|â–ˆâ–ˆâ–‹       | 302/1111 [34:16<1:40:38,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9203âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  27%|â–ˆâ–ˆâ–‹       | 303/1111 [34:21<1:30:55,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 9232âˆ•18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  27%|â–ˆâ–ˆâ–‹       | 304/1111 [34:27<1:26:59,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 80âˆ•19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  27%|â–ˆâ–ˆâ–‹       | 305/1111 [34:41<1:57:24,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 205âˆ•19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  28%|â–ˆâ–ˆâ–Š       | 306/1111 [34:50<1:58:24,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 210âˆ•19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verdicts:  28%|â–ˆâ–ˆâ–Š       | 307/1111 [35:00<2:02:18,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Calling GPT for verdict: ×¢\"×¤ 229âˆ•19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "# ========== API Setup ==========\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"  # Replace with actual key\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ========== Pattern Definitions ==========\n",
    "START_PARTS = [\"×¢×•×‘×“×•×ª×\", \"×›×œ×œ×™\", \"×›×ª×‘ ×”××™×©×•×\", \"×”××™×©×•×\", \"××™×©×•×\", \"×¨×§×¢\", \"×’×–×¨\", \"×“×™×Ÿ\", \"×¤×¡×§\",\"××‘×•×\",\"×”×¨×©×¢×ª\" ,\"×‘×¢× ×™×™× ×•\",\"×¢×‘×™×¨×•×ª\",\"×”×•×¨×©×¢\",\"×¢×•×‘×“×•×ª\",\"×”×©×ª×œ×©×œ×•×ª\", \"×’ ×– ×¨\",  \"×“ ×™ ×Ÿ\", \"×¤ ×¡ ×§\"]\n",
    "END_PARTS = [\"×× ×™ ××¡×›×™×\" ,\"×˜×¢× ×•×ª\", \"×¢××“×ª\", \"×ª×¡×§×™×¨\", \"×©×™×¨×•×ª\", \"××‘×—×Ÿ\", \"×“×™×•×Ÿ\", \"×”×ª×¡×§×™×¨\",\"×˜×™×¢×•× ×™\", \"×”×¦×“×“×™×\", \"×¦×“×“×™×\", \"×•×”×›×¨×¢×”\", \"×¨××™×•×ª\",\"×”×›×¨×¢×”\"]\n",
    "\n",
    "# ========== File Paths ==========\n",
    "csv_directory = \"/home/liorkob/M.Sc/thesis/data/5k/appeals_csv\"\n",
    "out_dir = \"/home/liorkob/M.Sc/thesis/data/5k/gpt\"\n",
    "output_file = os.path.join(out_dir, \"processed_appeals_with_gpt.csv\")\n",
    "failed_file = os.path.join(out_dir, \"failed_verdicts.csv\")\n",
    "\n",
    "# ========== Helper Functions ==========\n",
    "def extract_indictment_facts(df):\n",
    "    if df.empty or \"part\" not in df.columns or \"text\" not in df.columns:\n",
    "        return \"âŒ No indictment facts found\", None, None\n",
    "\n",
    "    df[\"part\"] = df[\"part\"].astype(str).str.strip()\n",
    "    start_row = df[df[\"part\"].str.contains('|'.join(START_PARTS), case=False, na=False, regex=True)]\n",
    "    if start_row.empty:\n",
    "        start_idx = 0\n",
    "        start_part_name = \"âŒ No start found (used full text)\"\n",
    "    else:\n",
    "        start_idx = start_row.index.min()\n",
    "        start_part_name = df.loc[start_idx, \"part\"]\n",
    "\n",
    "    end_row = df[\n",
    "        (df.index > start_idx) &\n",
    "        (df[\"part\"].str.contains('|'.join(END_PARTS), case=False, na=False, regex=True))\n",
    "    ]\n",
    "    if not end_row.empty and end_row.index.min() == start_idx:\n",
    "        end_row = df[df.index > start_idx + 1][df[\"part\"].str.contains('|'.join(END_PARTS), case=False, na=False, regex=True)]\n",
    "\n",
    "    end_idx = end_row.index.min() if not end_row.empty else len(df)\n",
    "    end_part_name = df.loc[end_idx, \"part\"] if not end_row.empty else \"âŒ No end found (used full text)\"\n",
    "    extracted_text = \"\\n\".join(df.loc[start_idx:end_idx - 1, \"text\"].dropna().astype(str))\n",
    "    return extracted_text.strip() if extracted_text else \"âŒ No indictment facts found\", start_part_name, end_part_name\n",
    "\n",
    "def extract_facts_with_gpt(text):\n",
    "\n",
    "    \"\"\"\n",
    "    Sends extracted text to GPT API and extracts the original indictment details from the case being appealed.\n",
    "    \"\"\"\n",
    "    if text == \"âŒ No indictment facts found\":\n",
    "        return \"âŒ No facts extracted\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    **Task:** Extract only the original indictment details of the case being appealed. Ignore all references to the appeal decision, legal arguments, and judicial reasoning. The extracted text should contain only the original facts that led to the indictment, exactly as they appear in the text.\n",
    "\n",
    "    **Guidelines:**\n",
    "    - Extract **only the factual allegations** from the original indictment.\n",
    "    - **Do not include** details about the appeal, court rulings, or sentencing decisions.\n",
    "    - Maintain the **exact wording** of the indictment without summarizing or omitting details.\n",
    "    - If the indictment contains multiple allegations, present them in a coherent paragraph.\n",
    "\n",
    "    **Example:**\n",
    "    \n",
    "    **Input:**\n",
    "    ×¢\"\"×¤ 761âˆ•07 - ×¢×¨×¢×•×¨ ×¢×œ ×’×–×¨ ×“×™× ×• ×©×œ ×‘×™×ª ×”××©×¤×˜ ×”××—×•×–×™. \n",
    "    ×‘××—×“ ××™××™×• ×©×œ ×—×•×“×© ×™×•× ×™ 2006, ×‘×©×¢×•×ª ×”×¢×¨×‘, × ×”×’ ×”× ××©× ×‘×¨×›×‘, ×•×›××©×¨ × ×¢×¦×¨ ×¢×œ ×™×“×™ ×©×•×˜×¨×™× ×œ×‘×“×™×§×”, ×”×•× × ××¦× ××—×–×™×§ ×‘××§×“×—, ××—×¡× ×™×ª ×•×ª×—××•×©×ª ×›×©××œ×” ×¢×˜×•×¤×™× ×‘×’×¨×‘ ×•××•×¡×ª×¨×™× ×‘×ª×—×ª×•× ×™×•.\n",
    "    ×›×Ÿ × ×˜×¢×Ÿ, ×›×™ ×”× ××©× ×”×¦×™×’ ×‘×¤× ×™ ×”×©×•×˜×¨×™× ×ª×¢×•×“×ª ×–×”×•×ª ×©×œ ××—×¨ ××ª×•×š ×›×•×•× ×” ×œ×”×•× ×•×ª×.\n",
    "    ×”× ××©× ×”×•×“×” ×‘×¢×•×‘×“×•×ª ×”×××•×¨×•×ª, ×•×‘×¢×§×‘×•×ª ×›×š ×”×•×¨×©×¢ ×‘×¢×‘×™×¨×•×ª ×©×œ ×”×—×–×§×ª × ×©×§ ×©×œ× ×›×“×™×Ÿ ×•×”×¤×¨×¢×” ×œ×©×•×˜×¨ ×‘××™×œ×•×™ ×ª×¤×§×™×“×•, ×¢×‘×™×¨×•×ª ×œ×¤×™ ×¡×¢×™×¤×™× 144 ×¨×™×©× ×•-275 ×œ×—×•×§ ×”×¢×•× ×©×™×Ÿ.\n",
    "\n",
    "    **Expected Output:**\n",
    "    ×‘××—×“ ××™××™×• ×©×œ ×—×•×“×© ×™×•× ×™ 2006, ×‘×©×¢×•×ª ×”×¢×¨×‘, × ×”×’ ×”× ××©× ×‘×¨×›×‘, ×•×›××©×¨ × ×¢×¦×¨ ×¢×œ ×™×“×™ ×©×•×˜×¨×™× ×œ×‘×“×™×§×”, × ××¦× ××—×–×™×§ ×‘××§×“×—, ××—×¡× ×™×ª ×•×ª×—××•×©×ª ×¢×˜×•×¤×™× ×‘×’×¨×‘ ×•××•×¡×ª×¨×™× ×‘×ª×—×ª×•× ×™×•. ×‘× ×•×¡×£, ×”×¦×™×’ ×œ×©×•×˜×¨×™× ×ª×¢×•×“×ª ×–×”×•×ª ×©×œ ××—×¨ ×‘×›×•×•× ×” ×œ×”×•× ×•×ª×. ×¢×œ ×¡××š ×¢×•×‘×“×•×ª ××œ×”, ×”×•××©× ×‘×¢×‘×™×¨×•×ª ×©×œ ×”×—×–×§×ª × ×©×§ ×©×œ× ×›×“×™×Ÿ ×•×”×¤×¨×¢×” ×œ×©×•×˜×¨ ×‘××™×œ×•×™ ×ª×¤×§×™×“×• ×œ×¤×™ ×¡×¢×™×¤×™× 144 ×¨×™×©× ×•-275 ×œ×—×•×§ ×”×¢×•× ×©×™×Ÿ.\n",
    "\n",
    "    **Input Text:**\n",
    "    {text}\n",
    "\n",
    "    **Extracted Indictment Details:**\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI trained to extract factual allegations from legal texts, ensuring no interpretation or rewording.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# ========== Load Existing Output ==========\n",
    "if os.path.exists(output_file):\n",
    "    processed_df = pd.read_csv(output_file)\n",
    "else:\n",
    "    processed_df = pd.DataFrame(columns=[\"verdict\", \"extracted_facts\", \"extracted_gpt_facts\", \"start_part\", \"end_part\"])\n",
    "\n",
    "processed_df[\"verdict\"] = processed_df[\"verdict\"].astype(str).str.strip()\n",
    "\n",
    "# ========== Processing Loop ==========\n",
    "total_files = 0\n",
    "successful_extractions = 0\n",
    "failed_extractions = 0\n",
    "failed_verdicts = []\n",
    "\n",
    "file_list = [f for f in os.listdir(csv_directory) if f.endswith(\".csv\")]\n",
    "\n",
    "for filename in tqdm(file_list, desc=\"Processing verdicts\"):\n",
    "    total_files += 1\n",
    "    file_path = os.path.join(csv_directory, filename)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        verdict_id = str(df[\"verdict\"].iloc[0]).strip()\n",
    "\n",
    "        # Check if already processed successfully\n",
    "        existing = processed_df[processed_df[\"verdict\"] == verdict_id]\n",
    "        if not existing.empty and existing[\"extracted_gpt_facts\"].iloc[0] != \"GPT extraction error\":\n",
    "            print(f\"â­ï¸ Skipping GPT for verdict (already processed): {verdict_id}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"ğŸ“¨ Calling GPT for verdict: {verdict_id}\")\n",
    "        extracted_facts, start_part, end_part = extract_indictment_facts(df)\n",
    "        extracted_gpt_facts = extract_facts_with_gpt(extracted_facts)\n",
    "        time.sleep(1)\n",
    "\n",
    "        if extracted_facts.startswith(\"âŒ\") or extracted_gpt_facts == \"GPT extraction error\":\n",
    "            failed_extractions += 1\n",
    "            failed_verdicts.append({\"verdict\": verdict_id, \"all_parts\": \"; \".join(df[\"part\"].dropna().astype(str))})\n",
    "            print(f\"âŒ GPT failed for verdict: {verdict_id}\")\n",
    "\n",
    "            continue\n",
    "\n",
    "        successful_extractions += 1\n",
    "        processed_df = processed_df[processed_df[\"verdict\"] != verdict_id]\n",
    "\n",
    "        new_row = {\n",
    "            \"verdict\": verdict_id,\n",
    "            \"extracted_facts\": extracted_facts,\n",
    "            \"extracted_gpt_facts\": extracted_gpt_facts,\n",
    "            \"start_part\": start_part,\n",
    "            \"end_part\": end_part\n",
    "        }\n",
    "        processed_df = pd.concat([processed_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        # âœ… Save immediately after each verdict\n",
    "        processed_df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸ’¥ Error processing {filename}: {e}\")\n",
    "\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "# ========== Final Save ==========\n",
    "processed_df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "failed_df = pd.DataFrame(failed_verdicts)\n",
    "failed_df.to_csv(failed_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\n=== Statistics ===\")\n",
    "print(pd.DataFrame([{ \"Total CSV Files Processed\": total_files, \"Successful Extractions\": successful_extractions, \"Failed Extractions\": failed_extractions }]))\n",
    "if not failed_df.empty:\n",
    "    print(\"\\n=== Sample of Failed Verdicts ===\")\n",
    "    print(failed_df.head())\n",
    "print(\"\\nâœ… Process complete. Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
